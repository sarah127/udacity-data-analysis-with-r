{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarah127/udacity-data-analysis-with-r/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgzROkNIH4do",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "83457b6e-30fc-40c8-d686-be2fc3214693"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzRDj21AgZ8u",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGDCijX7ybgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "89feeb1f-2c76-41bc-9d8d-c167fc8a78ff"
      },
      "source": [
        "#' ' means CPU whereas '/device:G:0' means GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAV8exRXypkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "878cacda-a084-4ed0-cdda-f821ee6e101f"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 154.8 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuFNEWi_19RH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "2ca37fbd-5b11-4c35-a62f-418339b7e336"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1R6gDJMND6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP8zG65mYk86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-IRoKKSfh4q",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "e2febe11-ce2a-4429-d372-e152cf78447e"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-223422d2-77ab-4ed0-aa68-2b83b48bf8e2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-223422d2-77ab-4ed0-aa68-2b83b48bf8e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wEHXFWvfzTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5f000ca2-054a-47ff-b0cf-02497e93679a"
      },
      "source": [
        "!ls /content/drive/*"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'191021-234625 (1).png'\t\t   'How to get started with Drive.pdf'\n",
            " 191021-234625.png\t\t   'IELTS Grammar Chris'\n",
            "'٢٠١٨٠٢٠٥_٢١٤٣٥٥ (1).jpg'\t    IMG_20180427_151315.jpg\n",
            "'٢٠١٨٠٢٠٥_٢١٤٣٥٥ (2).jpg'\t   'IMG_20190909_205719[1] (1).jpg'\n",
            " ٢٠١٨٠٢٠٥_٢١٤٣٥٥.jpg\t\t   'IMG_20190909_205719[1].jpg'\n",
            "'٢٠١٨٠٢٠٥_٢١٤٣٥٥ - sarah ali.jpg'   prposal.docx\n",
            " ٢٠١٨٠٤٠٨_١٣٤٦٠٦.jpg\t\t   'Ryan Higgins - IELTS Course 2014'\n",
            " AirlinesCodrnaAdult.csv\t   'Study English IELTS Preparation Series'\n",
            "'Colab Notebooks'\t\t   'TED talks+scripts'\n",
            " dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD03caqDhFhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "from  pyspark import SparkConf\n",
        "#conf = SparkConf().setMaster(\"local\").setAppName(\"My app\").set(\"spark.executor.memory\", \"1g\")\n",
        "#sc = SparkContext()\n",
        "# ===============================read from csv==============================================\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from pyspark.sql.types import StructType,StructField,StringType,TimestampType,IntegerType,DoubleType,LongType,FloatType\n",
        "Df5_Schema = StructType([StructField(\"Airline\", StringType(),True),StructField(\"Flight\", DoubleType()),\n",
        "StructField(\"AirportFrom\",StringType()),StructField(\"AirportTo\", StringType()),StructField(\"DayOfWeek\", IntegerType()),\n",
        "StructField(\"Time\",IntegerType()), StructField(\"Length\", IntegerType()),StructField(\"codrna_X1\",DoubleType()),\n",
        "StructField(\"codrna_X2\",DoubleType()),StructField(\"codrna_X3\",DoubleType()),StructField(\"codrna_X4\", DoubleType()),\n",
        "StructField(\"codrna_X5\", DoubleType()),StructField(\"codrna_X6\", DoubleType()),StructField(\"codrna_X7\", DoubleType()),\n",
        "StructField(\"codrna_X8\", DoubleType()),StructField(\"age\", IntegerType()),StructField(\"workclass\", StringType()),\n",
        "StructField(\"fnlwgt\", IntegerType()),StructField(\"education\", StringType()),StructField(\"education-num\", IntegerType()),\n",
        "StructField(\"marital-status\", StringType()),StructField(\"occupation\", StringType()),StructField(\"relationship\", StringType()),\n",
        "StructField(\"race\", StringType()),StructField(\"sex\", StringType()),StructField(\"capitalgain\", IntegerType()),\n",
        "StructField(\"capitalloss\", IntegerType()),StructField(\"hoursperweek\", IntegerType()),StructField(\"native-country\", StringType()),\n",
        "StructField(\"Delay\", IntegerType())])\n",
        "CSV_2007= \"/content/drive/My Drive/AirlinesCodrnaAdult.csv\"\n",
        "df5 =spark.read.schema(Df5_Schema).option(\"header\",\"true\").option(\"mode\", \"DROPMALFORMED\").csv(CSV_2007)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQvods40rPBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = [f.name for f in df5.schema.fields]\n",
        "dataTypes = [f.dataType for f in df5.schema.fields]\n",
        "ls=list(zip(names,dataTypes))\n",
        "str_cols=[]\n",
        "for i in range(len(ls)):\n",
        "     if type(ls[i][1])==StringType and len(df5.select(df5[ls[i][0]]).distinct().collect())<=20:\n",
        "         str_cols.append([i,ls[i][0]]) \n",
        "strings=[]\n",
        "for i in range(len(str_cols)):\n",
        "     strings.append(str_cols[i][1])  \n",
        "\n",
        "#the process of convertiong catogerical columns into numeric is not included in the machine learning operation \n",
        "#it will be left for future improvements !!!ان شاء الله      \n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df5) for column in strings]\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "df6 = pipeline.fit(df5).transform(df5)\n",
        "df6=df6.drop(*strings)\n",
        "df6_pd=df6.toPandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIM7xkiDsRJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "f55f86b9-3081-4d25-c2dd-fe8d671fb847"
      },
      "source": [
        "! pip install category_encoders"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 33.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.3)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.25.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.3)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB96hBgnrflo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import f1_score\n",
        "import category_encoders as ce\n",
        "from sklearn.utils import resample\n",
        "\n",
        "encoder_list = [ce.backward_difference.BackwardDifferenceEncoder,ce.basen.BaseNEncoder,ce.binary.BinaryEncoder,\n",
        "                ce.cat_boost.CatBoostEncoder,ce.helmert.HelmertEncoder,\n",
        "                ce.james_stein.JamesSteinEncoder,ce.one_hot.OneHotEncoder,ce.leave_one_out.LeaveOneOutEncoder,\n",
        "                ce.m_estimate.MEstimateEncoder,ce.ordinal.OrdinalEncoder,\n",
        "                ce.sum_coding.SumEncoder,ce.target_encoder.TargetEncoder,ce.woe.WOEEncoder]\n",
        "#numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "#categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X = df6_pd.drop('Delay', axis=1)\n",
        "y = df6_pd['Delay']\n",
        "#le = preprocessing.LabelEncoder()\n",
        "#label_encoder = le.fit(y)\n",
        "#y = label_encoder.transform(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "block_size=int(round(X_train.shape[0]/len(encoder_list)))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train = [X_train[i:i+n] for i in range(0,X_train.shape[0],n)]\n",
        "list_y_train = [y_train[i:i+n] for i in range(0,y_train.shape[0],n)]\n",
        "list_X_test = [X_test[i:i+n] for i in range(0,X_test.shape[0],n)]\n",
        "list_y_test = [y_test[i:i+n] for i in range(0,y_test.shape[0],n)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "486lmPRrsNS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_numeric_dataset=[]\n",
        "intermidate=[]\n",
        "testing_numeric_dataset=[]\n",
        "for i,encoder in enumerate(encoder_list):\n",
        "  #(encoder(handle_unknown='ignore',cols=['AirportFrom','AirportTo','native-country'])).fit_transform(boot1[i])\n",
        "   training_numeric_dataset.append(encoder_list[i](cols=['AirportFrom','AirportTo','native-country']).fit(list_X_train[i],list_y_train[i]))\n",
        "   intermidate.append((training_numeric_dataset[i]).transform(list_X_train[i],list_y_train[i]))\n",
        "for i in range(len(list_X_test)):\n",
        "    for j,encoder in enumerate(encoder_list):\n",
        "        testing_numeric_dataset.append((training_numeric_dataset[j]).transform(list_X_test[i])) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KMjFk6msm2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx=[]\n",
        "for i in range(len(encoder_list)):\n",
        "    #xx.append([i,min(intermidate[i].columns)] )\n",
        "    xx.append([encoder_list[i],len(intermidate[i].columns)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVO0TqN94DCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "while(1):\n",
        "    a.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XrUFnRFs2ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "block_size=int(round(X_train2.shape[0]/12))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train2 = [X_train2[i:i+n] for i in range(0,X_train2.shape[0],n)]\n",
        "list_y_train2 = [y_train2[i:i+n] for i in range(0,y_train2.shape[0],n)]\n",
        "list_X_test2 = [X_test2[i:i+n] for i in range(0,X_test2.shape[0],n)]\n",
        "list_y_test2 = [y_test2[i:i+n] for i in range(0,y_test2.shape[0],n)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAV2AZs2tE00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "d1cc8400-0225-449c-8b6f-acdf61e8b5ac"
      },
      "source": [
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from heapq import nlargest\n",
        "\n",
        "encoder_list = [ce.backward_difference.BackwardDifferenceEncoder(),ce.basen.BaseNEncoder(),\n",
        "                ce.binary.BinaryEncoder(),ce.cat_boost.CatBoostEncoder(),\n",
        "                ce.helmert.HelmertEncoder(),ce.james_stein.JamesSteinEncoder(),\n",
        "                ce.one_hot.OneHotEncoder(),ce.leave_one_out.LeaveOneOutEncoder()\n",
        "                ,ce.m_estimate.MEstimateEncoder(),ce.ordinal.OrdinalEncoder(),ce.sum_coding.SumEncoder(),\n",
        "                ce.target_encoder.TargetEncoder(),ce.woe.WOEEncoder()]\n",
        "my_dict={}\n",
        "for encoder in encoder_list:\n",
        "    model = Pipeline(steps=[('preprocessor', encoder),('classifier',RandomForestClassifier())])               \n",
        "    modelOpt = model.fit(X_train, y_train)\n",
        "    y_true,y_pred =y_test, model.predict(X_test)\n",
        "    clf2_val_score = roc_auc_score(y_test, modelOpt.predict_proba(X_test)[:, 1])\n",
        "    my_dict[type(encoder)]= [modelOpt.score(X_train, y_train),clf2_val_score]\n",
        "\n",
        "num=int(round(len(encoder_list)*0.5))    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNP-3BVuIy8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z={}\n",
        "for i in range(len(my_dict)):\n",
        "   z[list(my_dict.keys())[i]]=list(my_dict.items())[i][1][0] \n",
        "Highest1 = nlargest(num, z, key = z.get)  \n",
        "\n",
        "zz={}\n",
        "for i in range(len(my_dict)):\n",
        "   zz[list(my_dict.keys())[i]]=list(my_dict.items())[i][1][1] \n",
        "Highest2 = nlargest(num, zz, key = zz.get)  \n",
        "Highest3=list(set(Highest1+Highest2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN3Vj_8VJDhP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4c123df3-e82c-400a-d0e7-48f8822a80bd"
      },
      "source": [
        "Accepted=[]\n",
        "keys = my_dict.keys()\n",
        "for i,each in enumerate(xx):\n",
        " for j,val in enumerate(Highest3): \n",
        "   if xx[i][0]==val and  xx[i][1]==len(X_train.columns)  : \n",
        "           #  Accepted.append(\"%s :%s: %s\" % (i,type(each), my_dict.get(each))) \n",
        "           Accepted.append((i,val))\n",
        "           \n",
        "Accepted        "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, category_encoders.cat_boost.CatBoostEncoder),\n",
              " (5, category_encoders.james_stein.JamesSteinEncoder),\n",
              " (8, category_encoders.m_estimate.MEstimateEncoder),\n",
              " (9, category_encoders.ordinal.OrdinalEncoder),\n",
              " (11, category_encoders.target_encoder.TargetEncoder),\n",
              " (12, category_encoders.woe.WOEEncoder)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AWt8EE1Jl76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "4d07c2bb-c875-43c9-818d-9847afe77c3e"
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import warnings\n",
        "#{'clf': {'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 27}}\n",
        "#max_depth=7, max_features='auto', min_samples_leaf=2,\n",
        "                       #min_samples_split=3,n_estimators=27,random_state = 0))\n",
        "#DecisionTreeClassifier(max_depth=1),n_estimators=30,learning_rate=0.9949357616825972)) \n",
        "#max_depth=2,n_estimators=10,objective='binary:logistic'))\n",
        "pipe1 = make_pipeline(Accepted[0][1](),RandomForestClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](),AdaBoostClassifier())\n",
        "pipe3 = make_pipeline(Accepted[2][1](),XGBClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),ExtraTreesClassifier(criterion= 'entropy'))\n",
        "pipe5 = make_pipeline(Accepted[4][1](),GradientBoostingClassifier())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),GaussianNB())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6],\n",
        "                           meta_classifier=LogisticRegression())\n",
        "\n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"RandomForestClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77     94676\n",
            "           1       0.83      0.78      0.80    120682\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.78      0.79      0.78    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "RandomForestClassifier score: 0.913660\n",
            "Cross-val score: 0.83791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXlNDLdCP4fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "b2f66f91-12bb-4081-adcf-0c3d3aba7043"
      },
      "source": [
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "import numpy as np\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "space = {\n",
        "        'base_estimator': hp.choice('base_estimator',\n",
        "                   [ {\n",
        "                       'model': DecisionTreeClassifier,\n",
        "                       'param':\n",
        "                         {\n",
        "                            'criterion': hp.choice('criterion',[\"gini\", \"entropy\"]),\n",
        "                            'splitter': hp.choice('splitter',[\"best\", \"random\"])\n",
        "                          }\n",
        "                      }]),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
        "    'n_estimators': ho_scope.int(hp.quniform('n_estimators', 5, 30, 1)),\n",
        "    'algorithm': hp.choice('algorithm',[\"SAMME\"])\n",
        "   \n",
        "}               \n",
        "\n",
        "param_hyperopt= {\n",
        "    'RF_clf': \n",
        "    {\n",
        "    'max_depth': ho_scope.int(hp.quniform('max_depth', 5, 7, 1)),\n",
        "    'n_estimators': ho_scope.int(hp.quniform('n_estimators', 5, 30, 1)),\n",
        "    'max_features': hp.choice('max_features', ['auto', 'sqrt']),\n",
        "    'min_samples_split': ho_scope.int(hp.quniform('min_samples_split', 2, 5,1)),\n",
        "    'min_samples_leaf': ho_scope.int(hp.quniform('min_samples_leaf', 2, 5,1))\n",
        "    }\n",
        "    ,\n",
        "    'AdaBoost_clf':\n",
        "    {\n",
        "       'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
        "       'n_estimators': ho_scope.int(hp.quniform('_n_estimators', 5, 30, 1))     \n",
        "        \n",
        "    }\n",
        "} \n",
        "space2 = {\n",
        "    \n",
        "                                                                   \n",
        "       'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
        "       'n_estimators': ho_scope.int(hp.quniform('n_estimators', 5, 30, 1))\n",
        "       \n",
        "   \n",
        "}\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "def f_clf1(params):\n",
        "        model1 =Pipeline(steps=[('encoder',Accepted[0][1]()),('RF_clf', RandomForestClassifier(**params['RF_clf'],random_state=1))])\n",
        "        model2 =Pipeline(steps=[('encoder',Accepted[1][1]()),('AdaBoost_clf', AdaBoostClassifier(**params['AdaBoost_clf'],random_state=1))])\n",
        "        sclf2 = StackingClassifier(classifiers=[model1,model2],meta_classifier=LogisticRegression())\n",
        "        return sclf2\n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf1(params)\n",
        "    #clf = RandomForestClassifier(**params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "#best_param = fmin(objective_function,param_hyperopt,algo=tpe.suggest,max_evals=25,trials=trials,rstate= np.random.RandomState(1))\n",
        "#loss = [x['result']['loss'] for x in trials.trials]\n",
        "    \n",
        "#best_param_values = [x for x in best_param.values()]\n",
        "best_clf3 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                 param_hyperopt, algo=tpe.suggest, max_evals=25,trials=trials, rstate=np.random.RandomState(1))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 8/25 [13:47<29:14, 103.19s/it, best loss: -0.7679581190173854]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 12/25 [19:56<21:27, 99.07s/it, best loss: -0.7825590671715407]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 14/25 [23:16<17:49, 97.25s/it, best loss: -0.7825590671715407] "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 15/25 [25:00<16:32, 99.21s/it, best loss: -0.7825590671715407]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 20/25 [32:51<07:42, 92.44s/it, best loss: -0.7825590671715407]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 24/25 [39:57<01:45, 105.44s/it, best loss: -0.7825590671715407]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 25/25 [40:42<00:00, 87.41s/it, best loss: -0.7825590671715407] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhwS0ZCQpQCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwUDSajnoWz8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "88938e93-fc1e-4d47-c9b8-b46f4aabec6b"
      },
      "source": [
        "model_save_name = 'classifier.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-ac506fda1167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'classifier.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mF\"/content/gdrive/My Drive/{model_save_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'state_dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuYcc4nnZkp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d41cf336-f9b9-4921-c2d8-56629db7acd7"
      },
      "source": [
        "from hyperopt import fmin, hp, tpe, Trials, space_eval\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "clf1 = f_clf1(space_eval(param_hyperopt, best_clf3)).fit(X_train, y_train)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf1_val_score = roc_auc_score(y_test, clf1.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf1_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt, best_clf3))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-val score: 0.78256; validation score: 0.78166\n",
            "Best parameters:\n",
            "{'AdaBoost_clf': {'learning_rate': 0.8051561754791255, 'n_estimators': 28}, 'RF_clf': {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 21}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyBAgEvxakfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b82d30a2-80bf-4dd6-c7bc-36d44c6485ba"
      },
      "source": [
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"RandomForestClassifier score: %f\" % clf1.score(X_train, y_train))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77     94676\n",
            "           1       0.83      0.78      0.80    120682\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.78      0.79      0.78    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "RandomForestClassifier score: 0.731440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYTFgTbsbMmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "13701896-f9ea-4707-c543-e1927773389d",
        "id": "GoT4rgyqbNPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import warnings\n",
        "#{'clf': {'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 27}}\n",
        "#max_depth=7, max_features='auto', min_samples_leaf=2,\n",
        "                       #min_samples_split=3,n_estimators=27,random_state = 0))\n",
        "#DecisionTreeClassifier(max_depth=1),n_estimators=30,learning_rate=0.9949357616825972)) \n",
        "#max_depth=2,n_estimators=10,objective='binary:logistic'))\n",
        "#{'AdaBoost_clf': {'learning_rate': 0.8051561754791255, 'n_estimators': 28},\n",
        "# 'RF_clf': {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 21}}\n",
        "pipe1 = make_pipeline(Accepted[0][1](),RandomForestClassifier(n_estimators= 21,max_depth= 7,min_samples_split= 4,min_samples_leaf= 4,max_features= 'sqrt'))\n",
        "pipe2 = make_pipeline(Accepted[1][1](),AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=28,learning_rate=0.8051561754791255)) \n",
        "pipe3 = make_pipeline(Accepted[2][1](),XGBClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),ExtraTreesClassifier(criterion= 'entropy'))\n",
        "pipe5 = make_pipeline(Accepted[4][1](),GradientBoostingClassifier())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),GaussianNB())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6],\n",
        "                           meta_classifier=LogisticRegression())\n",
        "\n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"RandomForestClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77     94676\n",
            "           1       0.83      0.78      0.80    120682\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.78      0.79      0.78    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "RandomForestClassifier score: 0.913660\n",
            "Cross-val score: 0.84756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APRcNVp5qCWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7jAi0SyqJ6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Y91o41qbr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "88b2d411-5ff7-40f4-e923-9bed44881a11"
      },
      "source": [
        "model.save('model.h5')\n",
        "model_file = drive.CreateFile({'title' : 'model.h5'})\n",
        "model_file.SetContentFile('model.h5')\n",
        "model_file.Upload()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-2b04a008dfbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'title'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUpload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'save'"
          ]
        }
      ]
    }
  ]
}