{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarah127/udacity-data-analysis-with-r/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgzROkNIH4do",
        "colab_type": "code",
        "outputId": "86638391-db78-4795-d2d8-49f9ed79216e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAV8exRXypkt",
        "colab_type": "code",
        "outputId": "4af3c89d-3116-4eea-cecb-c86f9d4b9a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanizeii\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=dcbdf58874a9b33cc50fd72b4d90d4ef62c79ba4530bea212bccdb51bba3ad28\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement humanizeii (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for humanizeii\u001b[0m\n",
            "Gen RAM Free: 26.4 GB  | Proc size: 156.9 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1R6gDJMND6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP8zG65mYk86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD03caqDhFhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "from  pyspark import SparkConf\n",
        "#conf = SparkConf().setMaster(\"local\").setAppName(\"My app\").set(\"spark.executor.memory\", \"1g\")\n",
        "#sc = SparkContext()\n",
        "# ===============================read from csv==============================================\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from pyspark.sql.types import StructType,StructField,StringType,TimestampType,IntegerType,DoubleType,LongType,FloatType\n",
        "Df5_Schema = StructType([StructField(\"Airline\", StringType(),True),StructField(\"Flight\", DoubleType()),\n",
        "StructField(\"AirportFrom\",StringType()),StructField(\"AirportTo\", StringType()),StructField(\"DayOfWeek\", IntegerType()),\n",
        "StructField(\"Time\",IntegerType()), StructField(\"Length\", IntegerType()),StructField(\"codrna_X1\",DoubleType()),\n",
        "StructField(\"codrna_X2\",DoubleType()),StructField(\"codrna_X3\",DoubleType()),StructField(\"codrna_X4\", DoubleType()),\n",
        "StructField(\"codrna_X5\", DoubleType()),StructField(\"codrna_X6\", DoubleType()),StructField(\"codrna_X7\", DoubleType()),\n",
        "StructField(\"codrna_X8\", DoubleType()),StructField(\"age\", IntegerType()),StructField(\"workclass\", StringType()),\n",
        "StructField(\"fnlwgt\", IntegerType()),StructField(\"education\", StringType()),StructField(\"education-num\", IntegerType()),\n",
        "StructField(\"marital-status\", StringType()),StructField(\"occupation\", StringType()),StructField(\"relationship\", StringType()),\n",
        "StructField(\"race\", StringType()),StructField(\"sex\", StringType()),StructField(\"capitalgain\", IntegerType()),\n",
        "StructField(\"capitalloss\", IntegerType()),StructField(\"hoursperweek\", IntegerType()),StructField(\"native-country\", StringType()),\n",
        "StructField(\"Delay\", IntegerType())])\n",
        "CSV_2007= '/content/drive/My Drive/AirlinesCodrnaAdult.csv'\n",
        "df5 =spark.read.schema(Df5_Schema).option(\"header\",\"true\").option(\"mode\", \"DROPMALFORMED\").csv(CSV_2007)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQvods40rPBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = [f.name for f in df5.schema.fields]\n",
        "dataTypes = [f.dataType for f in df5.schema.fields]\n",
        "ls=list(zip(names,dataTypes))\n",
        "str_cols=[]\n",
        "for i in range(len(ls)):\n",
        "     if type(ls[i][1])==StringType and len(df5.select(df5[ls[i][0]]).distinct().collect())<=20:\n",
        "         str_cols.append([i,ls[i][0]]) \n",
        "strings=[]\n",
        "for i in range(len(str_cols)):\n",
        "     strings.append(str_cols[i][1])  \n",
        "\n",
        "#the process of convertiong catogerical columns into numeric is not included in the machine learning operation \n",
        "#it will be left for future improvements !!!ان شاء الله      \n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df5) for column in strings]\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "df6 = pipeline.fit(df5).transform(df5)\n",
        "df6=df6.drop(*strings)\n",
        "df6_pd=df6.toPandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIM7xkiDsRJI",
        "colab_type": "code",
        "outputId": "f7ab6ce9-80dc-4a1f-b8d9-a68853f395c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "! pip install category_encoders"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.17.5)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.25.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB96hBgnrflo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import f1_score\n",
        "import category_encoders as ce\n",
        "from sklearn.utils import resample\n",
        "\n",
        "encoder_list = [ce.backward_difference.BackwardDifferenceEncoder,ce.basen.BaseNEncoder,ce.binary.BinaryEncoder,\n",
        "                ce.cat_boost.CatBoostEncoder,ce.helmert.HelmertEncoder,\n",
        "                ce.james_stein.JamesSteinEncoder,ce.one_hot.OneHotEncoder,ce.leave_one_out.LeaveOneOutEncoder,\n",
        "                ce.m_estimate.MEstimateEncoder,ce.ordinal.OrdinalEncoder,\n",
        "                ce.sum_coding.SumEncoder,ce.target_encoder.TargetEncoder,ce.woe.WOEEncoder]\n",
        "#numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "#categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X = df6_pd.drop('Delay', axis=1)\n",
        "y = df6_pd['Delay']\n",
        "#le = preprocessing.LabelEncoder()\n",
        "#label_encoder = le.fit(y)\n",
        "#y = label_encoder.transform(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "block_size=int(round(X_train.shape[0]/len(encoder_list)))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train = [X_train[i:i+n] for i in range(0,X_train.shape[0],n)]\n",
        "list_y_train = [y_train[i:i+n] for i in range(0,y_train.shape[0],n)]\n",
        "list_X_test = [X_test[i:i+n] for i in range(0,X_test.shape[0],n)]\n",
        "list_y_test = [y_test[i:i+n] for i in range(0,y_test.shape[0],n)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "486lmPRrsNS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_numeric_dataset=[]\n",
        "intermidate=[]\n",
        "testing_numeric_dataset=[]\n",
        "for i,encoder in enumerate(encoder_list):\n",
        "  #(encoder(handle_unknown='ignore',cols=['AirportFrom','AirportTo','native-country'])).fit_transform(boot1[i])\n",
        "   training_numeric_dataset.append(encoder_list[i](cols=['AirportFrom','AirportTo','native-country']).fit(list_X_train[i],list_y_train[i]))\n",
        "   intermidate.append((training_numeric_dataset[i]).transform(list_X_train[i],list_y_train[i]))\n",
        "for i in range(len(list_X_test)):\n",
        "    for j,encoder in enumerate(encoder_list):\n",
        "        testing_numeric_dataset.append((training_numeric_dataset[j]).transform(list_X_test[i])) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KMjFk6msm2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx=[]\n",
        "for i in range(len(encoder_list)):\n",
        "    #xx.append([i,min(intermidate[i].columns)] )\n",
        "    xx.append([encoder_list[i],len(intermidate[i].columns)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XrUFnRFs2ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "block_size=int(round(X_train2.shape[0]/12))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train2 = [X_train2[i:i+n] for i in range(0,X_train2.shape[0],n)]\n",
        "list_y_train2 = [y_train2[i:i+n] for i in range(0,y_train2.shape[0],n)]\n",
        "list_X_test2 = [X_test2[i:i+n] for i in range(0,X_test2.shape[0],n)]\n",
        "list_y_test2 = [y_test2[i:i+n] for i in range(0,y_test2.shape[0],n)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3BlGKV4pypi",
        "colab_type": "code",
        "outputId": "8c2e729c-a72d-4eee-e6b2-6923bad36e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install unittest2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unittest2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/20/7f0f433060a962200b7272b8c12ba90ef5b903e218174301d0abfd523813/unittest2-1.1.0-py2.py3-none-any.whl (96kB)\n",
            "\r\u001b[K     |███▍                            | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.8MB/s \n",
            "\u001b[?25hCollecting traceback2\n",
            "  Downloading https://files.pythonhosted.org/packages/17/0a/6ac05a3723017a967193456a2efa0aa9ac4b51456891af1e2353bb9de21e/traceback2-1.4.0-py2.py3-none-any.whl\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.4 in /usr/local/lib/python3.6/dist-packages (from unittest2) (1.12.0)\n",
            "Collecting linecache2\n",
            "  Downloading https://files.pythonhosted.org/packages/c7/a3/c5da2a44c85bfbb6eebcfc1dde24933f8704441b98fdde6528f4831757a6/linecache2-1.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: linecache2, traceback2, argparse, unittest2\n",
            "Successfully installed argparse-1.4.0 linecache2-1.0.0 traceback2-1.4.0 unittest2-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n5nuzhaSUqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "import doctest\n",
        "import os\n",
        "import warnings\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import category_encoders.tests.helpers as th\n",
        "from sklearn.utils.estimator_checks import check_transformer_general, check_transformers_unfitted\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from unittest2 import TestSuite, TextTestRunner, TestCase  # or `from unittest import ...` if on Python 3.4+\n",
        "from copy import deepcopy\n",
        "class TestEncoders(TestCase):\n",
        "  def test_handle_missing_return_nan_train(self):\n",
        "        X = X2 \n",
        "        y = y2 \n",
        "\n",
        "        for encoder_name in (set(ce.__all__) - {'HashingEncoder'}):  # HashingEncoder supports new values by design -> excluded\n",
        "            with self.subTest(encoder_name=encoder_name):\n",
        "                enc = getattr(encoders, encoder_name)(handle_missing='return_nan')\n",
        "                result = enc.fit_transform(X, y).iloc[2, :]\n",
        "\n",
        "                if len(result) == 1:\n",
        "                    self.assertTrue(result.isnull().all())\n",
        "                else:\n",
        "                    self.assertTrue(result[1:].isnull().all())\n",
        "\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YII4QCuC8vL9",
        "colab_type": "code",
        "outputId": "d415cac4-9e76-4ca4-e3bf-94c3ebaaf751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!pip install packyou"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting packyou\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/88/d2d03add639909868eba9290282172b7ee3067d19e7050ce9b2865f2bf77/packyou-0.1.5.tar.gz\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/8c/4543981439d23c4ff65b2e62dddd767ebc84a8e664a9b67e840d1e2730d3/GitPython-3.0.5-py3-none-any.whl (455kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from packyou) (2.21.0)\n",
            "Collecting gitdb2>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->packyou) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->packyou) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->packyou) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->packyou) (2019.11.28)\n",
            "Collecting smmap2>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: packyou\n",
            "  Building wheel for packyou (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for packyou: filename=packyou-0.1.5-py2.py3-none-any.whl size=7167 sha256=660c578d77d02e67566ddc8d7f66ee343984cffb4c63516f8d3dfeac3b515173\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/9e/e2/b8e8fe8102a23560c8f2dfba847832ea0187706bb8c2001584\n",
            "Successfully built packyou\n",
            "Installing collected packages: smmap2, gitdb2, gitpython, packyou\n",
            "Successfully installed gitdb2-2.0.6 gitpython-3.0.5 packyou-0.1.5 smmap2-2.0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkW0XBx_9X1a",
        "colab_type": "code",
        "outputId": "d3620693-b414-4c49-8a22-13ef76c8e059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import category_encoders as ce\n",
        "from packyou.github.category_encoders.tests import test_encoders as tr\n",
        "\n",
        "aa=tr.TestEncoders.test_handle_unknown_return_nan\n",
        "aa"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-889f95cfc0a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackyou\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_encoders\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTestEncoders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestCase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/unittest2/case.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, methodName)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mtestMethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethodName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             raise ValueError(\"no such test method in %s: %s\" % \\\n",
            "\u001b[0;31mTypeError\u001b[0m: getattr(): attribute name must be string"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKoLkxiSj0oC",
        "colab_type": "code",
        "outputId": "bd48368a-8989-4a1f-cae4-7f82a0e99b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "for encoder_name in (set(ce.__all__)):\n",
        "  print(encoder_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-194b2f525319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mencoder_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__all__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '__name__'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8tdFVyTqhaT",
        "colab_type": "code",
        "outputId": "22f7e92f-482d-4c84-8b76-766c724f0b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "\n",
        "import tests as tt\n",
        "import category_encoders.tests.helpers as th\n",
        "th.verify_numeric()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-c38164e65fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_encoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_encoders' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe2dD4wB0LLh",
        "colab_type": "code",
        "outputId": "94fe4b25-900f-4d79-b1ef-23b7f1a707e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "type(ce.BackwardDifferenceEncoder()),ce.__all__[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(category_encoders.backward_difference.BackwardDifferenceEncoder,\n",
              " 'BackwardDifferenceEncoder')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az1iDyv80fCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr5MaAHkvxv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "names_encoders=[]\n",
        "for i, _ in enumerate(ce.__all__):\n",
        "    names_encoders.append(str(ce.__all__[i+1])+\"encoder\")  \n",
        "\n",
        "dict = {}\n",
        "for name, Accepted_val in zip(names, AcceptedR ):\n",
        "    dict[name] =make_pipeline(Accepted_val(),fiv[AcceptedR.index(Accepted_val)]['classifier'](**fiv[AcceptedR.index(Accepted_val)]['parameters']))\n",
        "\n",
        "encoder = ce.BackwardDifferenceEncoder()\n",
        "encoder = ce.BaseNEncoder()\n",
        "encoder = ce.BinaryEncoder()\n",
        "encoder = ce.CatBoostEncoder()\n",
        "encoder = ce.HashingEncoder()\n",
        "encoder = ce.HelmertEncoder()\n",
        "encoder = ce.JamesSteinEncoder()\n",
        "encoder = ce.LeaveOneOutEncoder()\n",
        "encoder = ce.MEstimateEncoder()\n",
        "encoder = ce.OneHotEncoder()\n",
        "encoder = ce.OrdinalEncoder()\n",
        "encoder = ce.SumEncoder()\n",
        "encoder = ce.PolynomialEncoder()\n",
        "encoder = ce.TargetEncoder()\n",
        "encoder = ce.WOEEncoder()\n",
        "\n",
        "encoder.fit(X, y)\n",
        "X_cleaned = encoder.transform(X_dirty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAV2AZs2tE00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from heapq import nlargest\n",
        "\n",
        "encoder_list = [ce.backward_difference.BackwardDifferenceEncoder(),ce.basen.BaseNEncoder(),\n",
        "                ce.binary.BinaryEncoder(),ce.cat_boost.CatBoostEncoder(),\n",
        "                ce.helmert.HelmertEncoder(),ce.james_stein.JamesSteinEncoder(),\n",
        "                ce.one_hot.OneHotEncoder(),ce.leave_one_out.LeaveOneOutEncoder()\n",
        "                ,ce.m_estimate.MEstimateEncoder(),ce.ordinal.OrdinalEncoder(),ce.sum_coding.SumEncoder(),\n",
        "                ce.target_encoder.TargetEncoder(),ce.woe.WOEEncoder()]\n",
        "my_dict={}\n",
        "for encoder in encoder_list:\n",
        "    model = Pipeline(steps=[('preprocessor', encoder),('classifier',RandomForestClassifier())])               \n",
        "    modelOpt = model.fit(X_train, y_train)\n",
        "    y_true,y_pred =y_test, model.predict(X_test)\n",
        "    clf2_val_score = roc_auc_score(y_test, modelOpt.predict_proba(X_test)[:, 1])\n",
        "    my_dict[type(encoder)]= [modelOpt.score(X_train, y_train),clf2_val_score]\n",
        "\n",
        "num=int(round(len(encoder_list)*0.5))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZZ84ICV1Nu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNP-3BVuIy8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z={}\n",
        "for i in range(len(my_dict)):\n",
        "   z[list(my_dict.keys())[i]]=list(my_dict.items())[i][1][0] \n",
        "Highest1 = nlargest(num, z, key = z.get)  \n",
        "\n",
        "zz={}\n",
        "for i in range(len(my_dict)):\n",
        "   zz[list(my_dict.keys())[i]]=list(my_dict.items())[i][1][1] \n",
        "Highest2 = nlargest(num, zz, key = zz.get)  \n",
        "Highest3=list(set(Highest1+Highest2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBykn8gEJFqf",
        "colab_type": "code",
        "outputId": "f8f4089b-c464-4811-a3dd-c336139ca463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "Highest3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[category_encoders.james_stein.JamesSteinEncoder,\n",
              " category_encoders.one_hot.OneHotEncoder,\n",
              " category_encoders.cat_boost.CatBoostEncoder,\n",
              " category_encoders.m_estimate.MEstimateEncoder,\n",
              " category_encoders.woe.WOEEncoder,\n",
              " category_encoders.target_encoder.TargetEncoder,\n",
              " category_encoders.backward_difference.BackwardDifferenceEncoder,\n",
              " category_encoders.ordinal.OrdinalEncoder,\n",
              " category_encoders.sum_coding.SumEncoder]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_4erO4hGjKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ww=list(zz.keys())\n",
        "rr=[]\n",
        "for i in range(len(ww)):\n",
        "  rr.append(ww[i].__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbPC2NsLI7TC",
        "colab_type": "code",
        "outputId": "2982ce5c-7084-45e2-f6b3-981528e7e2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "zz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{category_encoders.backward_difference.BackwardDifferenceEncoder: 0.8730051961069416,\n",
              " category_encoders.basen.BaseNEncoder: 0.879814200606559,\n",
              " category_encoders.binary.BinaryEncoder: 0.8799906362700769,\n",
              " category_encoders.cat_boost.CatBoostEncoder: 0.8973157657670824,\n",
              " category_encoders.helmert.HelmertEncoder: 0.8728729152360952,\n",
              " category_encoders.james_stein.JamesSteinEncoder: 0.8817666736268035,\n",
              " category_encoders.leave_one_out.LeaveOneOutEncoder: 0.5952200320537696,\n",
              " category_encoders.m_estimate.MEstimateEncoder: 0.8820850298469992,\n",
              " category_encoders.one_hot.OneHotEncoder: 0.874702704696578,\n",
              " category_encoders.ordinal.OrdinalEncoder: 0.8820258734746476,\n",
              " category_encoders.sum_coding.SumEncoder: 0.8751009023379546,\n",
              " category_encoders.target_encoder.TargetEncoder: 0.8821030638913904,\n",
              " category_encoders.woe.WOEEncoder: 0.8820140599818116}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN3Vj_8VJDhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Accepted=[]\n",
        "keys = my_dict.keys()\n",
        "for i,each in enumerate(xx):\n",
        " for j,val in enumerate(Highest3): \n",
        "   if xx[i][0]==val and  xx[i][1]==len(X_train.columns)  : \n",
        "           #  Accepted.append(\"%s :%s: %s\" % (i,type(each), my_dict.get(each))) \n",
        "           Accepted.append((i,val))\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20rpUs7-EfrN",
        "colab_type": "code",
        "outputId": "8127778c-7029-41e7-b862-b8ceda436508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "Accepted      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, category_encoders.cat_boost.CatBoostEncoder),\n",
              " (5, category_encoders.james_stein.JamesSteinEncoder),\n",
              " (8, category_encoders.m_estimate.MEstimateEncoder),\n",
              " (9, category_encoders.ordinal.OrdinalEncoder),\n",
              " (11, category_encoders.target_encoder.TargetEncoder),\n",
              " (12, category_encoders.woe.WOEEncoder)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AWt8EE1Jl76",
        "colab_type": "code",
        "outputId": "fc230191-4d00-4507-d988-385ebfee5ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "pipe1 = make_pipeline(Accepted[0][1](),RandomForestClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](), KNeighborsClassifier())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2], meta_classifier=LogisticRegression())\n",
        "\n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P6auG6ahBf-",
        "colab_type": "code",
        "outputId": "7a18e71f-32ef-4682-a556-3217604bdeae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())\n",
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "pipe5 = make_pipeline(Accepted[4][1](),AdaBoostClassifier())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6], meta_classifier=LogisticRegression())\n",
        "\n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.78      0.77     94498\n",
            "           1       0.82      0.80      0.81    120860\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.79      0.79      0.79    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "StackingClassifier score: 0.913806\n",
            "Cross-val score: 0.86648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZZsULnlhHEM",
        "colab_type": "code",
        "outputId": "3e9f3cbc-91bc-45f7-ab48-182853c9ecd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())\n",
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "pipe5 = make_pipeline(Accepted[4][1](),AdaBoostClassifier())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4], meta_classifier=LogisticRegression())\n",
        "\n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))\n",
        "res4=[]\n",
        "res4.append([model2.score(X_train, y_train),clf2_val_score])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.78      0.77     95019\n",
            "           1       0.82      0.80      0.81    120339\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.79      0.79      0.79    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "StackingClassifier score: 0.913694\n",
            "Cross-val score: 0.85805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAC_6RpSykOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6df1afc0-8475-4d74-92b1-55ff4c8278a4"
      },
      "source": [
        "res4"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.913693710008451, 0.858050828200362]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuYcc4nnZkp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hyperopt import fmin, hp, tpe, Trials, space_eval\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "clf1 = f_clf1(space_eval(param_hyperopt, best_clf3)).fit(X_train, y_train)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf1_val_score = roc_auc_score(y_test, clf1.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf1_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt, best_clf3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyBAgEvxakfh",
        "colab_type": "code",
        "outputId": "b82d30a2-80bf-4dd6-c7bc-36d44c6485ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"RandomForestClassifier score: %f\" % clf1.score(X_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77     94676\n",
            "           1       0.83      0.78      0.80    120682\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.78      0.79      0.78    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "RandomForestClassifier score: 0.731440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "13701896-f9ea-4707-c543-e1927773389d",
        "id": "GoT4rgyqbNPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import warnings\n",
        "pipe1 = make_pipeline(Accepted[0][1](),RandomForestClassifier(n_estimators= 21,\n",
        "                max_depth= 7,min_samples_split= 4,min_samples_leaf= 4,max_features= 'sqrt'))\n",
        "pipe2 = make_pipeline(Accepted[1][1](),AdaBoostClassifier(DecisionTreeClassifier(max_depth=1)\n",
        ",n_estimators=28,learning_rate=0.8051561754791255)) \n",
        "pipe3 = make_pipeline(Accepted[2][1](),XGBClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),ExtraTreesClassifier(criterion= 'entropy'))\n",
        "pipe5 = make_pipeline(Accepted[4][1](),GradientBoostingClassifier())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),GaussianNB())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6],\n",
        "                           meta_classifier=LogisticRegression())\n",
        "\n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"RandomForestClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77     94676\n",
            "           1       0.83      0.78      0.80    120682\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.78      0.79      0.78    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "RandomForestClassifier score: 0.913660\n",
            "Cross-val score: 0.84756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APRcNVp5qCWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7jAi0SyqJ6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGO4odcgVfWt",
        "colab_type": "code",
        "outputId": "c471e14c-016b-496c-bcf1-3b5fd2abcdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
        "# now you can import normally from ensemble\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import lightgbm as lgb\n",
        "# load dataset\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "#le = preprocessing.LabelEncoder()\n",
        "#label_encoder = le.fit(y)\n",
        "#y = label_encoder.transform(y)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2)\n",
        "block_size=int(round(X_train2.shape[0]/13))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train = [X_train2[i:i+n] for i in range(0,X_train2.shape[0],n)]\n",
        "list_y_train = [y_train2[i:i+n] for i in range(0,y_train2.shape[0],n)]\n",
        "list_X_test = [X_test2[i:i+n] for i in range(0,X_test2.shape[0],n)]\n",
        "list_y_test = [y_test2[i:i+n] for i in range(0,y_test2.shape[0],n)]\n",
        "test_data = lgb.Dataset(list_X_test[0], label=list_y_test[0])\n",
        "# Build the encoder\n",
        "# prepare configuration for cross validation test harness\n",
        "seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "parameters = {\n",
        "    'application': 'binary','objective': 'binary','metric': 'auc','is_unbalance': 'true',\n",
        "    'boosting': 'gbdt','num_leaves': 31,'feature_fraction': 0.5,'bagging_fraction': 0.5,\n",
        "    'bagging_freq': 20,'learning_rate': 0.05,'verbose': 0\n",
        "}\n",
        "fit_params={\"early_stopping_rounds\":10,\"eval_metric\" : 'auc',\"eval_set\" : [(X_test,y_test)],\n",
        "            'eval_names': ['valid'],'verbose': 100,\n",
        "            'feature_name': 'auto', # that's actually the default\n",
        "            'categorical_feature': 'auto' # that's actually the default\n",
        "           }\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                               ('RandomForestClassifier',RandomForestClassifier(n_estimators=20))])) \n",
        "                               .fit(list_X_train[0], list_y_train[0])) \n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                               ('AdaBoostClassifier',AdaBoostClassifier(n_estimators=25))]))\n",
        "                               .fit(list_X_train[1], list_y_train[1])) \n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                       ('HistGradientBoostingClassifier', HistGradientBoostingClassifier())])).fit(list_X_train[2], list_y_train[2]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                              ('XGBClassifier',XGBClassifier(max_depth=2,n_estimators=10,objective='binary:logistic'))]))\n",
        "                            .fit(list_X_train[3], list_y_train[3]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                              ('ExtraTreesClassifier',ExtraTreesClassifier(criterion= 'entropy'))]))\n",
        "                               .fit(list_X_train[4], list_y_train[4]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "              ('lightgbm',lgb.LGBMClassifier(n_estimators=5 , num_leaves= 15,\n",
        "           max_depth=-1,colsample_bytree=0.9,subsample=0.9,learning_rate=0.1))])).fit(list_X_train[5], list_y_train[5]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('LDA', LinearDiscriminantAnalysis())])).fit(list_X_train[6], list_y_train[6]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('MLPClassifier',\n",
        "                      MLPClassifier(hidden_layer_sizes=(50,30,30), max_iter=5, alpha=0.0001,\n",
        "                     solver='sgd', verbose=10,  random_state=1))])).fit(list_X_train[7], list_y_train[7]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('LR', LogisticRegression())])).fit(list_X_train[8], list_y_train[8]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('QDA', QuadraticDiscriminantAnalysis())])).fit(list_X_train[9], list_y_train[9]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                      ('CART', DecisionTreeClassifier())])).fit(list_X_train[10], list_y_train[10]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                       ('NB', GaussianNB())])).fit(list_X_train[11], list_y_train[11]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "   ('BaggingClassifier',BaggingClassifier( DecisionTreeClassifier(random_state=42), n_estimators=100,\n",
        "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42,oob_score = True))])).fit(list_X_train[12], list_y_train[12]))\n",
        "\n",
        "\n",
        "   \n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in enumerate(models):\n",
        "    #kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "    print('1')\n",
        "    cv_results = model_selection.cross_val_score(model, list_X_train[name], \n",
        "                            list_y_train[name], cv=5, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 85383943853.59269714\n",
            "Iteration 3, loss = 85383658564.95115662\n",
            "Iteration 4, loss = 85383373277.26551819\n",
            "Iteration 5, loss = 85383087990.53366089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0: 0.779835 (0.002477)\n",
            "1\n",
            "1: 0.744235 (0.009259)\n",
            "1\n",
            "2: 0.796752 (0.003469)\n",
            "1\n",
            "3: 0.709193 (0.003933)\n",
            "1\n",
            "4: 0.782069 (0.002215)\n",
            "1\n",
            "5: 0.747374 (0.009891)\n",
            "1\n",
            "6: 0.746695 (0.003495)\n",
            "1\n",
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 4790323417.33360863\n",
            "Iteration 3, loss = 4790309852.02261639\n",
            "Iteration 4, loss = 4790296286.75336266\n",
            "Iteration 5, loss = 4790282721.52347660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 2572473644.40217018\n",
            "Iteration 3, loss = 2572466359.62970781\n",
            "Iteration 4, loss = 2572459074.88136768\n",
            "Iteration 5, loss = 2572451790.15463781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 894225439.85077286\n",
            "Iteration 3, loss = 894222907.56550980\n",
            "Iteration 4, loss = 894220375.29099321\n",
            "Iteration 5, loss = 894217843.02462900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 1565378826.54866886\n",
            "Iteration 3, loss = 1565374393.68161130\n",
            "Iteration 4, loss = 1565369960.83070683\n",
            "Iteration 5, loss = 1565365527.99336481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 44774704532.75563049\n",
            "Iteration 3, loss = 44774578417.50790405\n",
            "Iteration 4, loss = 44774452302.61566162\n",
            "Iteration 5, loss = 44774326188.07955933\n",
            "7: 0.558025 (0.000034)\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8: 0.628154 (0.013295)\n",
            "1\n",
            "9: 0.722715 (0.003152)\n",
            "1\n",
            "10: 0.747178 (0.002753)\n",
            "1\n",
            "11: 0.615749 (0.003699)\n",
            "1\n",
            "12: 0.749034 (0.003251)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CseDCsH_WonM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ff=[]\n",
        "for i in range(len(results)):\n",
        "  ff.append(results[i].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9t2n4tOLvpu",
        "colab_type": "code",
        "outputId": "e61540aa-e2f8-4bcb-d92d-a47523cc5f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "aa=list(range(0,13))\n",
        "plt.figure(figsize=(6,6))\n",
        "data = pd.DataFrame({\"xlabel_values\": gg,\n",
        "                     \"x\": aa,\n",
        "                     \"y\": ff}\n",
        "                    )\n",
        "sns.catplot(x=\"x\",  y=\"y\", data=data,kind='box' , hue=\"xlabel_values\",height=4, aspect=2)\n",
        "ax.set(ylim=(0.50, 0.85))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.5, 0.85)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvYAAAEUCAYAAABAhXI0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 785.6x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiQ6AuRL_Add",
        "colab_type": "code",
        "outputId": "50cf8053-4858-47bb-afa1-437d991d8971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "gg=[]\n",
        "for i in range(len(models)):\n",
        "  gg.append(type(models[i][1]).__name__)\n",
        "aa=list(range(0,13))\n",
        "plt.figure(figsize=(9,8))\n",
        "data = pd.DataFrame({\"xlabel_values\": gg,\"x\": aa,\"y\": ff} )\n",
        "ax = sns.boxplot(x=\"x\",y= \"y\",hue=\"xlabel_values\",data=data)\n",
        "ax = sns.boxplot(data=results)\n",
        "aa=list(range(0,13))\n",
        "#sns.utils.axlabel(xlabel=aa,hue=gg, ylabel=aa, fontsize=9)\n",
        "#ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
        "ax.set(xlabel='classifier', ylabel='Acracy', title='Initial Perfered Classifiers')\n",
        "ax.set(ylim=(0.50, 0.85))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f22f6e3b3fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"xlabel_values\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xlabel_values\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ff' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x576 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs_JuIdQzwIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80f04454-1d27-4113-fbef-8c65d1be47fa"
      },
      "source": [
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
        "# now you can import normally from ensemble\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import lightgbm as lgb\n",
        "# load dataset\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "#le = preprocessing.LabelEncoder()\n",
        "#label_encoder = le.fit(y)\n",
        "#y = label_encoder.transform(y)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2)\n",
        "block_size=int(round(X_train2.shape[0]/13))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train = [X_train2[i:i+n] for i in range(0,X_train2.shape[0],n)]\n",
        "list_y_train = [y_train2[i:i+n] for i in range(0,y_train2.shape[0],n)]\n",
        "list_X_test = [X_test2[i:i+n] for i in range(0,X_test2.shape[0],n)]\n",
        "list_y_test = [y_test2[i:i+n] for i in range(0,y_test2.shape[0],n)]\n",
        "test_data = lgb.Dataset(list_X_test[0], label=list_y_test[0])\n",
        "# Build the encoder\n",
        "# prepare configuration for cross validation test harness\n",
        "seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "parameters = {\n",
        "    'application': 'binary','objective': 'binary','metric': 'auc','is_unbalance': 'true',\n",
        "    'boosting': 'gbdt','num_leaves': 31,'feature_fraction': 0.5,'bagging_fraction': 0.5,\n",
        "    'bagging_freq': 20,'learning_rate': 0.05,'verbose': 0\n",
        "}\n",
        "fit_params={\"early_stopping_rounds\":10,\"eval_metric\" : 'auc',\"eval_set\" : [(X_test,y_test)],\n",
        "            'eval_names': ['valid'],'verbose': 100,\n",
        "            'feature_name': 'auto', # that's actually the default\n",
        "            'categorical_feature': 'auto' # that's actually the default\n",
        "           }\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                               ('RandomForestClassifier',RandomForestClassifier(n_estimators=20))])) \n",
        "                               .fit(list_X_train[0], list_y_train[0])) \n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                               ('AdaBoostClassifier',AdaBoostClassifier(n_estimators=25))]))\n",
        "                               .fit(list_X_train[1], list_y_train[1])) \n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                       ('HistGradientBoostingClassifier', HistGradientBoostingClassifier())])).fit(list_X_train[2], list_y_train[2]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                              ('XGBClassifier',XGBClassifier(max_depth=2,n_estimators=10,objective='binary:logistic'))]))\n",
        "                            .fit(list_X_train[3], list_y_train[3]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                              ('ExtraTreesClassifier',ExtraTreesClassifier(criterion= 'entropy'))]))\n",
        "                               .fit(list_X_train[4], list_y_train[4]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "              ('lightgbm',lgb.LGBMClassifier(n_estimators=5 , num_leaves= 15,\n",
        "           max_depth=-1,colsample_bytree=0.9,subsample=0.9,learning_rate=0.1))])).fit(list_X_train[5], list_y_train[5]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('LDA', LinearDiscriminantAnalysis())])).fit(list_X_train[6], list_y_train[6]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('MLPClassifier',\n",
        "                      MLPClassifier(hidden_layer_sizes=(50,30,30), max_iter=5, alpha=0.0001,\n",
        "                     solver='sgd', verbose=10,  random_state=1))])).fit(list_X_train[7], list_y_train[7]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('LR', LogisticRegression())])).fit(list_X_train[8], list_y_train[8]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('QDA', QuadraticDiscriminantAnalysis())])).fit(list_X_train[9], list_y_train[9]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                      ('CART', DecisionTreeClassifier())])).fit(list_X_train[10], list_y_train[10]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                       ('NB', GaussianNB())])).fit(list_X_train[11], list_y_train[11]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "   ('BaggingClassifier',BaggingClassifier( DecisionTreeClassifier(random_state=42), n_estimators=100,\n",
        "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42,oob_score = True))])).fit(list_X_train[12], list_y_train[12]))\n",
        "\n",
        "\n",
        "   \n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in enumerate(models):\n",
        "    #kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "    print('1')\n",
        "    cv_results = model_selection.cross_val_score(model, list_X_train[name], \n",
        "                            list_y_train[name], cv=5, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 4687101209517779.00000000\n",
            "Iteration 3, loss = 4687085548766339.00000000\n",
            "Iteration 4, loss = 4687069888067226.00000000\n",
            "Iteration 5, loss = 4687054227420438.00000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0: 0.778522 (0.003901)\n",
            "1\n",
            "1: 0.752218 (0.005285)\n",
            "1\n",
            "2: 0.794972 (0.001558)\n",
            "1\n",
            "3: 0.704757 (0.005212)\n",
            "1\n",
            "4: 0.784785 (0.001221)\n",
            "1\n",
            "5: 0.738485 (0.003320)\n",
            "1\n",
            "6: 0.747540 (0.004027)\n",
            "1\n",
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 55414395049.58090210\n",
            "Iteration 3, loss = 55414238126.30326843\n",
            "Iteration 4, loss = 55414081203.46942139\n",
            "Iteration 5, loss = 55413924281.08096313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 6189401.93836398\n",
            "Iteration 3, loss = 6189384.40581607\n",
            "Iteration 4, loss = 6189366.87719975\n",
            "Iteration 5, loss = 6189349.34969836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 30317738531.85855484\n",
            "Iteration 3, loss = 30317652677.64995956\n",
            "Iteration 4, loss = 30317566823.68590164\n",
            "Iteration 5, loss = 30317480969.96602631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 4314444143.19308281\n",
            "Iteration 3, loss = 4314431925.48370075\n",
            "Iteration 4, loss = 4314419707.81230736\n",
            "Iteration 5, loss = 4314407490.17647743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 345459673.62581587\n",
            "Iteration 3, loss = 345458700.57737249\n",
            "Iteration 4, loss = 345457727.53532153\n",
            "Iteration 5, loss = 345456754.49703503\n",
            "7: 0.560289 (0.000034)\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8: 0.622103 (0.012807)\n",
            "1\n",
            "9: 0.729974 (0.002467)\n",
            "1\n",
            "10: 0.748189 (0.002325)\n",
            "1\n",
            "11: 0.614602 (0.003116)\n",
            "1\n",
            "12: 0.747465 (0.002991)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMaMhj3bgeukAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGSR_9eGDZB4",
        "colab_type": "code",
        "outputId": "3c2f3b9a-78b7-4a8c-f3bb-0fc34cae6aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "last=[]\n",
        "for name, model in enumerate(models):\n",
        "  last.append([type(model[1]),results[name].mean()])\n",
        "last\n",
        "def Sort(sub_li): \n",
        "   return(sorted(sub_li, key = lambda x: x[1], reverse=True))     \n",
        "bb=(Sort(last))\n",
        "try1=[]\n",
        "for i in range(len(bb)):\n",
        "  if bb[i][1]>=0.70:\n",
        "     try1.append(bb[i])\n",
        "try1"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier,\n",
              "  0.7949715831273098],\n",
              " [sklearn.ensemble._forest.ExtraTreesClassifier, 0.7847851248231811],\n",
              " [sklearn.ensemble._forest.RandomForestClassifier, 0.7785223018945713],\n",
              " [sklearn.ensemble._weight_boosting.AdaBoostClassifier, 0.7522182586090855],\n",
              " [sklearn.tree._classes.DecisionTreeClassifier, 0.7481890186593362],\n",
              " [sklearn.discriminant_analysis.LinearDiscriminantAnalysis,\n",
              "  0.7475402160224833],\n",
              " [sklearn.ensemble._bagging.BaggingClassifier, 0.7474647693797933],\n",
              " [lightgbm.sklearn.LGBMClassifier, 0.7384854323058576],\n",
              " [sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis,\n",
              "  0.7299740106341128],\n",
              " [xgboost.sklearn.XGBClassifier, 0.7047565923657741]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09XV0e_yx2rJ",
        "colab_type": "code",
        "outputId": "09dfa82b-760c-4dcc-a6ad-6a7c3d71bb8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "bb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier,\n",
              "  0.7945943590239859],\n",
              " [sklearn.ensemble._forest.ExtraTreesClassifier, 0.7808462675667986],\n",
              " [sklearn.ensemble._forest.RandomForestClassifier, 0.7805897845111422],\n",
              " [sklearn.ensemble._weight_boosting.AdaBoostClassifier, 0.7512525215403791],\n",
              " [sklearn.ensemble._bagging.BaggingClassifier, 0.7480078888675838],\n",
              " [sklearn.tree._classes.DecisionTreeClassifier, 0.747223233762471],\n",
              " [sklearn.discriminant_analysis.LinearDiscriminantAnalysis,\n",
              "  0.7454878038309398],\n",
              " [lightgbm.sklearn.LGBMClassifier, 0.7381382966693678],\n",
              " [sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis,\n",
              "  0.7266539484001128],\n",
              " [xgboost.sklearn.XGBClassifier, 0.7097669734676023],\n",
              " [sklearn.linear_model._logistic.LogisticRegression, 0.6158701938309009],\n",
              " [sklearn.naive_bayes.GaussianNB, 0.6143154689315227],\n",
              " [sklearn.neural_network._multilayer_perceptron.MLPClassifier,\n",
              "  0.5603495113294544]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAd-n2vnR-TY",
        "colab_type": "code",
        "outputId": "cb185e54-dc7b-4bbd-8639-64528cc91c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "import lightgbm as lgb\n",
        "from functools import partial\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "param_hyperopt5= {\n",
        "  'DecisionTreeClassifier':\n",
        "            {\n",
        "            'max_depth': ho_scope.int(hp.quniform('c0_max_depth', 5, 50, 5)),\n",
        "            'max_features': hp.choice('c0_max_features', ['auto', 'sqrt', 'log2']),\n",
        "            'min_samples_split': ho_scope.int(hp.quniform('c0_min_samples_split', 5, 40,5)),\n",
        "            'min_samples_leaf': ho_scope.int(hp.quniform('c0_min_samples_leaf', 5, 40,5)),                                  \n",
        "             'criterion': hp.choice('c0_criterion', ['gini', 'entropy'])\n",
        "         }  \n",
        "} \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "def f_clf5(params):\n",
        "   model1 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),('DecisionTreeClassifier', \n",
        "                                                         DecisionTreeClassifier(**f_unpack_dict(params['DecisionTreeClassifier'])))])   \n",
        "   return model1  \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf5(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf5 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt5, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf5 = f_clf5(space_eval(param_hyperopt5, best_clf5)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf5_val_score = roc_auc_score(y_test, clf5.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf5_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a5=space_eval(param_hyperopt5, best_clf5)\n",
        "AA_classifier={'classifier':list(a5.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf5_val_score,'parameters':list(a5.values())[0]}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:54<00:00, 17.19s/it, best loss: -0.8670630016196558]\n",
            "Cross-val score: 0.86706; validation score: 0.88926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz0WsbNDCAMr",
        "colab_type": "code",
        "outputId": "97c46779-b59f-4d36-8442-aa3c9e70c12a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
        "# now you can import normally from ensemble\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "import numpy as np\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "import xgboost as xgb\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "param_hyperopt= {\n",
        "        'DecisionTreeClassifier':\n",
        "            {\n",
        "            'max_depth': ho_scope.int(hp.quniform('c0_max_depth', 3, 7, 1)),\n",
        "            'max_features': hp.choice('c0_max_features', ['auto', 'sqrt', 'log2']),\n",
        "            'min_samples_split': ho_scope.int(hp.quniform('c0_min_samples_split', 3, 15,3)),\n",
        "            'min_samples_leaf': ho_scope.int(hp.quniform('c0_min_samples_leaf', 3, 15,3))                                   \n",
        "          \n",
        "         },\n",
        "        'RandomForestClassifier': \n",
        "            {\n",
        "            'max_depth': ho_scope.int(hp.quniform('c2_max_depth', 5, 30, 5)),\n",
        "            'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 10, 50, 10)),\n",
        "            'max_features': hp.choice('c2_max_features', ['auto', 'sqrt']),\n",
        "            'criterion': hp.choice('c2_criterion', ['gini', 'entropy']),\n",
        "            'min_samples_split': ho_scope.int(hp.quniform('c2_min_samples_split', 5, 20,5)),\n",
        "            'min_samples_leaf': ho_scope.int(hp.quniform('c2_min_samples_leaf', 5, 20,5))\n",
        "                          \n",
        "         }  ,                                             \n",
        "          'HistGradientBoostingClassifier':\n",
        "            {'learning_rate': hp.loguniform('c3_learning_rate', np.log(0.01), np.log(0.1)),\n",
        "                'max_iter': ho_scope.int(hp.quniform('c3_max_iter', 10, 200, 5)),\n",
        "                'max_depth': ho_scope.int(hp.quniform('c3_max_depth', 2,14, 1)),\n",
        "                'max_leaf_nodes': ho_scope.int(hp.quniform('c3_max_leaf_nodes', 5, 35,5)),\n",
        "                'min_samples_leaf': ho_scope.int(hp.quniform('c3_min_samples_leaf', 5, 25,5)),\n",
        "                'max_bins': ho_scope.int(hp.quniform('c3_max_bins', 20, 200,20)),\n",
        "                'validation_fraction':0.1,\n",
        "                'n_iter_no_change':None,\n",
        "                 'tol':1e-07,\n",
        "                'l2_regularization':0.0 \n",
        "           },\n",
        "  'ExtraTreesClassifier':\n",
        "            {\n",
        "                'max_depth': ho_scope.int(hp.quniform('c4_max_depth', 5, 20, 5)),\n",
        "                'n_estimators': ho_scope.int(hp.quniform('c4_n_estimators', 5, 200, 5)),\n",
        "                'max_features': ho_scope.int(hp.quniform('c4_max_features', 5, 20, 5)),\n",
        "                'criterion': hp.choice('c4_criterion', ['gini', 'entropy']),\n",
        "                'min_samples_split': ho_scope.int(hp.quniform('c4_min_samples_split', 2, 20,2)),\n",
        "                'min_samples_leaf': ho_scope.int(hp.quniform('c4_min_samples_leaf', 2, 20,2))      \n",
        "             }  ,\n",
        " 'AdaBoostClassifier':\n",
        "   {\n",
        "          'base_estimator':hp.choice('base_estimator', [DecisionTreeClassifier(**AA_classifier['parameters'])]),\n",
        "          'learning_rate': hp.loguniform('c5_learning_rate', np.log(0.01), np.log(1)),\n",
        "          'n_estimators': ho_scope.int(hp.quniform('c5_n_estimators', 10, 40, 5)),\n",
        "          'algorithm': hp.choice('c5_algorithm',[\"SAMME\"]) \n",
        "       },\n",
        "       'XGBClassifier':\n",
        "    {   \n",
        "        'max_depth': ho_scope.int(hp.quniform('c2_max_depth', 5, 15, 5)),\n",
        "           'min_child_weight': hp.choice ('c2_min_child',np.arange(1, 10, dtype=int)),\n",
        "           'subsample': hp.uniform ('c2_subsample', 0.2, 1),\n",
        "           'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 5, 45, 15)),\n",
        "          'eta':ho_scope.float(hp.quniform('c2_eta', 0.025, 0.5, 0.025)) ,\n",
        "          'gamma':ho_scope.float( hp.quniform('c2_gamma', 0.5, 1, 0.05)) ,\n",
        "        'colsample_bytree': ho_scope.float(hp.quniform('c2_colsample_bytree', 0.5, 1, 0.05)),\n",
        "         'objective': 'binary:logistic',\n",
        "          'n_iter_no_change':5\n",
        "       },\n",
        "   'LinearDiscriminantAnalysis':\n",
        "            {    }  ,\n",
        "  'QuadraticDiscriminantAnalysis' :\n",
        "        {  },\n",
        "   'LGBMClassifier':\n",
        "                  {\n",
        "                     'max_depth': ho_scope.int(hp.quniform('c6_max_depth', 2, 14, 2)),\n",
        "                   'num_leave': ho_scope.int(hp.quniform('c6_num_leaves', 5, 30, 5)),\n",
        "                   'min_child_samples': ho_scope.int(hp.quniform('c6_min_child_samples', 50, 100, 10)),\n",
        "                   'scale_pos_weight': ho_scope.float(hp.quniform('c6_scale_pos_weight', 50, 100, 10)),\n",
        "                   'subsample': ho_scope.float(hp.quniform('c6_subsample', 0.2, 0.9, 0.1)),\n",
        "                   'colsample_bytree': ho_scope.float(hp.quniform('c6_colsample_bytree', 0.2, 0.9, 0.1)),\n",
        "                   'reg_lambda': hp.choice(\"c6_reg_lambda\",[0, 1e-1, 1, 5, 10, 20, 50]),\n",
        "                   'reg_alpha': hp.choice(\"c6_reg_alpha\",[0, 1e-1, 1, 5, 10, 20, 50]) ,\n",
        "                   'max_bin': ho_scope.int(hp.quniform('c6_max_bin', 10, 200, 10)),\n",
        "                   'learning_rate': ho_scope.float(hp.quniform('c6_learning_rate', 0.001, 0.09, 0.005)),\n",
        "                   'num_iterations': ho_scope.int(hp.quniform('c6_num_iterations', 100, 2000, 100)),\n",
        "                    'n_iter_no_change':10,\n",
        "                   'metric' : 'binary_error'\n",
        "                   }     ,     \n",
        "  'LogisticRegression ':\n",
        "  { \n",
        "      ' classifier__penalty': hp.choice(' classifier__penalty', ['l1', 'l2']),\n",
        "     'classifier__C' :hp.loguniform('classifier__C', np.log(0.1), np.log(1)) ,\n",
        "    'classifier__solver' : 'liblinear'\n",
        "    }   ,\n",
        "  'MLPClassifier':\n",
        "  {\n",
        "      'hidden_layer_sizes': hp.choice(' c8_hidden_layer_sizes',[(50,50,50), (50,100,50), (100,)]),\n",
        "    'activation':hp.choice ('c8_activation',['tanh', 'relu']),\n",
        "    'solver': hp.choice('c8_solver',['sgd', 'adam']) ,\n",
        "    'alpha':hp.loguniform('c8_alpha',np.log(0.0001), np.log(0.05) ),\n",
        "    'learning_rate':hp.choice('c8_learning_rate', ['constant','adaptive'],)\n",
        "    },\n",
        "  'GaussianNB':\n",
        "  {  },\n",
        "  'BaggingClassifier':\n",
        "            {      \n",
        "             'base_estimator': hp.choice('base_estimator',[DecisionTreeClassifier(**AA_classifier['parameters'])]),\n",
        "              'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 5, 40, 10)),\n",
        "              'oob_score': hp.choice('oob_score', [True,False]),\n",
        "               'random_state': 1\n",
        "            }         \n",
        "       \n",
        "} \n",
        "\n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2,random_state = 0)\n",
        "\n",
        "best_clf3=[]\n",
        "final_clf=[]\n",
        "clf1_val_score=[]\n",
        "y_score=[]\n",
        "Fr_classifier=[]\n",
        "a1=[]\n",
        "classifiers=[]\n",
        "for i in range(len(try1)):\n",
        "    param_hyperopt3={try1[i][0].__name__:param_hyperopt[try1[i][0].__name__]}\n",
        "    clf_name=try1[i][0].__name__\n",
        "    cls=try1[i][0]\n",
        "    def f_clf1(params):\n",
        "       if not (params[clf_name]):   \n",
        "           model6 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),(clf_name,cls(**f_unpack_dict(params)))])\n",
        "           return model6\n",
        "       else:\n",
        "            model6 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),\n",
        "                                    (clf_name,cls(**f_unpack_dict(params[clf_name])))])\n",
        "            return model6\n",
        "    def objective_function(params,X_train2, y_train2):\n",
        "        model=f_clf1(params)\n",
        "        shuffle = KFold(n_splits=5, shuffle=True)\n",
        "        score = cross_val_score(model, X_train2, y_train2, cv=shuffle,scoring='roc_auc', n_jobs=-1).mean()\n",
        "        return {'loss': -score, 'status': STATUS_OK}  \n",
        "    trials = Trials()\n",
        "    best_clf3.append(fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                    param_hyperopt3, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))) \n",
        "    final_clf.append(f_clf1(space_eval(param_hyperopt3, best_clf3[i])).fit(X_train2, y_train2)) \n",
        "    # Calculating performance on validation set\n",
        "    y_score.append(final_clf[i].predict_proba(X_test2))  \n",
        "    clf1_val_score.append(roc_auc_score(y_test2, y_score[i][:,1])) \n",
        "    print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.format(-trials.best_trial['result']['loss'],\n",
        "                                                                       clf1_val_score[i]))\n",
        "    a1.append(space_eval(param_hyperopt3, best_clf3[i]))\n",
        "    classifiers.append({'classifier':cls,'Cross-val score':-trials.best_trial['result']['loss'],\n",
        "                        'validation score':clf1_val_score[i],'parameters':list(a1[i].values())[0]})\n",
        "classifiers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:13<00:00, 68.30s/it, best loss: -0.8886177024210724]\n",
            "Cross-val score: 0.88862; validation score: 0.88933\n",
            "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [47:54<00:00, 286.86s/it, best loss: -0.8864910228042046]\n",
            "Cross-val score: 0.88649; validation score: 0.88891\n",
            " 10%|█         | 1/10 [01:38<14:43, 98.22s/it, best loss: -0.8933156665907763]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [24:38<00:00, 124.67s/it, best loss: -0.9013013591922643]\n",
            "Cross-val score: 0.90130; validation score: 0.90351\n",
            " 50%|█████     | 5/10 [18:39<18:24, 220.96s/it, best loss: -0.8957563614568935]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [38:09<00:00, 214.09s/it, best loss: -0.8987301923595489]\n",
            "Cross-val score: 0.89873; validation score: 0.90090\n",
            "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [20:50<00:00, 113.78s/it, best loss: -0.8960769962978226]\n",
            "Cross-val score: 0.89608; validation score: 0.89811\n",
            "100%|██████████| 10/10 [02:13<00:00, 13.44s/it, best loss: -0.7325646123357055]\n",
            "Cross-val score: 0.73256; validation score: 0.72046\n",
            "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [03:28<00:00, 20.57s/it, best loss: -0.8268455654813259]\n",
            "Cross-val score: 0.82685; validation score: 0.82928\n",
            "100%|██████████| 10/10 [35:34<00:00, 232.21s/it, best loss: -0.9012510175710758]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-val score: 0.90125; validation score: 0.90214\n",
            "100%|██████████| 10/10 [02:43<00:00, 16.43s/it, best loss: -0.7867763433775503]\n",
            "Cross-val score: 0.78678; validation score: 0.78877\n",
            "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [17:36<00:00, 126.98s/it, best loss: -0.9030023304309267]\n",
            "Cross-val score: 0.90300; validation score: 0.90485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Cross-val score': 0.8886177024210724,\n",
              "  'classifier': sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier,\n",
              "  'parameters': {'l2_regularization': 0.0,\n",
              "   'learning_rate': 0.029641454778718972,\n",
              "   'max_bins': 100,\n",
              "   'max_depth': 10,\n",
              "   'max_iter': 175,\n",
              "   'max_leaf_nodes': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'n_iter_no_change': None,\n",
              "   'tol': 1e-07,\n",
              "   'validation_fraction': 0.1},\n",
              "  'validation score': 0.8893314575776722},\n",
              " {'Cross-val score': 0.8864910228042046,\n",
              "  'classifier': sklearn.ensemble._forest.ExtraTreesClassifier,\n",
              "  'parameters': {'criterion': 'entropy',\n",
              "   'max_depth': 15,\n",
              "   'max_features': 15,\n",
              "   'min_samples_leaf': 16,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 65},\n",
              "  'validation score': 0.8889058957589675},\n",
              " {'Cross-val score': 0.9013013591922643,\n",
              "  'classifier': sklearn.ensemble._forest.RandomForestClassifier,\n",
              "  'parameters': {'criterion': 'entropy',\n",
              "   'max_depth': 30,\n",
              "   'max_features': 'auto',\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  'validation score': 0.9035072526030485},\n",
              " {'Cross-val score': 0.8987301923595489,\n",
              "  'classifier': sklearn.ensemble._weight_boosting.AdaBoostClassifier,\n",
              "  'parameters': {'algorithm': 'SAMME',\n",
              "   'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                          max_depth=35, max_features='sqrt', max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=25, min_samples_split=20,\n",
              "                          min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                          random_state=None, splitter='best'),\n",
              "   'learning_rate': 0.07293190523422614,\n",
              "   'n_estimators': 40},\n",
              "  'validation score': 0.9008969943167825},\n",
              " {'Cross-val score': 0.8960769962978226,\n",
              "  'classifier': sklearn.ensemble._bagging.BaggingClassifier,\n",
              "  'parameters': {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                          max_depth=35, max_features='sqrt', max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=25, min_samples_split=20,\n",
              "                          min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                          random_state=None, splitter='best'),\n",
              "   'n_estimators': 40,\n",
              "   'oob_score': True,\n",
              "   'random_state': 1},\n",
              "  'validation score': 0.8981087067738658},\n",
              " {'Cross-val score': 0.7325646123357055,\n",
              "  'classifier': sklearn.tree._classes.DecisionTreeClassifier,\n",
              "  'parameters': {'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'min_samples_leaf': 12,\n",
              "   'min_samples_split': 6},\n",
              "  'validation score': 0.7204596302586113},\n",
              " {'Cross-val score': 0.8268455654813259,\n",
              "  'classifier': sklearn.discriminant_analysis.LinearDiscriminantAnalysis,\n",
              "  'parameters': {},\n",
              "  'validation score': 0.8292819955028902},\n",
              " {'Cross-val score': 0.9012510175710758,\n",
              "  'classifier': lightgbm.sklearn.LGBMClassifier,\n",
              "  'parameters': {'colsample_bytree': 0.5,\n",
              "   'learning_rate': 0.09,\n",
              "   'max_bin': 80,\n",
              "   'max_depth': 10,\n",
              "   'metric': 'binary_error',\n",
              "   'min_child_samples': 80,\n",
              "   'n_iter_no_change': 10,\n",
              "   'num_iterations': 1000,\n",
              "   'num_leave': 10,\n",
              "   'reg_alpha': 50,\n",
              "   'reg_lambda': 5,\n",
              "   'scale_pos_weight': 50.0,\n",
              "   'subsample': 0.8},\n",
              "  'validation score': 0.9021447915521081},\n",
              " {'Cross-val score': 0.7867763433775503,\n",
              "  'classifier': sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis,\n",
              "  'parameters': {},\n",
              "  'validation score': 0.7887682267477347},\n",
              " {'Cross-val score': 0.9030023304309267,\n",
              "  'classifier': xgboost.sklearn.XGBClassifier,\n",
              "  'parameters': {'colsample_bytree': 1.0,\n",
              "   'eta': 0.125,\n",
              "   'gamma': 0.75,\n",
              "   'max_depth': 15,\n",
              "   'min_child_weight': 3,\n",
              "   'n_estimators': 15,\n",
              "   'n_iter_no_change': 5,\n",
              "   'objective': 'binary:logistic',\n",
              "   'subsample': 0.7468459518994333},\n",
              "  'validation score': 0.9048467840317365}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjsBIxM_05gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e9e3771-a608-450e-f9c6-7391cd1f1cd7"
      },
      "source": [
        "try1[1][0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "xgboost.sklearn.XGBClassifier"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roVBwvIwn_kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers=[{'Cross-val score': 0.8886177024210724,\n",
        "  'classifier': try1[0][0],\n",
        "  'parameters': {'l2_regularization': 0.0,\n",
        "   'learning_rate': 0.029641454778718972,\n",
        "   'max_bins': 100,\n",
        "   'max_depth': 10,\n",
        "   'max_iter': 175,\n",
        "   'max_leaf_nodes': 20,\n",
        "   'min_samples_leaf': 15,\n",
        "   'n_iter_no_change': None,\n",
        "   'tol': 1e-07,\n",
        "   'validation_fraction': 0.1},\n",
        "  'validation score': 0.8893314575776722},\n",
        " {'Cross-val score': 0.8864910228042046,\n",
        "  'classifier': try1[1][0],\n",
        "  'parameters': {'criterion': 'entropy',\n",
        "   'max_depth': 15,\n",
        "   'max_features': 15,\n",
        "   'min_samples_leaf': 16,\n",
        "   'min_samples_split': 16,\n",
        "   'n_estimators': 65},\n",
        "  'validation score': 0.8889058957589675},\n",
        " {'Cross-val score': 0.9013013591922643,\n",
        "  'classifier': try1[2][0],\n",
        "  'parameters': {'criterion': 'entropy',\n",
        "   'max_depth': 30,\n",
        "   'max_features': 'auto',\n",
        "   'min_samples_leaf': 5,\n",
        "   'min_samples_split': 10,\n",
        "   'n_estimators': 50},\n",
        "  'validation score': 0.9035072526030485},\n",
        " {'Cross-val score': 0.8987301923595489,\n",
        "  'classifier': try1[3][0],\n",
        "  'parameters': {'algorithm': 'SAMME',\n",
        "   'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
        "                          max_depth=35, max_features='sqrt', max_leaf_nodes=None,\n",
        "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                          min_samples_leaf=25, min_samples_split=20,\n",
        "                          min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                          random_state=None, splitter='best'),\n",
        "   'learning_rate': 0.07293190523422614,\n",
        "   'n_estimators': 40},\n",
        "  'validation score': 0.9008969943167825},\n",
        " {'Cross-val score': 0.8960769962978226,\n",
        "  'classifier': try1[5][0],\n",
        "  'parameters': {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
        "                          max_depth=35, max_features='sqrt', max_leaf_nodes=None,\n",
        "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                          min_samples_leaf=25, min_samples_split=20,\n",
        "                          min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                          random_state=None, splitter='best'),\n",
        "   'n_estimators': 40,\n",
        "   'oob_score': True,\n",
        "   'random_state': 1},\n",
        "  'validation score': 0.8981087067738658},\n",
        " {'Cross-val score': 0.7325646123357055,\n",
        "  'classifier': try1[4][0],\n",
        "  'parameters': {'max_depth': 5,\n",
        "   'max_features': 'log2',\n",
        "   'min_samples_leaf': 12,\n",
        "   'min_samples_split': 6},\n",
        "  'validation score': 0.7204596302586113},\n",
        " {'Cross-val score': 0.8268455654813259,\n",
        "  'classifier': try1[6][0],\n",
        "  'parameters': {},\n",
        "  'validation score': 0.8292819955028902},\n",
        " {'Cross-val score': 0.9012510175710758,\n",
        "  'classifier': try1[7][0],\n",
        "  'parameters': {'colsample_bytree': 0.5,\n",
        "   'learning_rate': 0.09,\n",
        "   'max_bin': 80,\n",
        "   'max_depth': 10,\n",
        "   'metric': 'binary_error',\n",
        "   'min_child_samples': 80,\n",
        "   'n_iter_no_change': 10,\n",
        "   'num_iterations': 1000,\n",
        "   'num_leave': 10,\n",
        "   'reg_alpha': 50,\n",
        "   'reg_lambda': 5,\n",
        "   'scale_pos_weight': 50.0,\n",
        "   'subsample': 0.8},\n",
        "  'validation score': 0.9021447915521081},\n",
        " {'Cross-val score': 0.7867763433775503,\n",
        "  'classifier': try1[8][0],\n",
        "  'parameters': {},\n",
        "  'validation score': 0.7887682267477347},\n",
        " {'Cross-val score': 0.9030023304309267,\n",
        "  'classifier': try1[9][0],\n",
        "  'parameters': {'colsample_bytree': 1.0,\n",
        "   'eta': 0.125,\n",
        "   'gamma': 0.75,\n",
        "   'max_depth': 15,\n",
        "   'min_child_weight': 3,\n",
        "   'n_estimators': 15,\n",
        "   'n_iter_no_change': 5,\n",
        "   'objective': 'binary:logistic',\n",
        "   'subsample': 0.7468459518994333},\n",
        "  'validation score': 0.9048467840317365}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zTbGlzeOArL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cf6de22-3162-4ca3-c2a8-bc2c161dc438"
      },
      "source": [
        "try1[7][0]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lightgbm.sklearn.LGBMClassifier"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u525waZMUoZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers=[{'Cross-val score': 0.889145641582062,\n",
        "  'classifier': try1[0][0],\n",
        "  'parameters': {'l2_regularization': 0.0,\n",
        "   'learning_rate': 0.029641454778718972,\n",
        "   'max_bins': 100,\n",
        "   'max_depth': 10,\n",
        "   'max_iter': 175,\n",
        "   'max_leaf_nodes': 20,\n",
        "   'min_samples_leaf': 15,\n",
        "   'n_iter_no_change': None,\n",
        "   'tol': 1e-07,\n",
        "   'validation_fraction': 0.1},\n",
        "  'validation score': 0.8890387314781489},\n",
        " {'Cross-val score': 0.8862456887587555,\n",
        "  'classifier': try1[1][0],\n",
        "  'parameters': {'criterion': 'entropy',\n",
        "   'max_depth': 15,\n",
        "   'max_features': 15,\n",
        "   'min_samples_leaf': 12,\n",
        "   'min_samples_split': 10,\n",
        "   'n_estimators': 20},\n",
        "  'validation score': 0.8818171380065061},\n",
        " {'Cross-val score': 0.8846250315039053,\n",
        "  'classifier': try1[2][0],\n",
        "  'parameters': {'criterion': 'entropy',\n",
        "   'max_depth': 14,\n",
        "   'max_features': 'auto',\n",
        "   'min_samples_leaf': 2,\n",
        "   'min_samples_split': 6,\n",
        "   'n_estimators': 45},\n",
        "  'validation score': 0.8835185140616291},\n",
        " {'Cross-val score': 0.7629741618747085,\n",
        "  'classifier': try1[3][0],\n",
        "  'parameters': {'algorithm': 'SAMME',\n",
        "   'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                          max_depth=1, max_features=None, max_leaf_nodes=None,\n",
        "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                          min_samples_leaf=1, min_samples_split=2,\n",
        "                          min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                          random_state=None, splitter='best'),\n",
        "   'learning_rate': 0.30044074314959096,\n",
        "   'n_estimators': 80},\n",
        "  'validation score': 0.7644778116050867},\n",
        " {'Cross-val score': 0.8961590358829536,\n",
        "  'classifier': try1[6][0],\n",
        "  'parameters': {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                          max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                          min_samples_leaf=1, min_samples_split=2,\n",
        "                          min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                          random_state=None, splitter='best'),\n",
        "   'n_estimators': 30,\n",
        "   'oob_score': True,\n",
        "   'random_state': 1},\n",
        "  'validation score': 0.8989057692956279},\n",
        " {'Cross-val score': 0.7520561338733224,\n",
        "  'classifier': try1[4][0],\n",
        "  'parameters': {'max_depth': 6,\n",
        "   'max_features': 'sqrt',\n",
        "   'min_samples_leaf': 9,\n",
        "   'min_samples_split': 9},\n",
        "  'validation score': 0.7841260149694038},\n",
        " {'Cross-val score': 0.8268494098728028,\n",
        "  'classifier': try1[5][0],\n",
        "  'parameters': {},\n",
        "  'validation score': 0.8292819955028902},\n",
        " {'Cross-val score': 0.9013294538476375,\n",
        "  'classifier': try1[7][0],\n",
        "  'parameters': {'colsample_bytree': 0.5,\n",
        "   'learning_rate': 0.09,\n",
        "   'max_bin': 80,\n",
        "   'max_depth': 10,\n",
        "   'min_child_samples': 80,\n",
        "   'n_iter_no_change': 10,\n",
        "   'num_iterations': 1000,\n",
        "   'num_leave': 10,\n",
        "   'reg_alpha': 50,\n",
        "   'reg_lambda': 5,\n",
        "   'scale_pos_weight': 50.0,\n",
        "   'subsample': 0.8},\n",
        "  'validation score': 0.9021447915521081},\n",
        " {'Cross-val score': 0.7867791499718135,\n",
        "  'classifier': try1[8][0],\n",
        "  'parameters': {},\n",
        "  'validation score': 0.7887682267477347},\n",
        " {'Cross-val score': 0.9030990105443255,\n",
        "  'classifier': try1[9][0],\n",
        "  'parameters': {'colsample_bytree': 1.0,\n",
        "   'eta': 0.125,\n",
        "   'gamma': 0.75,\n",
        "   'max_depth': 15,\n",
        "   'min_child_weight': 3,\n",
        "   'n_estimators': 15,\n",
        "   'n_iter_no_change': 5,\n",
        "   'objective': 'binary:logistic',\n",
        "   'subsample': 0.7468459518994333},\n",
        "  'validation score': 0.9048467840317365}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-ZPMwgETLqx",
        "colab_type": "code",
        "outputId": "0872ef9b-ff8f-43ab-d3f5-e108442d7361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "from operator import itemgetter\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "newlist = sorted(classifiers, key=itemgetter('Cross-val score'), reverse=True)\n",
        "fiv=[]\n",
        "for i in range(len(newlist)):\n",
        "     if round(newlist[i]['Cross-val score'],2)>0.85:\n",
        "        fiv.append(newlist[i])  \n",
        "        \n",
        "names=[]\n",
        "for i, _ in enumerate(Accepted):\n",
        "    names.append(\"pipeline\"+str(i+1))  \n",
        "AcceptedR=[]\n",
        "for i in range(len(Accepted)):\n",
        "    AcceptedR.append(Accepted[i][1])\n",
        "dict = {}\n",
        "for name, Accepted_val in zip(names, AcceptedR ):\n",
        "    dict[name] =make_pipeline(Accepted_val(),fiv[AcceptedR.index(Accepted_val)]['classifier'](**fiv[AcceptedR.index(Accepted_val)]['parameters']))\n",
        "\n",
        "sclf2 = StackingClassifier(classifiers=list(dict.values()), meta_classifier=LogisticRegression()) \n",
        "model2=sclf2.fit(X_train2, y_train2)\n",
        "y_true3, y_pred3  =y_test2, model2.predict(X_test2)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train2, y_train2))\n",
        "clf2_val_score = roc_auc_score(y_test2, sclf2.predict_proba(X_test2)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.77      0.76     94841\n",
            "           1       0.82      0.81      0.81    120517\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.79      0.79      0.79    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "StackingClassifier score: 0.913056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_lR0iCoafFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51c65005-6b1c-45cd-fee5-c44d5c6b0433"
      },
      "source": [
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-val score: 0.87460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIRna7u_Mgo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a35b3518-7a7e-4a21-bc01-a6eea7a28405"
      },
      "source": [
        "fiv"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Cross-val score': 0.9030990105443255,\n",
              "  'classifier': xgboost.sklearn.XGBClassifier,\n",
              "  'parameters': {'colsample_bytree': 1.0,\n",
              "   'eta': 0.125,\n",
              "   'gamma': 0.75,\n",
              "   'max_depth': 15,\n",
              "   'min_child_weight': 3,\n",
              "   'n_estimators': 15,\n",
              "   'n_iter_no_change': 5,\n",
              "   'objective': 'binary:logistic',\n",
              "   'subsample': 0.7468459518994333},\n",
              "  'validation score': 0.9048467840317365},\n",
              " {'Cross-val score': 0.9013294538476375,\n",
              "  'classifier': sklearn.ensemble._weight_boosting.AdaBoostClassifier,\n",
              "  'parameters': {'colsample_bytree': 0.5,\n",
              "   'learning_rate': 0.09,\n",
              "   'max_bin': 80,\n",
              "   'max_depth': 10,\n",
              "   'min_child_samples': 80,\n",
              "   'n_iter_no_change': 10,\n",
              "   'num_iterations': 1000,\n",
              "   'num_leave': 10,\n",
              "   'reg_alpha': 50,\n",
              "   'reg_lambda': 5,\n",
              "   'scale_pos_weight': 50.0,\n",
              "   'subsample': 0.8},\n",
              "  'validation score': 0.9021447915521081},\n",
              " {'Cross-val score': 0.8961590358829536,\n",
              "  'classifier': sklearn.tree._classes.DecisionTreeClassifier,\n",
              "  'parameters': {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                          max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                          random_state=None, splitter='best'),\n",
              "   'n_estimators': 30,\n",
              "   'oob_score': True,\n",
              "   'random_state': 1},\n",
              "  'validation score': 0.8989057692956279},\n",
              " {'Cross-val score': 0.889145641582062,\n",
              "  'classifier': sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier,\n",
              "  'parameters': {'l2_regularization': 0.0,\n",
              "   'learning_rate': 0.029641454778718972,\n",
              "   'max_bins': 100,\n",
              "   'max_depth': 10,\n",
              "   'max_iter': 175,\n",
              "   'max_leaf_nodes': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'n_iter_no_change': None,\n",
              "   'tol': 1e-07,\n",
              "   'validation_fraction': 0.1},\n",
              "  'validation score': 0.8890387314781489},\n",
              " {'Cross-val score': 0.8862456887587555,\n",
              "  'classifier': sklearn.ensemble._forest.ExtraTreesClassifier,\n",
              "  'parameters': {'criterion': 'entropy',\n",
              "   'max_depth': 15,\n",
              "   'max_features': 15,\n",
              "   'min_samples_leaf': 12,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  'validation score': 0.8818171380065061},\n",
              " {'Cross-val score': 0.8846250315039053,\n",
              "  'classifier': sklearn.ensemble._forest.RandomForestClassifier,\n",
              "  'parameters': {'criterion': 'entropy',\n",
              "   'max_depth': 14,\n",
              "   'max_features': 'auto',\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 6,\n",
              "   'n_estimators': 45},\n",
              "  'validation score': 0.8835185140616291}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH6WnTQ0iK2I",
        "colab_type": "code",
        "outputId": "794339d3-e862-44d0-acda-f410ed60c834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fiv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Cross-val score': 0.9030990105443255,\n",
              "  'classifier': xgboost.sklearn.XGBClassifier,\n",
              "  'parameters': {'colsample_bytree': 1.0,\n",
              "   'eta': 0.125,\n",
              "   'gamma': 0.75,\n",
              "   'max_depth': 15,\n",
              "   'min_child_weight': 3,\n",
              "   'n_estimators': 15,\n",
              "   'n_iter_no_change': 5,\n",
              "   'objective': 'binary:logistic',\n",
              "   'subsample': 0.7468459518994333},\n",
              "  'validation score': 0.9048467840317365},\n",
              " {'Cross-val score': 0.9013294538476375,\n",
              "  'classifier': lightgbm.sklearn.LGBMClassifier,\n",
              "  'parameters': {'colsample_bytree': 0.5,\n",
              "   'learning_rate': 0.09,\n",
              "   'max_bin': 80,\n",
              "   'max_depth': 10,\n",
              "   'min_child_samples': 80,\n",
              "   'n_iter_no_change': 10,\n",
              "   'num_iterations': 1000,\n",
              "   'num_leave': 10,\n",
              "   'reg_alpha': 50,\n",
              "   'reg_lambda': 5,\n",
              "   'scale_pos_weight': 50.0,\n",
              "   'subsample': 0.8},\n",
              "  'validation score': 0.9021447915521081},\n",
              " {'Cross-val score': 0.8961590358829536,\n",
              "  'classifier': sklearn.ensemble._bagging.BaggingClassifier,\n",
              "  'parameters': {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                          max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                          random_state=None, splitter='best'),\n",
              "   'n_estimators': 30,\n",
              "   'oob_score': True,\n",
              "   'random_state': 1},\n",
              "  'validation score': 0.8989057692956279},\n",
              " {'Cross-val score': 0.889145641582062,\n",
              "  'classifier': sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier,\n",
              "  'parameters': {'l2_regularization': 0.0,\n",
              "   'learning_rate': 0.029641454778718972,\n",
              "   'max_bins': 100,\n",
              "   'max_depth': 10,\n",
              "   'max_iter': 175,\n",
              "   'max_leaf_nodes': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'n_iter_no_change': None,\n",
              "   'tol': 1e-07,\n",
              "   'validation_fraction': 0.1},\n",
              "  'validation score': 0.8890387314781489},\n",
              " {'Cross-val score': 0.8862456887587555,\n",
              "  'classifier': sklearn.ensemble._forest.ExtraTreesClassifier,\n",
              "  'parameters': {'criterion': 'entropy',\n",
              "   'max_depth': 15,\n",
              "   'max_features': 15,\n",
              "   'min_samples_leaf': 12,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  'validation score': 0.8818171380065061},\n",
              " {'Cross-val score': 0.8846250315039053,\n",
              "  'classifier': sklearn.ensemble._forest.RandomForestClassifier,\n",
              "  'parameters': {'criterion': 'entropy',\n",
              "   'max_depth': 14,\n",
              "   'max_features': 'auto',\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 6,\n",
              "   'n_estimators': 45},\n",
              "  'validation score': 0.8835185140616291}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro64pK_AQBNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "param_hyperopt1= {\n",
        "  'HistGradientBoostingClassifier':\n",
        "            {'learning_rate': hp.loguniform('c3_learning_rate', np.log(0.01), np.log(0.1)),\n",
        "                'max_iter': ho_scope.int(hp.quniform('c3_max_iter', 10, 600, 5)),\n",
        "                'max_depth': ho_scope.int(hp.quniform('c3_max_depth', 2,14, 1)),\n",
        "                'max_leaf_nodes': ho_scope.int(hp.quniform('c3_max_leaf_nodes', 5, 35,5)),\n",
        "                'min_samples_leaf': ho_scope.int(hp.quniform('c3_min_samples_leaf', 5, 25,5)),\n",
        "                'max_bins': ho_scope.int(hp.quniform('c3_max_bins', 20, 200,20)),\n",
        "                'validation_fraction':0.1,\n",
        "                'n_iter_no_change':None,\n",
        "                 'tol':1e-07,\n",
        "                'l2_regularization':0.0 \n",
        "           }\n",
        "       \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2,random_state = 0)\n",
        "def f_clf1(params):\n",
        "  model6 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),\n",
        "             ('HistGradientBoostingClassifier',HistGradientBoostingClassifier(**f_unpack_dict(params['HistGradientBoostingClassifier'])))])\n",
        "  return model6    \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf1(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf1 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2), param_hyperopt1, algo=tpe.suggest, max_evals=10,\n",
        "                 trials=trials, rstate=np.random.RandomState(1))\n",
        "clf1 = f_clf1(space_eval(param_hyperopt1, best_clf1)).fit(X_train2, y_train2)\n",
        "# Calculating performance on validation set\n",
        "y_score = clf1.predict_proba(X_test2)\n",
        "clf1_val_score = roc_auc_score(y_test2, y_score[:,1])\n",
        "#clf2_val_score = model_selection.cross_val_score(f_clf2, X_train2,  y_train2, cv=5, scoring='roc_auc')\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf1_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(space_eval(param_hyperopt, best_clf1))\n",
        "a1=space_eval(param_hyperopt1, best_clf1)\n",
        "Fr_classifier={'classifier':list(a1.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf1_val_score,'parameters':list(a1.values())[0]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azd6FkhgUPtB",
        "colab_type": "code",
        "outputId": "744052d9-c38d-49a5-f323-fd39eee31fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "Fr_classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8890878006805651,\n",
              " 'classifier': 'HistGradientBoostingClassifier',\n",
              " 'parameters': {'l2_regularization': 0.0,\n",
              "  'learning_rate': 0.029641454778718972,\n",
              "  'max_bins': 100,\n",
              "  'max_depth': 10,\n",
              "  'max_iter': 175,\n",
              "  'max_leaf_nodes': 20,\n",
              "  'min_samples_leaf': 15,\n",
              "  'n_iter_no_change': None,\n",
              "  'tol': 1e-07,\n",
              "  'validation_fraction': 0.1},\n",
              " 'validation score': 0.889389222120687}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkp-7STuMRJ7",
        "colab_type": "code",
        "outputId": "ab8b962a-4393-4505-c16b-1798bd0564f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "param_hyperopt1= {\n",
        "   'ExtraTreesClassifier':\n",
        "            {\n",
        "                'max_depth': ho_scope.int(hp.quniform('c4_max_depth', 5, 20, 5)),\n",
        "                'n_estimators': ho_scope.int(hp.quniform('c4_n_estimators', 5, 200, 5)),\n",
        "                'max_features': ho_scope.int(hp.quniform('c4_max_features', 5, 20, 5)),\n",
        "                'criterion': hp.choice('c4_criterion', ['gini', 'entropy']),\n",
        "                'min_samples_split': ho_scope.int(hp.quniform('c4_min_samples_split', 2, 20,2)),\n",
        "                'min_samples_leaf': ho_scope.int(hp.quniform('c4_min_samples_leaf', 2, 20,2))      \n",
        "             }     \n",
        "       \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2,random_state = 0)\n",
        "def f_clf1(params):\n",
        "  model6 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),\n",
        "             ('ExtraTreesClassifier',ExtraTreesClassifier(**f_unpack_dict(params['ExtraTreesClassifier'])))])\n",
        "  return model6    \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf1(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf1 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2), param_hyperopt1, algo=tpe.suggest, max_evals=10,\n",
        "                 trials=trials, rstate=np.random.RandomState(1))\n",
        "clf1 = f_clf1(space_eval(param_hyperopt1, best_clf1)).fit(X_train2, y_train2)\n",
        "# Calculating performance on validation set\n",
        "y_score = clf1.predict_proba(X_test2)\n",
        "clf1_val_score = roc_auc_score(y_test2, y_score[:,1])\n",
        "#clf2_val_score = model_selection.cross_val_score(f_clf2, X_train2,  y_train2, cv=5, scoring='roc_auc')\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf1_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(space_eval(param_hyperopt, best_clf1))\n",
        "a1=space_eval(param_hyperopt1, best_clf1)\n",
        "Fr_classifier={'classifier':list(a1.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf1_val_score,'parameters':list(a1.values())[0]}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [20:06<20:40, 248.16s/it, best loss: -0.8690808879799544]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [46:45<05:30, 330.18s/it, best loss: -0.8872052232768184]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10/10 [50:27<00:00, 297.73s/it, best loss: -0.8872052232768184]\n",
            "Cross-val score: 0.88721; validation score: 0.88559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha8jZBOPyWoB",
        "colab_type": "code",
        "outputId": "bd66493f-4c27-4ff7-f165-5fdfaa443766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "Fr_classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8872052232768184,\n",
              " 'classifier': 'ExtraTreesClassifier',\n",
              " 'parameters': {'criterion': 'entropy',\n",
              "  'max_depth': 15,\n",
              "  'max_features': 15,\n",
              "  'min_samples_leaf': 16,\n",
              "  'min_samples_split': 16,\n",
              "  'n_estimators': 65},\n",
              " 'validation score': 0.885587100775846}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxF_ty_pK5vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Fr_classifier={'Cross-val score': 0.8872052232768184,\n",
        " 'classifier': 'ExtraTreesClassifier',\n",
        " 'parameters': {'criterion': 'entropy',\n",
        "  'max_depth': 15,\n",
        "  'max_features': 15,\n",
        "  'min_samples_leaf': 16,\n",
        "  'min_samples_split': 16,\n",
        "  'n_estimators': 65},\n",
        " 'validation score': 0.885587100775846}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiM49RkuqGq3",
        "colab_type": "code",
        "outputId": "12696a15-11b4-4e42-ed58-c6f9b819fdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "param_hyperopt2= {\n",
        "  'RandomForestClassifier': \n",
        "            {\n",
        "            'max_depth': ho_scope.int(hp.quniform('c2_max_depth', 5, 30, 5)),\n",
        "            'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 10, 50, 10)),\n",
        "            'max_features': hp.choice('c2_max_features', ['auto', 'sqrt']),\n",
        "            'criterion': hp.choice('c2_criterion', ['gini', 'entropy']),\n",
        "            'min_samples_split': ho_scope.int(hp.quniform('c2_min_samples_split', 5, 20,5)),\n",
        "            'min_samples_leaf': ho_scope.int(hp.quniform('c2_min_samples_leaf', 5, 20,5))\n",
        "                          \n",
        "         } \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf2(params):\n",
        "  model4 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),('RandomForestClassifier',RandomForestClassifier(**f_unpack_dict(params['RandomForestClassifier'])))])\n",
        "  return model4    \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf2(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf2 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                 param_hyperopt2, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf2 = f_clf2(space_eval(param_hyperopt2, best_clf2)).fit(X_train2, y_train2)\n",
        "# Calculating performance on validation set\n",
        "y_score = clf2.predict_proba(X_test2)\n",
        "clf2_val_score = roc_auc_score(y_test2, y_score[:,1])\n",
        "#clf2_val_score = model_selection.cross_val_score(f_clf2, X_train2,  y_train2, cv=5, scoring='roc_auc')\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf2_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a2=space_eval(param_hyperopt2, best_clf2)\n",
        "Se_classifier={'classifier':list(a2.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf2_val_score,'parameters':list(a2.values())[0]}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [04:30<16:09, 121.20s/it, best loss: -0.8958777264023634]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [10:13<14:38, 146.40s/it, best loss: -0.8975299639454495]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [21:59<10:26, 208.84s/it, best loss: -0.901158842931584]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [25:57<00:00, 129.26s/it, best loss: -0.901158842931584]\n",
            "Cross-val score: 0.90116; validation score: 0.90359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_cLstq3kPbq",
        "colab_type": "code",
        "outputId": "ae91eb7e-9603-4577-b04d-ce1f8e52a200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "Se_classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.9026289374390334,\n",
              " 'classifier': 'RandomForestClassifier',\n",
              " 'parameters': {'criterion': 'entropy',\n",
              "  'max_depth': 28,\n",
              "  'max_features': 'auto',\n",
              "  'min_samples_leaf': 2,\n",
              "  'min_samples_split': 8,\n",
              "  'n_estimators': 80},\n",
              " 'validation score': 0.9047946424340776}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Qo9loEyJ9x",
        "colab_type": "code",
        "outputId": "484342be-24f6-446d-a6e1-24526623b584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "best_clf2\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c2_criterion': 1,\n",
              " 'c2_max_depth': 10.0,\n",
              " 'c2_max_features': 0,\n",
              " 'c2_min_samples_leaf': 2.0,\n",
              " 'c2_min_samples_split': 4.0,\n",
              " 'c2_n_estimators': 35.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKMWqZQ8L3JV",
        "colab_type": "code",
        "outputId": "1980a0fb-2cd6-454b-d62e-17de2747336a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "param_hyperopt3= {      \n",
        "       'BaggingClassifier':\n",
        "            {      \n",
        "             'base_estimator': hp.choice('base_estimator',[DecisionTreeClassifier(**AA_classifier['parameters'])]),\n",
        "              'n_estimators': ho_scope.int(hp.quniform('n_estimators', 5, 45,15)),\n",
        "              'oob_score': hp.choice('oob_score', [True,False]),\n",
        "               'random_state': 1\n",
        "            }\n",
        "                  \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf3(params):\n",
        "   model1 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),('BaggingClassifier', BaggingClassifier(**f_unpack_dict(params['BaggingClassifier'])))])   \n",
        "   return model1\n",
        "        \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf3(params)\n",
        "    shuffle = KFold(n_splits=5, shuffle=True)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=shuffle,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf3 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt3, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf3 = f_clf3(space_eval(param_hyperopt3, best_clf3)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf3_val_score = roc_auc_score(y_test, clf3.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf3_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt3, best_clf3))\n",
        "# Calculating performance on validation set\n",
        "clf3_val_score = roc_auc_score(y_test, clf3.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf3_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a3=space_eval(param_hyperopt3, best_clf3)\n",
        "Thrid_classifier={'classifier':list(a3.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf3_val_score,'parameters':list(a3.values())[0]}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [25:38<00:00, 125.03s/it, best loss: -0.8958560698166602]\n",
            "Cross-val score: 0.89586; validation score: 0.90506\n",
            "Best parameters:\n",
            "{'BaggingClassifier': {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
            "                       max_depth=35, max_features='sqrt', max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=25, min_samples_split=20,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), 'n_estimators': 30, 'oob_score': False, 'random_state': 1}}\n",
            "Cross-val score: 0.89586; validation score: 0.90506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-AC9k5VLzSY",
        "colab_type": "code",
        "outputId": "70ecde8f-4e17-4b5f-9b6e-b36238505ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "Thrid_classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8983805004954327,\n",
              " 'classifier': 'BaggingClassifier',\n",
              " 'parameters': {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                         max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=1, min_samples_split=2,\n",
              "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                         random_state=None, splitter='best'),\n",
              "  'n_estimators': 50,\n",
              "  'oob_score': True,\n",
              "  'random_state': 1},\n",
              " 'validation score': 0.9305090729151654}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isvNltHIFgwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Se_classifier={'Cross-val score': 0.901158842931584,\n",
        " 'classifier': 'RandomForestClassifier',\n",
        " 'parameters': {'criterion': 'entropy',\n",
        "  'max_depth': 30,\n",
        "  'max_features': 'auto',\n",
        "  'min_samples_leaf': 5,\n",
        "  'min_samples_split': 10,\n",
        "  },\n",
        " 'validation score': 0.9035936842810743}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB0p-1daEvuD",
        "colab_type": "code",
        "outputId": "36ef8c27-6951-4632-83c8-ff59a2d20fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "param_hyperopt3= {      \n",
        "       'BaggingClassifier':\n",
        "            {      \n",
        "             'base_estimator': hp.choice('base_estimator',[DecisionTreeClassifier(**AA_classifier['parameters'])]),\n",
        "              'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 5, 40, 10)),\n",
        "              'oob_score': hp.choice('oob_score', [True,False]),\n",
        "               'random_state': 1\n",
        "            }\n",
        "                \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf3(params):\n",
        "   model1 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),('BaggingClassifier', BaggingClassifier(**f_unpack_dict(params['BaggingClassifier'])))])   \n",
        "   return model1\n",
        "        \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf3(params)\n",
        "    shuffle = KFold(n_splits=5, shuffle=True)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=shuffle,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf3 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt3, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf3 = f_clf3(space_eval(param_hyperopt3, best_clf3)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf3_val_score = roc_auc_score(y_test, clf3.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf3_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt3, best_clf3))\n",
        "# Calculating performance on validation set\n",
        "clf3_val_score = roc_auc_score(y_test, clf3.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf3_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a3=space_eval(param_hyperopt3, best_clf3)\n",
        "Thrid_classifier={'classifier':list(a3.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf3_val_score,'parameters':list(a3.values())[0]}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [22:02<00:00, 119.53s/it, best loss: -0.8980952114989929]\n",
            "Cross-val score: 0.89810; validation score: 0.90737\n",
            "Best parameters:\n",
            "{'BaggingClassifier': {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
            "                       max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=5, min_samples_split=30,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), 'n_estimators': 40, 'oob_score': False, 'random_state': 1}}\n",
            "Cross-val score: 0.89810; validation score: 0.90737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j37o6YxZZgrL",
        "colab_type": "code",
        "outputId": "b3ea3d50-4f57-4ed9-c1a5-4bfc51091fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "Thrid_classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8980952114989929,\n",
              " 'classifier': 'BaggingClassifier',\n",
              " 'parameters': {'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                         max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=5, min_samples_split=30,\n",
              "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                         random_state=None, splitter='best'),\n",
              "  'n_estimators': 40,\n",
              "  'oob_score': False,\n",
              "  'random_state': 1},\n",
              " 'validation score': 0.9073684562295977}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O2unkUj6im8",
        "colab_type": "code",
        "outputId": "21d97e67-3c21-471a-8dd3-30bb6864ffcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.utils import shuffle\n",
        "param_hyperopt3= {      \n",
        "       'AdaBoostClassifier':\n",
        "   {\n",
        "         'base_estimator':hp.choice('base_estimator', [DecisionTreeClassifier(**AA_classifier['parameters'])]),\n",
        "          'learning_rate': hp.loguniform('c5_learning_rate', np.log(0.01), np.log(1)),\n",
        "          'n_estimators': ho_scope.int(hp.quniform('c5_n_estimators', 20, 60, 20)),\n",
        "          'algorithm': hp.choice('c5_algorithm',[\"SAMME\"])  \n",
        "       }\n",
        "                \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf3(params):\n",
        "   model1 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),('AdaBoostClassifier', AdaBoostClassifier(**f_unpack_dict(params['AdaBoostClassifier'])))])   \n",
        "   return model1\n",
        "        \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf3(params)\n",
        "    shuffle = KFold(n_splits=5, shuffle=True)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=shuffle,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf3 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt3, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf3 = f_clf3(space_eval(param_hyperopt3, best_clf3)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf3_val_score = roc_auc_score(y_test, clf3.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf3_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt3, best_clf3))\n",
        "# Calculating performance on validation set\n",
        "clf3_val_score = roc_auc_score(y_test, clf3.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf3_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a3=space_eval(param_hyperopt3, best_clf3)\n",
        "fifth_classifier={'classifier':list(a3.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf3_val_score,'parameters':list(a3.values())[0]}\n",
        "fifth_classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [31:08<30:40, 368.14s/it, best loss: -0.898711052250753] \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2ef2912f0778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m best_clf3 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n\u001b[0;32m---> 57\u001b[0;31m                 param_hyperopt3, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mclf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_clf3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_hyperopt3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_clf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-2ef2912f0778>\u001b[0m in \u001b[0;36mobjective_function\u001b[0;34m(params, X_train2, y_train2)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_clf3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'status'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ZkDVZl8N3H",
        "colab_type": "code",
        "outputId": "f5be2124-01bf-415b-b075-7ec9250df240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "AdaBoostClassifier(),DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                    n_estimators=50, random_state=None),\n",
              " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                        max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                        random_state=None, splitter='best'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv4WPj9XX5OS",
        "colab_type": "code",
        "outputId": "574f1cb6-df71-4c2e-de27-2b844774672f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "import xgboost as xgb\n",
        "\n",
        "param_hyperopt4= {\n",
        "  'XGBClassifier':\n",
        "      {\n",
        "           'max_depth': ho_scope.int(hp.quniform('c16_max_depth', 5, 15, 5)),\n",
        "           'min_child_weight': hp.choice ('x_min_child',np.arange(1, 10, dtype=int)),\n",
        "           'subsample': hp.uniform ('x_subsample', 0.2, 1),\n",
        "           'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 5, 45, 15)),\n",
        "       }         \n",
        "       \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "def f_clf4(params):\n",
        "   model1 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),('XGBClassifier', xgb.XGBClassifier())])   \n",
        "   return model1  \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf4(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf4 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt4, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf4 = f_clf4(space_eval(param_hyperopt4, best_clf4)).fit(X_train2, y_train2)\n",
        "# Calculating performance on validation set\n",
        "clf4_val_score = roc_auc_score(y_test, clf4.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf4_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a4=space_eval(param_hyperopt4, best_clf4)\n",
        "Four_classifier={'classifier':list(a4.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf4_val_score,'parameters':list(a4.values())[0]}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [03:11<28:42, 191.36s/it, best loss: -0.8774978395308153]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [06:26<25:39, 192.48s/it, best loss: -0.8774978395308153]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [09:38<22:25, 192.27s/it, best loss: -0.8774978395308153]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [12:51<19:15, 192.63s/it, best loss: -0.8774978395308153]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [16:03<16:01, 192.33s/it, best loss: -0.8774978395308153]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [19:15<12:48, 192.16s/it, best loss: -0.8774978395308153]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [25:44<06:27, 193.70s/it, best loss: -0.8774978395308153]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [29:01<03:14, 194.72s/it, best loss: -0.8774978395308153]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10/10 [32:21<00:00, 196.06s/it, best loss: -0.8774978395308153]\n",
            "Cross-val score: 0.87750; validation score: 0.87816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmuOPHfZZL9T",
        "colab_type": "code",
        "outputId": "56963711-3dbd-4674-e8d5-b749c222d5ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Four_classifier\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8774978395308153,\n",
              " 'classifier': 'XGBClassifier',\n",
              " 'parameters': {'max_depth': 10,\n",
              "  'min_child_weight': 8,\n",
              "  'n_estimators': 15,\n",
              "  'subsample': 0.3916405019248916},\n",
              " 'validation score': 0.8781637598970042}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6WfRi1-5dev",
        "colab_type": "code",
        "outputId": "d97dd3f5-fc89-4682-da8d-c6db801bb718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "import lightgbm as lgb\n",
        "from functools import partial\n",
        "\n",
        "param_hyperopt5= {\n",
        "   'LGBMClassifier1':\n",
        "                  {\n",
        "                   'max_depth': ho_scope.int(hp.quniform('c16_max_depth', -2, 10, 1)),\n",
        "                   'num_leave': ho_scope.int(hp.quniform('c16_num_leaves', 10, 200, 10)),\n",
        "                   'min_child_samples': ho_scope.int(hp.quniform('c16_min_child_samples', 10, 90, 10)),\n",
        "                   'scale_pos_weight': ho_scope.int(hp.quniform('c16_scale_pos_weight', 10, 90, 10)),\n",
        "                   'subsample': ho_scope.float(hp.quniform('c16_subsample', 0.1, 0.9, 0.1)),\n",
        "                   'colsample_bytree': ho_scope.float(hp.quniform('c16_colsample_bytree', 0.1, 0.9, 0.1)),\n",
        "                   'reg_lambda': hp.choice(\"c16_reg_lambda\",[0, 1e-1, 1, 5, 10, 20, 50]),\n",
        "                   'reg_alpha': hp.choice(\"c16_reg_alpha\",[0, 1e-1, 1, 5, 10, 20, 50]),\n",
        "                   'bagging_fraction': ho_scope.float(hp.quniform('c16_bagging_fraction', 0.1, 0.9, 0.05)),\n",
        "                    'bagging_freq': ho_scope.int(hp.quniform('c6_bagging_freq', 1, 8, 1)),\n",
        "                   'min_data_in_leaf': ho_scope.int(hp.quniform('c16_min_data_in_leaf', 100, 1000, 100)),\n",
        "                  'min_sum_hessian_in_leaf': ho_scope.int(hp.quniform('c16_min_sum_hessian_in_leaf', 5, 20, 5)),\n",
        "                   'max_bin': ho_scope.int(hp.quniform('c16_max_bin', 10, 100, 10)),\n",
        "                   'learning_rate': ho_scope.float(hp.quniform('c16_learning_rate', 0.001, 0.09, 0.005)),\n",
        "                   'num_iterations': ho_scope.int(hp.quniform('c16_num_iterations', 100, 10000, 100)),\n",
        "                   'n_iter_no_change':10\n",
        "                       },\n",
        "                  \n",
        "                   'LGBMClassifier':\n",
        "                  {\n",
        "                     'max_depth': ho_scope.int(hp.quniform('c6_max_depth', 2, 14, 2)),\n",
        "                   'num_leave': ho_scope.int(hp.quniform('c6_num_leaves', 5, 30, 5)),\n",
        "                   'min_child_samples': ho_scope.int(hp.quniform('c6_min_child_samples', 50, 100, 10)),\n",
        "                   'scale_pos_weight': ho_scope.float(hp.quniform('c6_scale_pos_weight', 50, 100, 10)),\n",
        "                   'subsample': ho_scope.float(hp.quniform('c6_subsample', 0.2, 0.9, 0.1)),\n",
        "                   'colsample_bytree': ho_scope.float(hp.quniform('c6_colsample_bytree', 0.2, 0.9, 0.1)),\n",
        "                   'reg_lambda': hp.choice(\"c6_reg_lambda\",[0, 1e-1, 1, 5, 10, 20, 50]),\n",
        "                   'reg_alpha': hp.choice(\"c6_reg_alpha\",[0, 1e-1, 1, 5, 10, 20, 50]) ,\n",
        "                   'max_bin': ho_scope.int(hp.quniform('c6_max_bin', 10, 200, 10)),\n",
        "                   'learning_rate': ho_scope.float(hp.quniform('c6_learning_rate', 0.001, 0.09, 0.005)),\n",
        "                   'num_iterations': ho_scope.int(hp.quniform('c6_num_iterations', 100, 2000, 100)),\n",
        "                    'n_iter_no_change':10,\n",
        "                   'metric' : 'binary_error'\n",
        "                   }     \n",
        "} \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "def f_clf5(params):\n",
        "   model1 =Pipeline(steps=[('encoder',ce.cat_boost.CatBoostEncoder()),('LGBMClassifier', \n",
        "                                                         lgb.LGBMClassifier(**f_unpack_dict(params['LGBMClassifier'])))])   \n",
        "   return model1  \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf5(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf5 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt5, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf5 = f_clf5(space_eval(param_hyperopt5, best_clf5)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf5_val_score = roc_auc_score(y_test, clf5.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf5_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a5=space_eval(param_hyperopt5, best_clf5)\n",
        "fith_classifier={'classifier':list(a5.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf5_val_score,'parameters':list(a5.values())[0]}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [04:40<42:06, 280.74s/it, best loss: -0.8997379383173877]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [36:57<00:00, 241.33s/it, best loss: -0.9012358759310123]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cross-val score: 0.90124; validation score: 0.90335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5RjjjioGC-e",
        "colab_type": "code",
        "outputId": "66fcbba0-567f-4547-d752-462863733938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "fith_classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.9012358759310123,\n",
              " 'classifier': 'LGBMClassifier',\n",
              " 'parameters': {'colsample_bytree': 0.5,\n",
              "  'learning_rate': 0.09,\n",
              "  'max_bin': 80,\n",
              "  'max_depth': 10,\n",
              "  'metric': 'binary_error',\n",
              "  'min_child_samples': 80,\n",
              "  'n_iter_no_change': 10,\n",
              "  'num_iterations': 1000,\n",
              "  'num_leave': 10,\n",
              "  'reg_alpha': 50,\n",
              "  'reg_lambda': 5,\n",
              "  'scale_pos_weight': 50.0,\n",
              "  'subsample': 0.8},\n",
              " 'validation score': 0.9033486822173652}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn4Xx2mh_YYt",
        "colab_type": "code",
        "outputId": "31687cf8-02ed-4631-c6e5-a1fcb0f6eeb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "fith_classifier['parameters']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.5,\n",
              " 'learning_rate': 0.09,\n",
              " 'max_bin': 80,\n",
              " 'max_depth': 10,\n",
              " 'metric': 'binary_error',\n",
              " 'min_child_samples': 80,\n",
              " 'n_iter_no_change': 10,\n",
              " 'num_iterations': 1000,\n",
              " 'num_leave': 10,\n",
              " 'reg_alpha': 50,\n",
              " 'reg_lambda': 5,\n",
              " 'scale_pos_weight': 50.0,\n",
              " 'subsample': 0.8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cgd1WCfT9JN",
        "colab_type": "code",
        "outputId": "d0347250-5bef-4e9f-8429-558d3a0cd90e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpJXkL-3TzNp",
        "colab_type": "code",
        "outputId": "e336595c-3631-48ba-cbaf-94bbb48333df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "AA_classifier['parameters']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8407488723057787,\n",
              " 'classifier': 'DecisionTreeClassifier',\n",
              " 'parameters': {'max_depth': 14,\n",
              "  'max_features': 'sqrt',\n",
              "  'min_samples_leaf': 12,\n",
              "  'min_samples_split': 12},\n",
              " 'validation score': 0.8755575889142267}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3If0WbQtPcQM",
        "colab_type": "code",
        "outputId": "b9cd8772-57f9-4646-ad28-db0027affb3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "param_hyperopt6= {\n",
        "    'QuadraticDiscriminantAnalysis':\n",
        "      {\n",
        "           \n",
        "      }      \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf6(params):\n",
        "   model3 =Pipeline(steps=[('encoder',Accepted[5][1]()),('QuadraticDiscriminantAnalysis',QuadraticDiscriminantAnalysis())])\n",
        "   return model3 \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf6(params)\n",
        "    #clf = RandomForestClassifier(**params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf6 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt6, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "\n",
        "clf6 = f_clf6(space_eval(param_hyperopt6, best_clf6)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf6_val_score = roc_auc_score(y_test, clf6.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.format(-trials.best_trial['result']['loss'], clf6_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt6, best_clf6))\n",
        "# Calculating performance on validation set\n",
        "clf6_val_score = roc_auc_score(y_test, clf6.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf6_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a6=space_eval(param_hyperopt6, best_clf6)\n",
        "six_classifier={'classifier':list(a6.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf6_val_score,'parameters':list(a6.values())[0]}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:04<00:00, 12.22s/it, best loss: -0.7861718985031253]\n",
            "Cross-val score: 0.78617; validation score: 0.78727\n",
            "Best parameters:\n",
            "{'QuadraticDiscriminantAnalysis': {}}\n",
            "Cross-val score: 0.78617; validation score: 0.78727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oUvZj4cvDNH",
        "colab_type": "code",
        "outputId": "0ea89023-2184-4be9-fed7-d9b4d7759c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
        "# now you can import normally from ensemble\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "pipe1 = make_pipeline(Accepted[3][1](),XGBClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())  \n",
        "pipe3 = make_pipeline(Accepted[0][1](),ExtraTreesClassifier()) \n",
        "pipe6 = make_pipeline(Accepted[4][1](),lgb.LGBMClassifier(**fith_classifier['parameters'])) \n",
        "pipe4 = make_pipeline(Accepted[2][1](),HistGradientBoostingClassifier())\n",
        "pipe5 = make_pipeline(Accepted[5][1](),QuadraticDiscriminantAnalysis())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5], meta_classifier=LogisticRegression()) \n",
        "model2=sclf2.fit(X_train2, y_train2)\n",
        "y_true3, y_pred3  =y_test2, model2.predict(X_test2)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train2, y_train2))\n",
        "clf2_val_score = roc_auc_score(y_test2, sclf2.predict_proba(X_test2)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b7d907e5ff4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mpipe1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccepted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mpipe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccepted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mpipe3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccepted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Accepted' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZRFjh3jzf8x",
        "colab_type": "code",
        "outputId": "31834de4-363c-4746-9188-bff9785af0a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
        "# now you can import normally from ensemble\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())  \n",
        "pipe3 = make_pipeline(Accepted[0][1](),ExtraTreesClassifier()) \n",
        "pipe6 = make_pipeline(Accepted[3][1](),lgb.LGBMClassifier(**)) \n",
        "pipe4 = make_pipeline(Accepted[2][1](),HistGradientBoostingClassifier())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe2,pipe3,pipe4,pipe6], meta_classifier=LogisticRegression()) \n",
        "model2=sclf2.fit(X_train2, y_train2)\n",
        "y_true3, y_pred3  =y_test2, model2.predict(X_test2)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train2, y_train2))\n",
        "clf2_val_score = roc_auc_score(y_test2, sclf2.predict_proba(X_test2)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.77      0.77     94841\n",
            "           1       0.82      0.81      0.81    120517\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.79      0.79      0.79    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "StackingClassifier score: 0.913729\n",
            "Cross-val score: 0.86096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DFF7PDGoM7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
        "# now you can import normally from ensemble\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "pipe1 = make_pipeline(Accepted[3][1](),XGBClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())  \n",
        "pipe3 = make_pipeline(Accepted[0][1](),ExtraTreesClassifier()) \n",
        "pipe6 = make_pipeline(Accepted[4][1](),lgb.LGBMClassifier()) \n",
        "pipe4 = make_pipeline(Accepted[2][1](),HistGradientBoostingClassifier())\n",
        "pipe5 = make_pipeline(Accepted[5][1](), BaggingClassifier(DecisionTreeClassifier()) )\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5], meta_classifier=LogisticRegression()) \n",
        "model2=sclf2.fit(X_train2, y_train2)\n",
        "y_true3, y_pred3  =y_test2, model2.predict(X_test2)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train2, y_train2))\n",
        "clf2_val_score = roc_auc_score(y_test2, sclf2.predict_proba(X_test2)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA4P3yftv5VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Fr_classifier={'Cross-val score': 0.8755075622861487,\n",
        " 'classifier': 'ExtraTreesClassifier',\n",
        " 'parameters': {'criterion': 'entropy',\n",
        "  'max_depth': 15,\n",
        "  'max_features': 13,\n",
        "  'min_samples_leaf': 4,\n",
        "  'min_samples_split': 4,\n",
        "  'n_estimators': 13},\n",
        " 'validation score': 0.884938764808794}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72q7zxSvwQK6",
        "colab_type": "code",
        "outputId": "367c1766-0447-4db5-c048-a6e2f9b376a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "Fr_classifier['parameters']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 15,\n",
              " 'max_features': 13,\n",
              " 'min_samples_leaf': 4,\n",
              " 'min_samples_split': 4,\n",
              " 'n_estimators': 13}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT1x5xQ-vWFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Se_classifier={'Cross-val score': 0.8273926245659394,\n",
        " 'classifier': 'RandomForestClassifier',\n",
        " 'parameters': {'criterion': 'gini',\n",
        "  'max_depth': 7,\n",
        "  'max_features': 'auto',\n",
        "  'min_samples_leaf': 2,\n",
        "  'min_samples_split': 3,\n",
        "  'n_estimators': 23},\n",
        " 'validation score': 0.7973701565847332}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jb9jiievacj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Thrid_classifier={'Cross-val score': 0.8268064630182487,\n",
        " 'classifier': 'LinearDiscriminantAnalysis',\n",
        " 'parameters': {},\n",
        " 'validation score': 0.827194350739109}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWLcgpDlvecC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Four_classifier={'Cross-val score': 0.8761819849027198,\n",
        " 'classifier': 'XGBClassifier',\n",
        " 'parameters': {'max_depth': 7,\n",
        "  'min_child_weight': 1,\n",
        "  'n_estimators': 38,\n",
        "  'subsample': 0.8479101254812229},\n",
        " 'validation score': 0.8770024548105813}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT7GCH_evh_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fith_classifier={'Cross-val score': 0.8931760781045686,\n",
        " 'classifier': 'LGBMClassifier',\n",
        " 'parameters': {'colsample_bytree': 1.0,\n",
        "  'max_depth': 9,\n",
        "  'min_child_samples': 70,\n",
        "  'num_leave': 10,\n",
        "  'reg_alpha': 5,\n",
        "  'reg_lambda': 20,\n",
        "  'scale_pos_weight': 50.0,\n",
        "  'subsample': 1.0},\n",
        " 'validation score': 0.8944420319608248}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOeAy9aqvmT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "six_classifier={'Cross-val score': 0.786171897798788,\n",
        " 'classifier': 'QuadraticDiscriminantAnalysis',\n",
        " 'parameters': {},\n",
        " 'validation score': 0.787235957146868}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoY5YxNhSY0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a8={'ExtraTreesClassifier': {'criterion': 'gini',\n",
        "  'max_depth': 7,\n",
        "  'max_features': 7,\n",
        "  'min_samples_leaf': 4,\n",
        "  'min_samples_split': 4,\n",
        "  'n_estimators': 19},\n",
        " 'LGBMClassifier': {'colsample_bytree': 1.0,\n",
        "  'max_depth': 7,\n",
        "  'min_child_samples': 80,\n",
        "  'num_leave': 50,\n",
        "  'reg_alpha': 0,\n",
        "  'reg_lambda': 10,\n",
        "  'scale_pos_weight': 70.0,\n",
        "  'subsample': 1.0},\n",
        " 'RandomForestClassifier': {'criterion': 'entropy',\n",
        "  'max_depth': 5,\n",
        "  'max_features': 'sqrt',\n",
        "  'min_samples_leaf': 3,\n",
        "  'min_samples_split': 2,\n",
        "  'n_estimators': 30},\n",
        " 'XGBClassifier': {'max_depth': 13,\n",
        "  'min_child_weight': 3,\n",
        "  'subsample': 0.9406880083709813}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQZrDLCO4tzY",
        "colab_type": "code",
        "outputId": "c582b68c-85a5-4e0b-8489-5f14779fcd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "{'ExtraTreesClassifier': {'criterion': 'gini',\n",
        "  'max_depth': 7,\n",
        "  'max_features': 7,\n",
        "  'min_samples_leaf': 4,\n",
        "  'min_samples_split': 4,\n",
        "  'n_estimators': 19},\n",
        " 'LGBMClassifier': {'colsample_bytree': 1.0,\n",
        "  'max_depth': 7,\n",
        "  'min_child_samples': 80,\n",
        "  'num_leave': 50,\n",
        "  'reg_alpha': 0,\n",
        "  'reg_lambda': 10,\n",
        "  'scale_pos_weight': 70.0,\n",
        "  'subsample': 1.0},\n",
        " 'RandomForestClassifier': {'criterion': 'entropy',\n",
        "  'max_depth': 5,\n",
        "  'max_features': 'sqrt',\n",
        "  'min_samples_leaf': 3,\n",
        "  'min_samples_split': 2,\n",
        "  'n_estimators': 30},\n",
        " 'XGBClassifier': {'max_depth': 13,\n",
        "  'min_child_weight': 3,\n",
        "  'subsample': 0.9406880083709813}}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e735912700ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFr_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Fr_classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc6sc6QfbVhx",
        "colab_type": "code",
        "outputId": "29f521ad-9c86-49e6-8b04-a46f03df8b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())\n",
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe6], meta_classifier=LogisticRegression())\n",
        "model2=sclf2.fit(X_train2, y_train2)\n",
        "y_true3, y_pred3  =y_test2, model2.predict(X_test2)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train2, y_train2))\n",
        "clf2_val_score = roc_auc_score(y_test2, sclf2.predict_proba(X_test2)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77     94841\n",
            "           1       0.82      0.80      0.81    120517\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.79      0.79      0.79    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "StackingClassifier score: 0.913023\n",
            "Cross-val score: 0.86650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxWwikwQVEhi",
        "colab_type": "code",
        "outputId": "b3d5b3a5-0fec-48c2-c0b2-1451a54da5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier(**a8['RandomForestClassifier']))  \n",
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier(**a8['ExtraTreesClassifier'])) \n",
        "pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier(**a8['LGBMClassifier'])) \n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe2,pipe3,pipe4,pipe6], meta_classifier=LogisticRegression()) \n",
        "model2=sclf2.fit(X_train2, y_train2)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test2)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train2, y_train2))\n",
        "clf2_val_score = roc_auc_score(y_test2, sclf2.predict_proba(X_test2)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.48      0.46     94433\n",
            "           1       0.56      0.52      0.54    120925\n",
            "\n",
            "    accuracy                           0.50    215358\n",
            "   macro avg       0.50      0.50      0.50    215358\n",
            "weighted avg       0.51      0.50      0.50    215358\n",
            "\n",
            "StackingClassifier score: 0.809074\n",
            "Cross-val score: 0.50016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_NjQ3a2n3HR",
        "colab_type": "code",
        "outputId": "6020a5fe-fbf9-484b-8fac-728a0220d551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "for clf, label in zip([list(sclf2.named_classifiers.keys()),sclf2],[list(a8.keys())]):\n",
        "  for i in range(len(list(a8.keys()))):\n",
        "    if list(a8.keys())[i]  in label:\n",
        "      if (type((sclf2.named_classifiers[clf[0]][1])).__name__)==list(a8.keys())[i]:\n",
        "          pipe1 = make_pipeline(Accepted[0][1](),\n",
        "                                XGBClassifier(**a8[(type((sclf2.named_classifiers[clf[0]][1])).__name__)]))\n",
        "      if (type((sclf2.named_classifiers[clf[1]][1])).__name__)==list(a8.keys())[i]:\n",
        "          pipe2 = make_pipeline(Accepted[1][1](),\n",
        "                                RandomForestClassifier(**a8[(type((sclf2.named_classifiers[clf[1]][1])).__name__)]))  \n",
        "      if (type((sclf2.named_classifiers[clf[2]][1])).__name__)==list(a8.keys())[i]:\n",
        "          pipe3 = make_pipeline(Accepted[2][1](),\n",
        "                                ExtraTreesClassifier(**a8[(type((sclf2.named_classifiers[clf[2]][1])).__name__)])) \n",
        "      if (type((sclf2.named_classifiers[clf[5]][1])).__name__)==list(a8.keys())[i]:\n",
        "          pipe6 = make_pipeline(Accepted[5][1](),\n",
        "                                lgb.LGBMClassifier(**a8[(type((sclf2.named_classifiers[clf[5]][1])).__name__)])) \n",
        "    else:  \n",
        "            pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "            pipe5 = make_pipeline(Accepted[4][1](),QuadraticDiscriminantAnalysis())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6], meta_classifier=LogisticRegression()) \n",
        "model2=sclf2.fit(X_train2, y_train2)\n",
        "y_true3, y_pred3  =y_test2, model2.predict(X_test2)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train2, y_train2))\n",
        "clf2_val_score = roc_auc_score(y_test2, sclf2.predict_proba(X_test2)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.84      0.79     94841\n",
            "           1       0.86      0.78      0.82    120517\n",
            "\n",
            "    accuracy                           0.81    215358\n",
            "   macro avg       0.81      0.81      0.81    215358\n",
            "weighted avg       0.81      0.81      0.81    215358\n",
            "\n",
            "StackingClassifier score: 0.813905\n",
            "Cross-val score: 0.87589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmXql2VSupkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier(**a8['XGBClassifier']))\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier(**a8['RandomForestClassifier']))  \n",
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier(**a8['ExtraTreesClassifier'])) \n",
        "pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier(**a8['LGBMClassifier'])) \n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "pipe5 = make_pipeline(Accepted[4][1](),QuadraticDiscriminantAnalysis())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6], meta_classifier=LogisticRegression()) \n",
        "model2=sclf2.fit(X_train2, y_train2)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test2)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train2, y_train2))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test2)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVt5r7R6nsh3",
        "colab_type": "code",
        "outputId": "e6169280-bbd4-43fe-e1bc-db87afbce428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "a8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ExtraTreesClassifier': {'criterion': 'gini',\n",
              "  'max_depth': 7,\n",
              "  'max_features': 7,\n",
              "  'min_samples_leaf': 4,\n",
              "  'min_samples_split': 4,\n",
              "  'n_estimators': 19},\n",
              " 'LGBMClassifier': {'colsample_bytree': 1.0,\n",
              "  'max_depth': 7,\n",
              "  'min_child_samples': 80,\n",
              "  'num_leave': 50,\n",
              "  'reg_alpha': 0,\n",
              "  'reg_lambda': 10,\n",
              "  'scale_pos_weight': 70.0,\n",
              "  'subsample': 1.0},\n",
              " 'RandomForestClassifier': {'criterion': 'entropy',\n",
              "  'max_depth': 5,\n",
              "  'max_features': 'sqrt',\n",
              "  'min_samples_leaf': 3,\n",
              "  'min_samples_split': 2,\n",
              "  'n_estimators': 30},\n",
              " 'XGBClassifier': {'max_depth': 13,\n",
              "  'min_child_weight': 3,\n",
              "  'subsample': 0.9406880083709813}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsh4A3eZtNDm",
        "colab_type": "code",
        "outputId": "ce2a2c8c-e6da-4b64-e765-8c1c6e23887b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(pipe1.named_steps.keys())[1],list(a8.keys())[0].lower()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('xgbclassifier', 'extratreesclassifier')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyjoLr3s4OzU",
        "colab_type": "code",
        "outputId": "febab780-ac65-4655-aec1-4f82539af121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "a8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ExtraTreesClassifier': {'criterion': 'gini',\n",
              "  'max_depth': 7,\n",
              "  'max_features': 7,\n",
              "  'min_samples_leaf': 4,\n",
              "  'min_samples_split': 4,\n",
              "  'n_estimators': 19},\n",
              " 'LGBMClassifier': {'colsample_bytree': 1.0,\n",
              "  'max_depth': 7,\n",
              "  'min_child_samples': 80,\n",
              "  'num_leave': 50,\n",
              "  'reg_alpha': 0,\n",
              "  'reg_lambda': 10,\n",
              "  'scale_pos_weight': 70.0,\n",
              "  'subsample': 1.0},\n",
              " 'RandomForestClassifier': {'criterion': 'entropy',\n",
              "  'max_depth': 5,\n",
              "  'max_features': 'sqrt',\n",
              "  'min_samples_leaf': 3,\n",
              "  'min_samples_split': 2,\n",
              "  'n_estimators': 30},\n",
              " 'XGBClassifier': {'max_depth': 13,\n",
              "  'min_child_weight': 3,\n",
              "  'subsample': 0.9406880083709813}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS_rBX750WcG",
        "colab_type": "code",
        "outputId": "684e1d1d-3603-4dcd-d668-e03588a3b3e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "for clf, label in zip([list(sclf2.named_classifiers.keys()),sclf2],[list(a8.keys())]):\n",
        "  for i in range(len(list(a8.keys()))):\n",
        "    if list(a8.keys())[i]  in label:\n",
        "      if (type((sclf2.named_classifiers[clf[0]][1])).__name__)==list(a8.keys())[i]:\n",
        "          pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier(**a8[(type((sclf2.named_classifiers[clf[0]][1])).__name__)]))\n",
        "          pipe2\n",
        "      if (type((sclf2.named_classifiers[clf[1]][1])).__name__)==list(a8.keys())[i]:\n",
        "          pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier(**a8[(type((sclf2.named_classifiers[clf[1]][1])).__name__)]))  \n",
        "          pipe2   \n",
        "      if (type((sclf2.named_classifiers[clf[2]][1])).__name__)==list(a8.keys())[i]:\n",
        "          pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier(**a8[(type((sclf2.named_classifiers[clf[2]][1])).__name__)])) \n",
        "      if (type((sclf2.named_classifiers[clf[3]][1])).__name__)==list(a8.keys())[i]:\n",
        "          pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier(**a8[(type((sclf2.named_classifiers[clf[5]][1])).__name__)])) \n",
        "    else:  \n",
        "            pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "            pipe5 = make_pipeline(Accepted[4][1](),QuadraticDiscriminantAnalysis())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6], meta_classifier=LogisticRegression())  \n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('catboostencoder',\n",
              "                 CatBoostEncoder(a=1, cols=None, drop_invariant=False,\n",
              "                                 handle_missing='value', handle_unknown='value',\n",
              "                                 random_state=None, return_df=True, sigma=None,\n",
              "                                 verbose=0)),\n",
              "                ('xgbclassifier',\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=13,\n",
              "                               min_child_weight=3, missing=None,\n",
              "                               n_estimators=100, n_jobs=1, nthread=None,\n",
              "                               objective='binary:logistic', random_state=0,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None,\n",
              "                               subsample=0.9406880083709813, verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVFICfs6qliC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for clf, label in zip([list(sclf2.named_classifiers.keys()),sclf2],[list(a8.keys())]):\n",
        "  if label[0].lower()==list(pipe1.named_steps.keys())[1]:\n",
        "    print(label)\n",
        "\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier())\n",
        "\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())\n",
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "pipe5 = make_pipeline(Accepted[4][1](),QuadraticDiscriminantAnalysis())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiGbF94Mg6XY",
        "colab_type": "code",
        "outputId": "5aa1680c-f325-446f-a5be-4e03b7543f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sclf2.named_classifiers['pipeline-1'][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0,\n",
              "              max_depth={'colsample_bytree': 1.0, 'max_depth': 7,\n",
              "                         'min_child_samples': 80, 'num_leave': 50,\n",
              "                         'reg_alpha': 0, 'reg_lambda': 10,\n",
              "                         'scale_pos_weight': 70.0, 'subsample': 1.0},\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaFe4_nXdj96",
        "colab_type": "code",
        "outputId": "a9616d42-3e4f-49b5-9a1d-07a9b904f5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier(**a8['ExtraTreesClassifier'] )  )\n",
        "pipe3\n",
        "a8.keys(),list(sclf2.named_classifiers.keys())\n",
        "a8['XGBClassifier']\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier(**a8['XGBClassifier']))\n",
        "pipe1,a8['XGBClassifier']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Pipeline(memory=None,\n",
              "          steps=[('catboostencoder',\n",
              "                  CatBoostEncoder(a=1, cols=None, drop_invariant=False,\n",
              "                                  handle_missing='value', handle_unknown='value',\n",
              "                                  random_state=None, return_df=True, sigma=None,\n",
              "                                  verbose=0)),\n",
              "                 ('xgbclassifier',\n",
              "                  XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                colsample_bylevel=1, colsample_bynode=1,\n",
              "                                colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                                max_delta_step=0, max_depth=13,\n",
              "                                min_child_weight=3, missing=None,\n",
              "                                n_estimators=100, n_jobs=1, nthread=None,\n",
              "                                objective='binary:logistic', random_state=0,\n",
              "                                reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                                seed=None, silent=None,\n",
              "                                subsample=0.9406880083709813, verbosity=1))],\n",
              "          verbose=False),\n",
              " {'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.9406880083709813})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHU7-dKPdJKv",
        "colab_type": "code",
        "outputId": "51ca7629-9338-4a86-add8-74e741515f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(pipe1.named_steps.keys())[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xgbclassifier'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5TMP6e7ab6X",
        "colab_type": "code",
        "outputId": "016882b2-f986-4157-8671-fc3dcbf786bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i,k in enumerate(list(sclf2.named_classifiers.keys())):\n",
        "  for j,val in enumerate(list(a8.keys())):\n",
        "    if type((sclf2.named_classifiers[k][1])).__name__ ==list(a8.keys())[j]:\n",
        "        print(list(a8.values())[j])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQa1FPcy3ucp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "{'ExtraTreesClassifier': {'criterion': 'gini', 'max_depth': 7, 'max_features': 7, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 19}, \n",
        "'LGBMClassifier': {'colsample_bytree': 1.0, 'max_depth': 7, 'min_child_samples': 80, 'num_leave': 50, 'reg_alpha': 0, 'reg_lambda': 10, 'scale_pos_weight': 70.0, 'subsample': 1.0},\n",
        "'RandomForestClassifier': {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 30},\n",
        "'XGBClassifier': {'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.9406880083709813}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwGKr5nNdGcp",
        "colab_type": "code",
        "outputId": "a9f7cd5b-9183-42f2-8736-1a16defcbdbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "import numpy as np\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "param_hyperopt={\n",
        "  'RandomForestClassifier': \n",
        "            {\n",
        "            'max_depth': ho_scope.int(hp.quniform('c2_max_depth', 5, 7, 1)),\n",
        "            'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 5, 30, 1)),\n",
        "            'max_features': hp.choice('c2_max_features', ['auto', 'sqrt']),\n",
        "            'criterion': hp.choice('c2_criterion', ['gini', 'entropy']),\n",
        "            'min_samples_split': ho_scope.int(hp.quniform('c2_min_samples_split', 2, 5,1)),\n",
        "            'min_samples_leaf': ho_scope.int(hp.quniform('c2_min_samples_leaf', 2, 5,1))\n",
        "                          \n",
        "         },\n",
        "  'ExtraTreesClassifier':\n",
        "            {\n",
        "                'max_depth': ho_scope.int(hp.quniform('c4_max_depth', 5, 20, 1)),\n",
        "                'n_estimators': ho_scope.int(hp.quniform('c4_n_estimators', 5, 30, 1)),\n",
        "                'max_features': ho_scope.int(hp.quniform('c4_max_features', 5, 20, 1)),\n",
        "                'criterion': hp.choice('c4_criterion', ['gini', 'entropy']),\n",
        "                'min_samples_split': ho_scope.int(hp.quniform('c4_min_samples_split', 2, 5,1)),\n",
        "                'min_samples_leaf': ho_scope.int(hp.quniform('c4_min_samples_leaf', 2, 5,1))\n",
        "       },\n",
        "  'XGBClassifier':\n",
        "      {\n",
        "           'max_depth': hp.choice(\"x_max_depth\", np.arange(5, 25, dtype=int)),\n",
        "           'min_child_weight': hp.choice ('x_min_child',np.arange(1, 10, dtype=int)),\n",
        "           'subsample': hp.uniform ('x_subsample', 0.8, 1)\n",
        "       },\n",
        "  'LGBMClassifier':\n",
        "       {\n",
        "        'max_depth': ho_scope.int(hp.quniform('c6_max_depth', 3, 10, 1)),\n",
        "        'num_leave': ho_scope.int(hp.quniform('c6_num_leaves', 5, 50, 5)),\n",
        "        'min_child_samples': ho_scope.int(hp.quniform('c6_min_child_samples', 50, 100, 10)),\n",
        "        'scale_pos_weight': ho_scope.float(hp.quniform('c6_scale_pos_weight', 50, 100, 10)),\n",
        "        'subsample': ho_scope.float(hp.quniform('c6_subsample', 0.6, 0.9, 1)),\n",
        "        'colsample_bytree': ho_scope.float(hp.quniform('c6_colsample_bytree', 0.6, 0.9, 1)),\n",
        "        'reg_lambda': hp.choice(\"c6_reg_lambda\",[0, 1e-1, 1, 5, 10, 20, 50]),\n",
        "        'reg_alpha': hp.choice(\"c6_reg_alpha\",[0, 1e-1, 1, 5, 10, 20, 50])\n",
        "       }         \n",
        "       \n",
        "}  \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf8(params):\n",
        "   model1 =Pipeline(steps=[('encoder',Accepted[0][1]()),\n",
        "             ('c4',ExtraTreesClassifier(**f_unpack_dict(params['ExtraTreesClassifier'])))])\n",
        "   model2 =Pipeline(steps=[('encoder',Accepted[1][1]()),('LGBMClassifier', lgb.LGBMClassifier(**f_unpack_dict(params['LGBMClassifier'])))]) \n",
        "   model3 =Pipeline(steps=[('encoder',Accepted[2][1]()),('XGBClassifier', xgb.XGBClassifier(**f_unpack_dict(params['XGBClassifier'])))])   \n",
        "   model4 =Pipeline(steps=[('encoder',Accepted[3][1]()),('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis())]) \n",
        "   model5 =Pipeline(steps=[('encoder',Accepted[4][1]()),\n",
        "             ('c2',RandomForestClassifier(**f_unpack_dict(params['RandomForestClassifier'])))]) \n",
        "   model6 =Pipeline(steps=[('encoder',Accepted[5][1]()),('QuadraticDiscriminantAnalysis', QuadraticDiscriminantAnalysis())])\n",
        "   sclf2 = StackingClassifier(classifiers=[model1,model2,model3,model4,model5,model6],meta_classifier=LogisticRegression())\n",
        "   return sclf2\n",
        "  \n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf8(params)\n",
        "    #clf = RandomForestClassifier(**params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf8 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "\n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "clf8 = f_clf8(space_eval(param_hyperopt, best_clf8)).fit(X_train, y_train)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf8_val_score = roc_auc_score(y_test, clf8.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf8_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt, best_clf8))\n",
        "oo=-trials.best_trial['result']['loss']\n",
        "oo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [29:27<4:25:04, 1767.20s/it, best loss: -0.8759822037775029]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd05nQ3EojhD",
        "colab_type": "code",
        "outputId": "7a2da0a9-b32c-4347-b9e2-3466c7cbaff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "import numpy as np\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "\n",
        "param_hyperopt= {\n",
        "    'AdaBoostClassifier':\n",
        "     {\n",
        "          'learning_rate': hp.loguniform('c5_learning_rate', np.log(0.01), np.log(1)),\n",
        "           'n_estimators': ho_scope.int(hp.quniform('c5_n_estimators', 5, 30, 1)),\n",
        "           'algorithm': hp.choice('c5_algorithm',[\"SAMME\"])  \n",
        "       }    \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf7(params):\n",
        "   model2 =Pipeline(steps=[('encoder',Accepted[5][1]()),\n",
        "             ('c5',AdaBoostClassifier(**f_unpack_dict(params['AdaBoostClassifier'])))]) \n",
        "   return model2\n",
        "        \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf7(params)\n",
        "    #clf = RandomForestClassifier(**params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf7 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                 param_hyperopt, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "\n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "clf7 = f_clf7(space_eval(param_hyperopt, best_clf7)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf7_val_score = roc_auc_score(y_test, clf7.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf7_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt, best_clf7))\n",
        "cc=-trials.best_trial['result']['loss']\n",
        "cc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [07:45<00:00, 43.23s/it, best loss: -0.7034403411046589]\n",
            "Cross-val score: 0.70344; validation score: 0.70367\n",
            "Best parameters:\n",
            "{'AdaBoostClassifier': {'algorithm': 'SAMME', 'learning_rate': 0.30044074314959096, 'n_estimators': 13}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7034403411046589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}