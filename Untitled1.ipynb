{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarah127/udacity-data-analysis-with-r/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgzROkNIH4do",
        "colab_type": "code",
        "outputId": "82a05f1c-bb10-47e9-ac06-a125f8319808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGDCijX7ybgt",
        "colab_type": "code",
        "outputId": "89feeb1f-2c76-41bc-9d8d-c167fc8a78ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "#' ' means CPU whereas '/device:G:0' means GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-SxmThUynsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!df -h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAV8exRXypkt",
        "colab_type": "code",
        "outputId": "63f18db1-7b5e-46bf-b77c-ff1f2aa148eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanizeii\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=eb9e90e332a81ca70b4a05945f443b0ac1277404f67cca8accb7fc0a3c130c25\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement humanizeii (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for humanizeii\u001b[0m\n",
            "Gen RAM Free: 26.0 GB  | Proc size: 202.4 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuFNEWi_19RH",
        "colab_type": "code",
        "outputId": "2ca37fbd-5b11-4c35-a62f-418339b7e336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1R6gDJMND6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP8zG65mYk86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-IRoKKSfh4q",
        "colab_type": "code",
        "outputId": "e2febe11-ce2a-4429-d372-e152cf78447e",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-223422d2-77ab-4ed0-aa68-2b83b48bf8e2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-223422d2-77ab-4ed0-aa68-2b83b48bf8e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wEHXFWvfzTH",
        "colab_type": "code",
        "outputId": "5f000ca2-054a-47ff-b0cf-02497e93679a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!ls /content/drive/*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'191021-234625 (1).png'\t\t   'How to get started with Drive.pdf'\n",
            " 191021-234625.png\t\t   'IELTS Grammar Chris'\n",
            "'٢٠١٨٠٢٠٥_٢١٤٣٥٥ (1).jpg'\t    IMG_20180427_151315.jpg\n",
            "'٢٠١٨٠٢٠٥_٢١٤٣٥٥ (2).jpg'\t   'IMG_20190909_205719[1] (1).jpg'\n",
            " ٢٠١٨٠٢٠٥_٢١٤٣٥٥.jpg\t\t   'IMG_20190909_205719[1].jpg'\n",
            "'٢٠١٨٠٢٠٥_٢١٤٣٥٥ - sarah ali.jpg'   prposal.docx\n",
            " ٢٠١٨٠٤٠٨_١٣٤٦٠٦.jpg\t\t   'Ryan Higgins - IELTS Course 2014'\n",
            " AirlinesCodrnaAdult.csv\t   'Study English IELTS Preparation Series'\n",
            "'Colab Notebooks'\t\t   'TED talks+scripts'\n",
            " dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD03caqDhFhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "from  pyspark import SparkConf\n",
        "#conf = SparkConf().setMaster(\"local\").setAppName(\"My app\").set(\"spark.executor.memory\", \"1g\")\n",
        "#sc = SparkContext()\n",
        "# ===============================read from csv==============================================\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from pyspark.sql.types import StructType,StructField,StringType,TimestampType,IntegerType,DoubleType,LongType,FloatType\n",
        "Df5_Schema = StructType([StructField(\"Airline\", StringType(),True),StructField(\"Flight\", DoubleType()),\n",
        "StructField(\"AirportFrom\",StringType()),StructField(\"AirportTo\", StringType()),StructField(\"DayOfWeek\", IntegerType()),\n",
        "StructField(\"Time\",IntegerType()), StructField(\"Length\", IntegerType()),StructField(\"codrna_X1\",DoubleType()),\n",
        "StructField(\"codrna_X2\",DoubleType()),StructField(\"codrna_X3\",DoubleType()),StructField(\"codrna_X4\", DoubleType()),\n",
        "StructField(\"codrna_X5\", DoubleType()),StructField(\"codrna_X6\", DoubleType()),StructField(\"codrna_X7\", DoubleType()),\n",
        "StructField(\"codrna_X8\", DoubleType()),StructField(\"age\", IntegerType()),StructField(\"workclass\", StringType()),\n",
        "StructField(\"fnlwgt\", IntegerType()),StructField(\"education\", StringType()),StructField(\"education-num\", IntegerType()),\n",
        "StructField(\"marital-status\", StringType()),StructField(\"occupation\", StringType()),StructField(\"relationship\", StringType()),\n",
        "StructField(\"race\", StringType()),StructField(\"sex\", StringType()),StructField(\"capitalgain\", IntegerType()),\n",
        "StructField(\"capitalloss\", IntegerType()),StructField(\"hoursperweek\", IntegerType()),StructField(\"native-country\", StringType()),\n",
        "StructField(\"Delay\", IntegerType())])\n",
        "CSV_2007= '/content/drive/My Drive/AirlinesCodrnaAdult.csv'\n",
        "df5 =spark.read.schema(Df5_Schema).option(\"header\",\"true\").option(\"mode\", \"DROPMALFORMED\").csv(CSV_2007)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQvods40rPBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = [f.name for f in df5.schema.fields]\n",
        "dataTypes = [f.dataType for f in df5.schema.fields]\n",
        "ls=list(zip(names,dataTypes))\n",
        "str_cols=[]\n",
        "for i in range(len(ls)):\n",
        "     if type(ls[i][1])==StringType and len(df5.select(df5[ls[i][0]]).distinct().collect())<=20:\n",
        "         str_cols.append([i,ls[i][0]]) \n",
        "strings=[]\n",
        "for i in range(len(str_cols)):\n",
        "     strings.append(str_cols[i][1])  \n",
        "\n",
        "#the process of convertiong catogerical columns into numeric is not included in the machine learning operation \n",
        "#it will be left for future improvements !!!ان شاء الله      \n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df5) for column in strings]\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "df6 = pipeline.fit(df5).transform(df5)\n",
        "df6=df6.drop(*strings)\n",
        "df6_pd=df6.toPandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIM7xkiDsRJI",
        "colab_type": "code",
        "outputId": "bc439d53-5e0d-4751-95dc-0a79047b419c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "! pip install category_encoders"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 30.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.3)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.17.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.6.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB96hBgnrflo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import f1_score\n",
        "import category_encoders as ce\n",
        "from sklearn.utils import resample\n",
        "\n",
        "encoder_list = [ce.backward_difference.BackwardDifferenceEncoder,ce.basen.BaseNEncoder,ce.binary.BinaryEncoder,\n",
        "                ce.cat_boost.CatBoostEncoder,ce.helmert.HelmertEncoder,\n",
        "                ce.james_stein.JamesSteinEncoder,ce.one_hot.OneHotEncoder,ce.leave_one_out.LeaveOneOutEncoder,\n",
        "                ce.m_estimate.MEstimateEncoder,ce.ordinal.OrdinalEncoder,\n",
        "                ce.sum_coding.SumEncoder,ce.target_encoder.TargetEncoder,ce.woe.WOEEncoder]\n",
        "#numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "#categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X = df6_pd.drop('Delay', axis=1)\n",
        "y = df6_pd['Delay']\n",
        "#le = preprocessing.LabelEncoder()\n",
        "#label_encoder = le.fit(y)\n",
        "#y = label_encoder.transform(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "block_size=int(round(X_train.shape[0]/len(encoder_list)))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train = [X_train[i:i+n] for i in range(0,X_train.shape[0],n)]\n",
        "list_y_train = [y_train[i:i+n] for i in range(0,y_train.shape[0],n)]\n",
        "list_X_test = [X_test[i:i+n] for i in range(0,X_test.shape[0],n)]\n",
        "list_y_test = [y_test[i:i+n] for i in range(0,y_test.shape[0],n)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "486lmPRrsNS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_numeric_dataset=[]\n",
        "intermidate=[]\n",
        "testing_numeric_dataset=[]\n",
        "for i,encoder in enumerate(encoder_list):\n",
        "  #(encoder(handle_unknown='ignore',cols=['AirportFrom','AirportTo','native-country'])).fit_transform(boot1[i])\n",
        "   training_numeric_dataset.append(encoder_list[i](cols=['AirportFrom','AirportTo','native-country']).fit(list_X_train[i],list_y_train[i]))\n",
        "   intermidate.append((training_numeric_dataset[i]).transform(list_X_train[i],list_y_train[i]))\n",
        "for i in range(len(list_X_test)):\n",
        "    for j,encoder in enumerate(encoder_list):\n",
        "        testing_numeric_dataset.append((training_numeric_dataset[j]).transform(list_X_test[i])) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KMjFk6msm2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx=[]\n",
        "for i in range(len(encoder_list)):\n",
        "    #xx.append([i,min(intermidate[i].columns)] )\n",
        "    xx.append([encoder_list[i],len(intermidate[i].columns)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVO0TqN94DCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "while(1):\n",
        "    a.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XrUFnRFs2ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "block_size=int(round(X_train2.shape[0]/12))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train2 = [X_train2[i:i+n] for i in range(0,X_train2.shape[0],n)]\n",
        "list_y_train2 = [y_train2[i:i+n] for i in range(0,y_train2.shape[0],n)]\n",
        "list_X_test2 = [X_test2[i:i+n] for i in range(0,X_test2.shape[0],n)]\n",
        "list_y_test2 = [y_test2[i:i+n] for i in range(0,y_test2.shape[0],n)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAV2AZs2tE00",
        "colab_type": "code",
        "outputId": "5c219cc6-2899-48e6-d1d8-6444c857008c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from heapq import nlargest\n",
        "\n",
        "encoder_list = [ce.backward_difference.BackwardDifferenceEncoder(),ce.basen.BaseNEncoder(),\n",
        "                ce.binary.BinaryEncoder(),ce.cat_boost.CatBoostEncoder(),\n",
        "                ce.helmert.HelmertEncoder(),ce.james_stein.JamesSteinEncoder(),\n",
        "                ce.one_hot.OneHotEncoder(),ce.leave_one_out.LeaveOneOutEncoder()\n",
        "                ,ce.m_estimate.MEstimateEncoder(),ce.ordinal.OrdinalEncoder(),ce.sum_coding.SumEncoder(),\n",
        "                ce.target_encoder.TargetEncoder(),ce.woe.WOEEncoder()]\n",
        "my_dict={}\n",
        "for encoder in encoder_list:\n",
        "    model = Pipeline(steps=[('preprocessor', encoder),('classifier',RandomForestClassifier())])               \n",
        "    modelOpt = model.fit(X_train, y_train)\n",
        "    y_true,y_pred =y_test, model.predict(X_test)\n",
        "    clf2_val_score = roc_auc_score(y_test, modelOpt.predict_proba(X_test)[:, 1])\n",
        "    my_dict[type(encoder)]= [modelOpt.score(X_train, y_train),clf2_val_score]\n",
        "\n",
        "num=int(round(len(encoder_list)*0.5))    "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNP-3BVuIy8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z={}\n",
        "for i in range(len(my_dict)):\n",
        "   z[list(my_dict.keys())[i]]=list(my_dict.items())[i][1][0] \n",
        "Highest1 = nlargest(num, z, key = z.get)  \n",
        "\n",
        "zz={}\n",
        "for i in range(len(my_dict)):\n",
        "   zz[list(my_dict.keys())[i]]=list(my_dict.items())[i][1][1] \n",
        "Highest2 = nlargest(num, zz, key = zz.get)  \n",
        "Highest3=list(set(Highest1+Highest2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuhCUjfj_lc1",
        "colab_type": "code",
        "outputId": "2b77bb5f-d1d5-4224-d1a0-60476ed1eb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "zz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{category_encoders.backward_difference.BackwardDifferenceEncoder: 0.8606833246206118,\n",
              " category_encoders.basen.BaseNEncoder: 0.8663549344139968,\n",
              " category_encoders.binary.BinaryEncoder: 0.8663393023681079,\n",
              " category_encoders.cat_boost.CatBoostEncoder: 0.8827985009757067,\n",
              " category_encoders.helmert.HelmertEncoder: 0.8592280236084026,\n",
              " category_encoders.james_stein.JamesSteinEncoder: 0.8683739506772159,\n",
              " category_encoders.leave_one_out.LeaveOneOutEncoder: 0.515101473852555,\n",
              " category_encoders.m_estimate.MEstimateEncoder: 0.8681464920689393,\n",
              " category_encoders.one_hot.OneHotEncoder: 0.8617009332062612,\n",
              " category_encoders.ordinal.OrdinalEncoder: 0.867874490461257,\n",
              " category_encoders.sum_coding.SumEncoder: 0.8616371273696918,\n",
              " category_encoders.target_encoder.TargetEncoder: 0.8682504198254399,\n",
              " category_encoders.woe.WOEEncoder: 0.8686003347631575}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN3Vj_8VJDhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Accepted=[]\n",
        "keys = my_dict.keys()\n",
        "for i,each in enumerate(xx):\n",
        " for j,val in enumerate(Highest3): \n",
        "   if xx[i][0]==val and  xx[i][1]==len(X_train.columns)  : \n",
        "           #  Accepted.append(\"%s :%s: %s\" % (i,type(each), my_dict.get(each))) \n",
        "           Accepted.append((i,val))\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20rpUs7-EfrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Accepted      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AWt8EE1Jl76",
        "colab_type": "code",
        "outputId": "fc230191-4d00-4507-d988-385ebfee5ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "pipe1 = make_pipeline(Accepted[0][1](),RandomForestClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](), KNeighborsClassifier())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2], meta_classifier=LogisticRegression())\n",
        "\n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P6auG6ahBf-",
        "colab_type": "code",
        "outputId": "007160a0-cad7-4f6b-a795-189247f3448a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())\n",
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "pipe5 = make_pipeline(Accepted[4][1](),AdaBoostClassifier())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6], meta_classifier=LogisticRegression())\n",
        "\n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"StackingClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.77      0.76     94889\n",
            "           1       0.82      0.80      0.81    120469\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.78      0.78      0.78    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "StackingClassifier score: 0.908887\n",
            "Cross-val score: 0.84649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuYcc4nnZkp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hyperopt import fmin, hp, tpe, Trials, space_eval\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "clf1 = f_clf1(space_eval(param_hyperopt, best_clf3)).fit(X_train, y_train)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf1_val_score = roc_auc_score(y_test, clf1.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf1_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt, best_clf3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyBAgEvxakfh",
        "colab_type": "code",
        "outputId": "b82d30a2-80bf-4dd6-c7bc-36d44c6485ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"RandomForestClassifier score: %f\" % clf1.score(X_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77     94676\n",
            "           1       0.83      0.78      0.80    120682\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.78      0.79      0.78    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "RandomForestClassifier score: 0.731440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "13701896-f9ea-4707-c543-e1927773389d",
        "id": "GoT4rgyqbNPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import warnings\n",
        "pipe1 = make_pipeline(Accepted[0][1](),RandomForestClassifier(n_estimators= 21,\n",
        "                max_depth= 7,min_samples_split= 4,min_samples_leaf= 4,max_features= 'sqrt'))\n",
        "pipe2 = make_pipeline(Accepted[1][1](),AdaBoostClassifier(DecisionTreeClassifier(max_depth=1)\n",
        ",n_estimators=28,learning_rate=0.8051561754791255)) \n",
        "pipe3 = make_pipeline(Accepted[2][1](),XGBClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),ExtraTreesClassifier(criterion= 'entropy'))\n",
        "pipe5 = make_pipeline(Accepted[4][1](),GradientBoostingClassifier())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),GaussianNB())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6],\n",
        "                           meta_classifier=LogisticRegression())\n",
        "\n",
        "model2=sclf2.fit(X_train, y_train)\n",
        "y_true3, y_pred3  =y_test, model2.predict(X_test)\n",
        "print(classification_report(y_true3, y_pred3))  \n",
        "print(\"RandomForestClassifier score: %f\" % model2.score(X_train, y_train))\n",
        "clf2_val_score = roc_auc_score(y_test, sclf2.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}'.format(clf2_val_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77     94676\n",
            "           1       0.83      0.78      0.80    120682\n",
            "\n",
            "    accuracy                           0.79    215358\n",
            "   macro avg       0.78      0.79      0.78    215358\n",
            "weighted avg       0.79      0.79      0.79    215358\n",
            "\n",
            "RandomForestClassifier score: 0.913660\n",
            "Cross-val score: 0.84756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APRcNVp5qCWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7jAi0SyqJ6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGO4odcgVfWt",
        "colab_type": "code",
        "outputId": "03a78f97-cb4a-4837-9869-92cd1f7e7105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "# load dataset\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "#le = preprocessing.LabelEncoder()\n",
        "#label_encoder = le.fit(y)\n",
        "#y = label_encoder.transform(y)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2)\n",
        "block_size=int(round(X_train2.shape[0]/12))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train = [X_train2[i:i+n] for i in range(0,X_train2.shape[0],n)]\n",
        "list_y_train = [y_train2[i:i+n] for i in range(0,y_train2.shape[0],n)]\n",
        "list_X_test = [X_test2[i:i+n] for i in range(0,X_test2.shape[0],n)]\n",
        "list_y_test = [y_test2[i:i+n] for i in range(0,y_test2.shape[0],n)]\n",
        "test_data = lgb.Dataset(list_X_test[0], label=list_y_test[0])\n",
        "# Build the encoder\n",
        "# prepare configuration for cross validation test harness\n",
        "seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "parameters = {\n",
        "    'application': 'binary','objective': 'binary','metric': 'auc','is_unbalance': 'true',\n",
        "    'boosting': 'gbdt','num_leaves': 31,'feature_fraction': 0.5,'bagging_fraction': 0.5,\n",
        "    'bagging_freq': 20,'learning_rate': 0.05,'verbose': 0\n",
        "}\n",
        "fit_params={\"early_stopping_rounds\":10,\"eval_metric\" : 'auc',\"eval_set\" : [(X_test,y_test)],\n",
        "            'eval_names': ['valid'],'verbose': 100,\n",
        "            'feature_name': 'auto', # that's actually the default\n",
        "            'categorical_feature': 'auto' # that's actually the default\n",
        "           }\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                               ('RandomForestClassifier',RandomForestClassifier(n_estimators=20))])) \n",
        "                               .fit(list_X_train[0], list_y_train[0])) \n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                               ('AdaBoostClassifier',AdaBoostClassifier(n_estimators=25))]))\n",
        "                               .fit(list_X_train[1], list_y_train[1])) \n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                               ('GradientBoostingClassifier',GradientBoostingClassifier())]))\n",
        "                              .fit(list_X_train[2], list_y_train[2]))  \n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                              ('XGBClassifier',XGBClassifier(max_depth=2,n_estimators=10,objective='binary:logistic'))]))\n",
        "                            .fit(list_X_train[3], list_y_train[3]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                              ('ExtraTreesClassifier',ExtraTreesClassifier(criterion= 'entropy'))]))\n",
        "                               .fit(list_X_train[4], list_y_train[4]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "              ('lightgbm',lgb.LGBMClassifier(n_estimators=5 , num_leaves= 15,\n",
        "           max_depth=-1,colsample_bytree=0.9,subsample=0.9,learning_rate=0.1))])).fit(list_X_train[5], list_y_train[5]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('LDA', LinearDiscriminantAnalysis())])).fit(list_X_train[6], list_y_train[6]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('MLPClassifier',\n",
        "                      MLPClassifier(hidden_layer_sizes=(10,10), max_iter=5, alpha=0.0001,\n",
        "                     solver='sgd', verbose=10,  random_state=1))])).fit(list_X_train[7], list_y_train[7]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('LR', LogisticRegression())])).fit(list_X_train[8], list_y_train[8]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('QDA', QuadraticDiscriminantAnalysis())])).fit(list_X_train[9], list_y_train[9]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                      ('CART', DecisionTreeClassifier())])).fit(list_X_train[10], list_y_train[10]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                       ('NB', GaussianNB())])).fit(list_X_train[11], list_y_train[11]))\n",
        "   \n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in enumerate(models):\n",
        "    #kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "    print('1')\n",
        "    cv_results = model_selection.cross_val_score(model, list_X_train[name], \n",
        "                            list_y_train[name], cv=5, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 104.38134065\n",
            "Iteration 3, loss = 104.37902593\n",
            "Iteration 4, loss = 104.37853393\n",
            "Iteration 5, loss = 104.37815567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0: 0.782381 (0.004526)\n",
            "1\n",
            "1: 0.754423 (0.002999)\n",
            "1\n",
            "2: 0.778815 (0.002042)\n",
            "1\n",
            "3: 0.708161 (0.003867)\n",
            "1\n",
            "4: 0.771529 (0.002236)\n",
            "1\n",
            "5: 0.750662 (0.003572)\n",
            "1\n",
            "6: 0.746106 (0.002216)\n",
            "1\n",
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 150.06958461\n",
            "Iteration 3, loss = 150.06539659\n",
            "Iteration 4, loss = 150.06454619\n",
            "Iteration 5, loss = 150.06406634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 133.36387865\n",
            "Iteration 3, loss = 133.35976349\n",
            "Iteration 4, loss = 133.35897329\n",
            "Iteration 5, loss = 133.35855287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 146.27477581\n",
            "Iteration 3, loss = 146.27059144\n",
            "Iteration 4, loss = 146.26978226\n",
            "Iteration 5, loss = 146.26932014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 178.85326108\n",
            "Iteration 3, loss = 178.84897594\n",
            "Iteration 4, loss = 178.84807387\n",
            "Iteration 5, loss = 178.84750325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 129.72083973\n",
            "Iteration 3, loss = 129.71662152\n",
            "Iteration 4, loss = 129.71586594\n",
            "Iteration 5, loss = 129.71543978\n",
            "7: 0.561753 (0.000012)\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8: 0.635361 (0.003408)\n",
            "1\n",
            "9: 0.728819 (0.002045)\n",
            "1\n",
            "10: 0.747709 (0.003441)\n",
            "1\n",
            "11: 0.609353 (0.002873)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0JuZJe7/A1w897E1lNkJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGSR_9eGDZB4",
        "colab_type": "code",
        "outputId": "cff64a9b-0793-4a9c-c1ec-63924d9b58f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "for name, model in enumerate(models):\n",
        "  print(results[name].mean())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7823810136021336\n",
            "0.7544228815733763\n",
            "0.7788147318846163\n",
            "0.7081605539418434\n",
            "0.7715293123349614\n",
            "0.7506616539812587\n",
            "0.7461064750053661\n",
            "0.5617529877076503\n",
            "0.6353605968429097\n",
            "0.7288190056704107\n",
            "0.7477086056716529\n",
            "0.6093527268840728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvwjMnT6oJ42",
        "colab_type": "code",
        "outputId": "cd3b7bae-ca9f-4f1d-ffeb-43aac80bd5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "for name, model in enumerate(models):\n",
        "  print(type(model[1]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
            "<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
            "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
            "<class 'xgboost.sklearn.XGBClassifier'>\n",
            "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
            "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
            "<class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>\n",
            "<class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n",
            "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
            "<class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>\n",
            "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
            "<class 'sklearn.naive_bayes.GaussianNB'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "76c10194-88b2-4da4-dfa8-bc31f7d5900c",
        "id": "_205EAuPwgx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import category_encoders as ce\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "# load dataset\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "#le = preprocessing.LabelEncoder()\n",
        "#label_encoder = le.fit(y)\n",
        "#y = label_encoder.transform(y)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2)\n",
        "block_size=int(round(X_train2.shape[0]/2))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train = [X_train2[i:i+n] for i in range(0,X_train2.shape[0],n)]\n",
        "list_y_train = [y_train2[i:i+n] for i in range(0,y_train2.shape[0],n)]\n",
        "list_X_test = [X_test2[i:i+n] for i in range(0,X_test2.shape[0],n)]\n",
        "list_y_test = [y_test2[i:i+n] for i in range(0,y_test2.shape[0],n)]\n",
        "test_data = lgb.Dataset(list_X_test[0], label=list_y_test[0])\n",
        "# Build the encoder\n",
        "\n",
        "# prepare configuration for cross validation test harness\n",
        "seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "parameters = {\n",
        "    'application': 'binary','objective': 'binary','metric': 'auc','is_unbalance': 'true',\n",
        "    'boosting': 'gbdt','num_leaves': 31,'feature_fraction': 0.5,'bagging_fraction': 0.5,\n",
        "    'bagging_freq': 20,'learning_rate': 0.05,'verbose': 0\n",
        "}\n",
        "fit_params={\"early_stopping_rounds\":10,\"eval_metric\" : 'auc',\"eval_set\" : [(X_test2,y_test2)],\n",
        "            'eval_names': ['valid'],'verbose': 100,\n",
        "            'feature_name': 'auto', # that's actually the default\n",
        "            'categorical_feature': 'auto' # that's actually the default\n",
        "           }\n",
        "iterace=100\n",
        "num_leaves_list = [50] * iterace\n",
        "num_boost_round = iterace\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "            ('lightgbm',\n",
        "             lgb.LGBMClassifier(n_estimators=5 , num_leaves= 15, max_depth=-1,colsample_bytree=0.9,subsample=0.9,learning_rate=0.1))]))\n",
        "             .fit(list_X_train[0], list_y_train[0]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                              ('ExtraTreesClassifier',\n",
        "                               ExtraTreesClassifier(criterion= 'entropy'))]))\n",
        "                               .fit(list_X_train[1], list_y_train[1]))\n",
        "\n",
        "\n",
        "   \n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'roc_auc'\n",
        "for name, model in enumerate(models):\n",
        "    #kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "    print('1')\n",
        "    cv_results = model_selection.cross_val_score(model, list_X_train[name],  list_y_train[name], cv=5, scoring=scoring)scoring = 'roc_auc'\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0: 0.847674 (0.002017)\n",
            "1\n",
            "1: 0.823186 (0.002219)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRhkAktQoA0CSGvX/Ac5WlSFRrzLfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t4x9fLj60z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
        "<class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>\n",
        "<class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>\n",
        "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
        "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
        "<class 'sklearn.naive_bayes.GaussianNB'>\n",
        "0.6829684029332511\n",
        "0.827949216322429\n",
        "0.7833181903727263\n",
        "0.8093042942328639\n",
        "0.751999156259342\n",
        "0.6736773534599882"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5coHmYxjACfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
        "<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
        "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
        "<class 'xgboost.sklearn.XGBClassifier'>\n",
        "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
        "0.7832383328566881\n",
        "0.7549017227889664\n",
        "0.7809340403330391\n",
        "0.7092973230909462\n",
        "0.7739688907408679"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Mgb687EFSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>\n",
        "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
        "<class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>\n",
        "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
        "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
        "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
        "<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
        "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
        "<class 'sklearn.naive_bayes.GaussianNB'>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkp-7STuMRJ7",
        "colab_type": "code",
        "outputId": "dfa96680-e9ad-46bd-f785-4a5b1bc23273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "\n",
        "param_hyperopt1= {\n",
        "   'ExtraTreesClassifier':\n",
        "            {\n",
        "                'max_depth': ho_scope.int(hp.quniform('c4_max_depth', 5, 20, 1)),\n",
        "                'n_estimators': ho_scope.int(hp.quniform('c4_n_estimators', 5, 30, 1)),\n",
        "                'max_features': ho_scope.int(hp.quniform('c4_max_features', 5, 20, 1)),\n",
        "                'criterion': hp.choice('c4_criterion', ['gini', 'entropy']),\n",
        "                'min_samples_split': ho_scope.int(hp.quniform('c4_min_samples_split', 2, 5,1)),\n",
        "                'min_samples_leaf': ho_scope.int(hp.quniform('c4_min_samples_leaf', 2, 5,1))      \n",
        "             }     \n",
        "       \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2,random_state = 0)\n",
        "def f_clf1(params):\n",
        "  model6 =Pipeline(steps=[('encoder',Accepted[0][1]()),\n",
        "             ('c4',ExtraTreesClassifier(**f_unpack_dict(params['ExtraTreesClassifier'])))])\n",
        "  return model6    \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf1(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf1 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2), param_hyperopt1, algo=tpe.suggest, max_evals=10,\n",
        "                 trials=trials, rstate=np.random.RandomState(1))\n",
        "clf1 = f_clf1(space_eval(param_hyperopt1, best_clf1)).fit(X_train2, y_train2)\n",
        "# Calculating performance on validation set\n",
        "y_score = clf1.predict_proba(X_test2)\n",
        "clf1_val_score = roc_auc_score(y_test2, y_score[:,1])\n",
        "#clf2_val_score = model_selection.cross_val_score(f_clf2, X_train2,  y_train2, cv=5, scoring='roc_auc')\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf1_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(space_eval(param_hyperopt, best_clf1))\n",
        "a1=space_eval(param_hyperopt1, best_clf1)\n",
        "Fr_classifier={'classifier':list(a1.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf1_val_score,'parameters':list(a1.values())[0]}"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [03:47<05:41, 56.91s/it, best loss: -0.8657111762879497]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [07:34<03:29, 69.80s/it, best loss: -0.8705357564428059]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [09:18<01:01, 61.29s/it, best loss: -0.8755075622861487]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10/10 [10:16<00:00, 60.38s/it, best loss: -0.8755075622861487]\n",
            "Cross-val score: 0.87551; validation score: 0.88494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiM49RkuqGq3",
        "colab_type": "code",
        "outputId": "60a13b37-3f05-44f7-9eeb-10a825fd66be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "\n",
        "param_hyperopt2= {\n",
        "  'RandomForestClassifier': \n",
        "            {\n",
        "            'max_depth': ho_scope.int(hp.quniform('c2_max_depth', 5, 7, 1)),\n",
        "            'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 5, 30, 1)),\n",
        "            'max_features': hp.choice('c2_max_features', ['auto', 'sqrt']),\n",
        "            'criterion': hp.choice('c2_criterion', ['gini', 'entropy']),\n",
        "            'min_samples_split': ho_scope.int(hp.quniform('c2_min_samples_split', 2, 5,1)),\n",
        "            'min_samples_leaf': ho_scope.int(hp.quniform('c2_min_samples_leaf', 2, 5,1))\n",
        "                          \n",
        "         } \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf2(params):\n",
        "  model4 =Pipeline(steps=[('encoder',Accepted[1][1]()),\n",
        "             ('c2',RandomForestClassifier(**f_unpack_dict(params['RandomForestClassifier'])))])\n",
        "  return model4    \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf2(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf2 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                 param_hyperopt2, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf2 = f_clf2(space_eval(param_hyperopt2, best_clf2)).fit(X_train2, y_train2)\n",
        "# Calculating performance on validation set\n",
        "y_score = clf2.predict_proba(X_test2)\n",
        "clf2_val_score = roc_auc_score(y_test2, y_score[:,1])\n",
        "#clf2_val_score = model_selection.cross_val_score(f_clf2, X_train2,  y_train2, cv=5, scoring='roc_auc')\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf2_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a2=space_eval(param_hyperopt2, best_clf2)\n",
        "Se_classifier={'classifier':list(a2.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf2_val_score,'parameters':list(a2.values())[0]}"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [06:17<00:00, 33.94s/it, best loss: -0.8273926245659394]\n",
            "Cross-val score: 0.82739; validation score: 0.79737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKMWqZQ8L3JV",
        "colab_type": "code",
        "outputId": "598978e8-4c35-4ba5-afb2-f7e0e000bc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "param_hyperopt3= {      \n",
        "       'LinearDiscriminantAnalysis':\n",
        "            {      \n",
        "            \n",
        "            }\n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf3(params):\n",
        "   model1 =Pipeline(steps=[('encoder',Accepted[2][1]()),('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis())])   \n",
        "   return model1\n",
        "        \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf3(params)\n",
        "    shuffle = KFold(n_splits=5, shuffle=True)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=shuffle,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf3 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt3, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf3 = f_clf3(space_eval(param_hyperopt3, best_clf3)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf3_val_score = roc_auc_score(y_test, clf3.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf3_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt3, best_clf3))\n",
        "# Calculating performance on validation set\n",
        "clf3_val_score = roc_auc_score(y_test, clf3.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf3_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a3=space_eval(param_hyperopt3, best_clf3)\n",
        "Thrid_classifier={'classifier':list(a3.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf3_val_score,'parameters':list(a3.values())[0]}"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:37<00:00, 15.45s/it, best loss: -0.8268064630182487]\n",
            "Cross-val score: 0.82681; validation score: 0.82719\n",
            "Best parameters:\n",
            "{'LinearDiscriminantAnalysis': {}}\n",
            "Cross-val score: 0.82681; validation score: 0.82719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv4WPj9XX5OS",
        "colab_type": "code",
        "outputId": "465ba13b-a8b0-43bc-d282-2f3c166c1370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "import xgboost as xgb\n",
        "\n",
        "param_hyperopt4= {\n",
        "  'XGBClassifier':\n",
        "      {\n",
        "           'max_depth': hp.choice(\"x_max_depth\", np.arange(5, 10, dtype=int)),\n",
        "           'min_child_weight': hp.choice ('x_min_child',np.arange(1, 5, dtype=int)),\n",
        "           'subsample': hp.uniform ('x_subsample', 0.8, 1),\n",
        "           'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 5, 40, 1)),\n",
        "       }         \n",
        "       \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "def f_clf4(params):\n",
        "   model1 =Pipeline(steps=[('encoder',Accepted[3][1]()),('XGBClassifier', xgb.XGBClassifier())])   \n",
        "   return model1  \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf4(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf4 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt4, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf4 = f_clf4(space_eval(param_hyperopt4, best_clf4)).fit(X_train2, y_train2)\n",
        "# Calculating performance on validation set\n",
        "clf4_val_score = roc_auc_score(y_test, clf4.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf4_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a4=space_eval(param_hyperopt4, best_clf4)\n",
        "Four_classifier={'classifier':list(a4.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf4_val_score,'parameters':list(a4.values())[0]}"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [02:31<22:41, 151.31s/it, best loss: -0.8761819849027198]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [05:01<20:08, 151.10s/it, best loss: -0.8761819849027198]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [07:32<17:37, 151.07s/it, best loss: -0.8761819849027198]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [10:04<15:08, 151.36s/it, best loss: -0.8761819849027198]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [12:37<12:38, 151.68s/it, best loss: -0.8761819849027198]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [15:13<10:12, 153.06s/it, best loss: -0.8761819849027198]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [17:46<07:39, 153.05s/it, best loss: -0.8761819849027198]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [20:18<05:05, 152.79s/it, best loss: -0.8761819849027198]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [22:54<02:33, 153.75s/it, best loss: -0.8761819849027198]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10/10 [25:29<00:00, 153.97s/it, best loss: -0.8761819849027198]\n",
            "Cross-val score: 0.87618; validation score: 0.87700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4xwRCitsi90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a4=space_eval(param_hyperopt4, best_clf4)\n",
        "Four_classifier={'classifier':list(a4.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf4_val_score,'parameters':list(a4.values())[0]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6WfRi1-5dev",
        "colab_type": "code",
        "outputId": "f63ca853-1ed2-4681-a12c-6ce43a1638cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "import lightgbm as lgb\n",
        "from functools import partial\n",
        "\n",
        "param_hyperopt5= {\n",
        "   'LGBMClassifier':\n",
        "                  {\n",
        "                   'max_depth': ho_scope.int(hp.quniform('c6_max_depth', 3, 10, 1)),\n",
        "                   'num_leave': ho_scope.int(hp.quniform('c6_num_leaves', 5, 50, 5)),\n",
        "                   'min_child_samples': ho_scope.int(hp.quniform('c6_min_child_samples', 50, 100, 10)),\n",
        "                   'scale_pos_weight': ho_scope.float(hp.quniform('c6_scale_pos_weight', 50, 100, 10)),\n",
        "                   'subsample': ho_scope.float(hp.quniform('c6_subsample', 0.6, 0.9, 1)),\n",
        "                   'colsample_bytree': ho_scope.float(hp.quniform('c6_colsample_bytree', 0.6, 0.9, 1)),\n",
        "                   'reg_lambda': hp.choice(\"c6_reg_lambda\",[0, 1e-1, 1, 5, 10, 20, 50]),\n",
        "                   'reg_alpha': hp.choice(\"c6_reg_alpha\",[0, 1e-1, 1, 5, 10, 20, 50])\n",
        "                   }         \n",
        "       \n",
        "} \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "def f_clf5(params):\n",
        "   model1 =Pipeline(steps=[('encoder',Accepted[4][1]()),('LGBMClassifier', \n",
        "                                                         lgb.LGBMClassifier(**f_unpack_dict(params['LGBMClassifier'])))])   \n",
        "   return model1  \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf5(params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf5 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt5, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "clf5 = f_clf5(space_eval(param_hyperopt5, best_clf5)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf5_val_score = roc_auc_score(y_test, clf5.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf5_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a5=space_eval(param_hyperopt5, best_clf5)\n",
        "fith_classifier={'classifier':list(a5.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf5_val_score,'parameters':list(a5.values())[0]}"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [00:39<05:55, 39.48s/it, best loss: -0.8913360429569718]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [06:26<00:00, 36.78s/it, best loss: -0.8931760781045686]\n",
            "Cross-val score: 0.89318; validation score: 0.89444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3If0WbQtPcQM",
        "colab_type": "code",
        "outputId": "db558e83-8156-45ed-91db-65fbd9e211cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "param_hyperopt6= {\n",
        "    'QuadraticDiscriminantAnalysis':\n",
        "      {\n",
        "           \n",
        "      }      \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf6(params):\n",
        "   model3 =Pipeline(steps=[('encoder',Accepted[5][1]()),('QuadraticDiscriminantAnalysis',QuadraticDiscriminantAnalysis())])\n",
        "   return model3 \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf6(params)\n",
        "    #clf = RandomForestClassifier(**params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf6 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt6, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "\n",
        "clf6 = f_clf6(space_eval(param_hyperopt6, best_clf6)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf6_val_score = roc_auc_score(y_test, clf6.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.format(-trials.best_trial['result']['loss'], clf6_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt6, best_clf6))\n",
        "# Calculating performance on validation set\n",
        "clf6_val_score = roc_auc_score(y_test, clf6.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf6_val_score))\n",
        "#print('Best parameters:')\n",
        "#print(\n",
        "a6=space_eval(param_hyperopt6, best_clf6)\n",
        "six_classifier={'classifier':list(a6.keys())[0],'Cross-val score':-trials.best_trial['result']['loss'],'validation score':clf6_val_score,'parameters':list(a6.values())[0]}"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:06<00:00, 12.49s/it, best loss: -0.786171897798788]\n",
            "Cross-val score: 0.78617; validation score: 0.78724\n",
            "Best parameters:\n",
            "{'QuadraticDiscriminantAnalysis': {}}\n",
            "Cross-val score: 0.78617; validation score: 0.78724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA4P3yftv5VC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "de8a85ee-494a-4b29-c4b4-f51773824c94"
      },
      "source": [
        "Fr_classifier"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8755075622861487,\n",
              " 'classifier': 'ExtraTreesClassifier',\n",
              " 'parameters': {'criterion': 'entropy',\n",
              "  'max_depth': 15,\n",
              "  'max_features': 13,\n",
              "  'min_samples_leaf': 4,\n",
              "  'min_samples_split': 4,\n",
              "  'n_estimators': 13},\n",
              " 'validation score': 0.884938764808794}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT1x5xQ-vWFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e410cd81-9b86-4803-baab-8ac3f7226780"
      },
      "source": [
        "Se_classifier"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8273926245659394,\n",
              " 'classifier': 'RandomForestClassifier',\n",
              " 'parameters': {'criterion': 'gini',\n",
              "  'max_depth': 7,\n",
              "  'max_features': 'auto',\n",
              "  'min_samples_leaf': 2,\n",
              "  'min_samples_split': 3,\n",
              "  'n_estimators': 23},\n",
              " 'validation score': 0.7973701565847332}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jb9jiievacj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "65bf9e4a-0848-4f1c-c4dd-5d41ab5b8608"
      },
      "source": [
        "Thrid_classifier"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8268064630182487,\n",
              " 'classifier': 'LinearDiscriminantAnalysis',\n",
              " 'parameters': {},\n",
              " 'validation score': 0.827194350739109}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWLcgpDlvecC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f0f1a177-9f33-43bb-f7cb-145038a10fc1"
      },
      "source": [
        "Four_classifier"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8761819849027198,\n",
              " 'classifier': 'XGBClassifier',\n",
              " 'parameters': {'max_depth': 7,\n",
              "  'min_child_weight': 1,\n",
              "  'n_estimators': 38,\n",
              "  'subsample': 0.8479101254812229},\n",
              " 'validation score': 0.8770024548105813}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT7GCH_evh_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "299b9ae2-505a-435e-cfe6-551f8a9fbd38"
      },
      "source": [
        "fith_classifier"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.8931760781045686,\n",
              " 'classifier': 'LGBMClassifier',\n",
              " 'parameters': {'colsample_bytree': 1.0,\n",
              "  'max_depth': 9,\n",
              "  'min_child_samples': 70,\n",
              "  'num_leave': 10,\n",
              "  'reg_alpha': 5,\n",
              "  'reg_lambda': 20,\n",
              "  'scale_pos_weight': 50.0,\n",
              "  'subsample': 1.0},\n",
              " 'validation score': 0.8944420319608248}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOeAy9aqvmT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2293deb0-dab7-410f-de2b-5e14296284c3"
      },
      "source": [
        "six_classifier"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cross-val score': 0.786171897798788,\n",
              " 'classifier': 'QuadraticDiscriminantAnalysis',\n",
              " 'parameters': {},\n",
              " 'validation score': 0.787235957146868}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoY5YxNhSY0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a8={'ExtraTreesClassifier': {'criterion': 'gini',\n",
        "  'max_depth': 7,\n",
        "  'max_features': 7,\n",
        "  'min_samples_leaf': 4,\n",
        "  'min_samples_split': 4,\n",
        "  'n_estimators': 19},\n",
        " 'LGBMClassifier': {'colsample_bytree': 1.0,\n",
        "  'max_depth': 7,\n",
        "  'min_child_samples': 80,\n",
        "  'num_leave': 50,\n",
        "  'reg_alpha': 0,\n",
        "  'reg_lambda': 10,\n",
        "  'scale_pos_weight': 70.0,\n",
        "  'subsample': 1.0},\n",
        " 'RandomForestClassifier': {'criterion': 'entropy',\n",
        "  'max_depth': 5,\n",
        "  'max_features': 'sqrt',\n",
        "  'min_samples_leaf': 3,\n",
        "  'min_samples_split': 2,\n",
        "  'n_estimators': 30},\n",
        " 'XGBClassifier': {'max_depth': 13,\n",
        "  'min_child_weight': 3,\n",
        "  'subsample': 0.9406880083709813}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pPpNhbSxXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b063ae00-ef91-43ba-f31b-0f0b891d9107"
      },
      "source": [
        "list(a8.keys())[0]==type(ExtraTreesClassifier()).__name__"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR-MiLGdTMB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "476b9603-b415-4c6a-c498-86b99284806f"
      },
      "source": [
        " model3 =Pipeline(steps=[('encoder',Accepted[5][1]()),('QuadraticDiscriminantAnalysis',QuadraticDiscriminantAnalysis())])\n",
        "type(model3[0]).__name__ "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WOEEncoder'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx6XQUooUNdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d975c48a-29a5-4bd8-8563-4c8e257f309c"
      },
      "source": [
        "list(a8.keys())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ExtraTreesClassifier',\n",
              " 'LGBMClassifier',\n",
              " 'RandomForestClassifier',\n",
              " 'XGBClassifier']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQZrDLCO4tzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "c582b68c-85a5-4e0b-8489-5f14779fcd65"
      },
      "source": [
        "{'ExtraTreesClassifier': {'criterion': 'gini',\n",
        "  'max_depth': 7,\n",
        "  'max_features': 7,\n",
        "  'min_samples_leaf': 4,\n",
        "  'min_samples_split': 4,\n",
        "  'n_estimators': 19},\n",
        " 'LGBMClassifier': {'colsample_bytree': 1.0,\n",
        "  'max_depth': 7,\n",
        "  'min_child_samples': 80,\n",
        "  'num_leave': 50,\n",
        "  'reg_alpha': 0,\n",
        "  'reg_lambda': 10,\n",
        "  'scale_pos_weight': 70.0,\n",
        "  'subsample': 1.0},\n",
        " 'RandomForestClassifier': {'criterion': 'entropy',\n",
        "  'max_depth': 5,\n",
        "  'max_features': 'sqrt',\n",
        "  'min_samples_leaf': 3,\n",
        "  'min_samples_split': 2,\n",
        "  'n_estimators': 30},\n",
        " 'XGBClassifier': {'max_depth': 13,\n",
        "  'min_child_weight': 3,\n",
        "  'subsample': 0.9406880083709813}}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e735912700ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFr_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Fr_classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc6sc6QfbVhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier())\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())\n",
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "pipe5 = make_pipeline(Accepted[4][1](),QuadraticDiscriminantAnalysis())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier())\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6], meta_classifier=LogisticRegression())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxWwikwQVEhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "6c35b65c-dbad-439f-c4aa-4defb500bd1a"
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "for i,k in enumerate(list(sclf2.named_classifiers.keys())):\n",
        "  for j,val in enumerate(list(a8.keys())):\n",
        "    if type((sclf2.named_classifiers[k][1])).__name__ ==list(a8.keys())[j]:\n",
        "      pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier(**a8[val]))\n",
        "for i,k in enumerate(list(sclf2.named_classifiers.keys())):\n",
        "  for j,val in enumerate(list(a8.keys())):\n",
        "     if type((sclf2.named_classifiers[k][1])).__name__ ==list(a8.keys())[j]:\n",
        "      pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier(**a8[val]))\n",
        "for i,k in enumerate(list(sclf2.named_classifiers.keys())):\n",
        "  for j,val in enumerate(list(a8.keys())):\n",
        "    if type((sclf2.named_classifiers[k][1])).__name__ ==list(a8.keys())[j]:      \n",
        "      pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier(**a8[val]))\n",
        "for i,k in enumerate(list(sclf2.named_classifiers.keys())):\n",
        "  for j,val in enumerate(list(a8.keys())):\n",
        "    if type((sclf2.named_classifiers[k][1])).__name__ ==list(a8.keys())[j]:      \n",
        "      pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis(**a8[val]))\n",
        "for i,k in enumerate(list(sclf2.named_classifiers.keys())):\n",
        "  for j,val in enumerate(list(a8.keys())):\n",
        "    if type((sclf2.named_classifiers[k][1])).__name__ ==list(a8.keys())[j]:\n",
        "      pipe5 = make_pipeline(Accepted[4][1](),QuadraticDiscriminantAnalysis(**a8[val]))\n",
        "for i,k in enumerate(list(sclf2.named_classifiers.keys())):\n",
        "  for j,val in enumerate(list(a8.keys())):\n",
        "    if type((sclf2.named_classifiers[k][1])).__name__ ==list(a8.keys())[j]:      \n",
        "      pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier(**a8[val]))\n",
        "\n",
        "sclf2 = StackingClassifier(classifiers=[pipe1,pipe2,pipe3,pipe4,pipe5,pipe6], meta_classifier=LogisticRegression())\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-758a29e3a786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_classifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mpipe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccepted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0ma8\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_classifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'min_child_weight'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsh4A3eZtNDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce2a2c8c-e6da-4b64-e765-8c1c6e23887b"
      },
      "source": [
        "list(pipe1.named_steps.keys())[1],list(a8.keys())[0].lower()"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('xgbclassifier', 'extratreesclassifier')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVFICfs6qliC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for clf, label in zip([list(sclf2.named_classifiers.keys()),sclf2],[list(a8.keys())]):\n",
        "  if label[0].lower()==list(pipe1.named_steps.keys())[1]:\n",
        "    print(label)\n",
        "\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier())\n",
        "\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())\n",
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "pipe5 = make_pipeline(Accepted[4][1](),QuadraticDiscriminantAnalysis())\n",
        "pipe6 = make_pipeline(Accepted[5][1](),lgb.LGBMClassifier())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_QG3jfWoLMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "619dc299-79c4-4e32-ca6f-442e3dd47cc2"
      },
      "source": [
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier(**a8['XGBClassifier']))\n",
        "pipe1,a8['XGBClassifier']"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Pipeline(memory=None,\n",
              "          steps=[('catboostencoder',\n",
              "                  CatBoostEncoder(a=1, cols=None, drop_invariant=False,\n",
              "                                  handle_missing='value', handle_unknown='value',\n",
              "                                  random_state=None, return_df=True, sigma=None,\n",
              "                                  verbose=0)),\n",
              "                 ('xgbclassifier',\n",
              "                  XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                colsample_bylevel=1, colsample_bynode=1,\n",
              "                                colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                                max_delta_step=0, max_depth=13,\n",
              "                                min_child_weight=3, missing=None,\n",
              "                                n_estimators=100, n_jobs=1, nthread=None,\n",
              "                                objective='binary:logistic', random_state=0,\n",
              "                                reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                                seed=None, silent=None,\n",
              "                                subsample=0.9406880083709813, verbosity=1))],\n",
              "          verbose=False),\n",
              " {'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.9406880083709813})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0IPp8evfQkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7ebcfbc6-2563-4608-f52b-0b7698809814"
      },
      "source": [
        "for i,k in enumerate(list(sclf2.named_classifiers.keys())):\n",
        "  for j,val in enumerate(list(a8.keys())):\n",
        "    if type((sclf2.named_classifiers[k][1])).__name__ ==list(a8.keys())[j]:\n",
        "      print(list(a8[val])[0])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_depth\n",
            "criterion\n",
            "criterion\n",
            "colsample_bytree\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oty2Q7TFlUNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sclf2.named_classifiers\n",
        "for i in range(len(list(a8.keys()))):\n",
        "   if list(pipe1.named_steps.keys())[1]==list(a8.keys())[i]:\n",
        "      print(a8.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiGbF94Mg6XY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5aa1680c-f325-446f-a5be-4e03b7543f2e"
      },
      "source": [
        "sclf2.named_classifiers['pipeline-1'][1]"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0,\n",
              "              max_depth={'colsample_bytree': 1.0, 'max_depth': 7,\n",
              "                         'min_child_samples': 80, 'num_leave': 50,\n",
              "                         'reg_alpha': 0, 'reg_lambda': 10,\n",
              "                         'scale_pos_weight': 70.0, 'subsample': 1.0},\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaFe4_nXdj96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "a9616d42-3e4f-49b5-9a1d-07a9b904f5e1"
      },
      "source": [
        "pipe3 = make_pipeline(Accepted[2][1](),ExtraTreesClassifier(**a8['ExtraTreesClassifier'] )  )\n",
        "pipe3\n",
        "a8.keys(),list(sclf2.named_classifiers.keys())\n",
        "a8['XGBClassifier']\n",
        "pipe1 = make_pipeline(Accepted[0][1](),XGBClassifier(**a8['XGBClassifier']))\n",
        "pipe1,a8['XGBClassifier']"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Pipeline(memory=None,\n",
              "          steps=[('catboostencoder',\n",
              "                  CatBoostEncoder(a=1, cols=None, drop_invariant=False,\n",
              "                                  handle_missing='value', handle_unknown='value',\n",
              "                                  random_state=None, return_df=True, sigma=None,\n",
              "                                  verbose=0)),\n",
              "                 ('xgbclassifier',\n",
              "                  XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                colsample_bylevel=1, colsample_bynode=1,\n",
              "                                colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                                max_delta_step=0, max_depth=13,\n",
              "                                min_child_weight=3, missing=None,\n",
              "                                n_estimators=100, n_jobs=1, nthread=None,\n",
              "                                objective='binary:logistic', random_state=0,\n",
              "                                reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                                seed=None, silent=None,\n",
              "                                subsample=0.9406880083709813, verbosity=1))],\n",
              "          verbose=False),\n",
              " {'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.9406880083709813})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHU7-dKPdJKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51ca7629-9338-4a86-add8-74e741515f96"
      },
      "source": [
        "list(pipe1.named_steps.keys())[1]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xgbclassifier'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVJ3yM5qcTeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "312adf8d-3e45-426a-87d6-160f90293884"
      },
      "source": [
        "sclf2.named_classifiers['pipeline-1']"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('catboostencoder',\n",
              "                 CatBoostEncoder(a=1, cols=None, drop_invariant=False,\n",
              "                                 handle_missing='value', handle_unknown='value',\n",
              "                                 random_state=None, return_df=True, sigma=None,\n",
              "                                 verbose=0)),\n",
              "                ('xgbclassifier',\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0,\n",
              "                               learning_rate={'colsa...\n",
              "                               n_estimators={'criterion': 'entropy',\n",
              "                                             'max_depth': 5,\n",
              "                                             'max_features': 'sqrt',\n",
              "                                             'min_samples_leaf': 3,\n",
              "                                             'min_samples_split': 2,\n",
              "                                             'n_estimators': 30},\n",
              "                               n_jobs=1, nthread=None,\n",
              "                               objective='binary:logistic', random_state=0,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity={'max_depth': 13,\n",
              "                                          'min_child_weight': 3,\n",
              "                                          'subsample': 0.9406880083709813}))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxlnbXvCVwb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "6e0ef1f6-e378-4cdd-f77c-c9e4891216cf"
      },
      "source": [
        "from itertools import combinations\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from xgboost.sklearn import XGBClassifier  \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import lightgbm as lgb\n",
        "import category_encoders as ce\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score,classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "#for i in range(len(list(a8.keys())))\n",
        "\n",
        "pipe2 = make_pipeline(Accepted[1][1](),RandomForestClassifier())\n",
        "pipe4 = make_pipeline(Accepted[3][1](),LinearDiscriminantAnalysis())\n",
        "\n",
        "sclf2 = StackingClassifier(classifiers=[pipe2,pipe4], meta_classifier=LogisticRegression())\n",
        "sclf2\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(average_probas=False,\n",
              "                   classifiers=[Pipeline(memory=None,\n",
              "                                         steps=[('jamessteinencoder',\n",
              "                                                 JamesSteinEncoder(cols=None,\n",
              "                                                                   drop_invariant=False,\n",
              "                                                                   handle_missing='value',\n",
              "                                                                   handle_unknown='value',\n",
              "                                                                   model='independent',\n",
              "                                                                   random_state=None,\n",
              "                                                                   randomized=False,\n",
              "                                                                   return_df=True,\n",
              "                                                                   sigma=0.05,\n",
              "                                                                   verbose=0)),\n",
              "                                                ('randomforestclassifier',\n",
              "                                                 RandomForestClassifier(bootstrap=T...\n",
              "                   meta_classifier=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                      dual=False,\n",
              "                                                      fit_intercept=True,\n",
              "                                                      intercept_scaling=1,\n",
              "                                                      l1_ratio=None,\n",
              "                                                      max_iter=100,\n",
              "                                                      multi_class='warn',\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      random_state=None,\n",
              "                                                      solver='warn', tol=0.0001,\n",
              "                                                      verbose=0,\n",
              "                                                      warm_start=False),\n",
              "                   store_train_meta_features=False, use_clones=True,\n",
              "                   use_features_in_secondary=False, use_probas=False,\n",
              "                   verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yif1ZmBHWOHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6ff0c91-1784-4fd6-b507-d136b2fc6f8d"
      },
      "source": [
        "(sclf2.named_classifiers['pipeline-1'][1])\n",
        "type((sclf2.named_classifiers['pipeline-1'][1])).__name__ \n",
        "list(sclf2.named_classifiers.keys())"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pipeline-1', 'pipeline-2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5TMP6e7ab6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "016882b2-f986-4157-8671-fc3dcbf786bf"
      },
      "source": [
        "for i,k in enumerate(list(sclf2.named_classifiers.keys())):\n",
        "  for j,val in enumerate(list(a8.keys())):\n",
        "    if type((sclf2.named_classifiers[k][1])).__name__ ==list(a8.keys())[j]:\n",
        "        print(list(a8.values())[j])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQa1FPcy3ucp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "{'ExtraTreesClassifier': {'criterion': 'gini', 'max_depth': 7, 'max_features': 7, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 19}, \n",
        "'LGBMClassifier': {'colsample_bytree': 1.0, 'max_depth': 7, 'min_child_samples': 80, 'num_leave': 50, 'reg_alpha': 0, 'reg_lambda': 10, 'scale_pos_weight': 70.0, 'subsample': 1.0},\n",
        "'RandomForestClassifier': {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 30},\n",
        "'XGBClassifier': {'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.9406880083709813}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwGKr5nNdGcp",
        "colab_type": "code",
        "outputId": "a9f7cd5b-9183-42f2-8736-1a16defcbdbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "import numpy as np\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "param_hyperopt={\n",
        "  'RandomForestClassifier': \n",
        "            {\n",
        "            'max_depth': ho_scope.int(hp.quniform('c2_max_depth', 5, 7, 1)),\n",
        "            'n_estimators': ho_scope.int(hp.quniform('c2_n_estimators', 5, 30, 1)),\n",
        "            'max_features': hp.choice('c2_max_features', ['auto', 'sqrt']),\n",
        "            'criterion': hp.choice('c2_criterion', ['gini', 'entropy']),\n",
        "            'min_samples_split': ho_scope.int(hp.quniform('c2_min_samples_split', 2, 5,1)),\n",
        "            'min_samples_leaf': ho_scope.int(hp.quniform('c2_min_samples_leaf', 2, 5,1))\n",
        "                          \n",
        "         },\n",
        "  'ExtraTreesClassifier':\n",
        "            {\n",
        "                'max_depth': ho_scope.int(hp.quniform('c4_max_depth', 5, 20, 1)),\n",
        "                'n_estimators': ho_scope.int(hp.quniform('c4_n_estimators', 5, 30, 1)),\n",
        "                'max_features': ho_scope.int(hp.quniform('c4_max_features', 5, 20, 1)),\n",
        "                'criterion': hp.choice('c4_criterion', ['gini', 'entropy']),\n",
        "                'min_samples_split': ho_scope.int(hp.quniform('c4_min_samples_split', 2, 5,1)),\n",
        "                'min_samples_leaf': ho_scope.int(hp.quniform('c4_min_samples_leaf', 2, 5,1))\n",
        "       },\n",
        "  'XGBClassifier':\n",
        "      {\n",
        "           'max_depth': hp.choice(\"x_max_depth\", np.arange(5, 25, dtype=int)),\n",
        "           'min_child_weight': hp.choice ('x_min_child',np.arange(1, 10, dtype=int)),\n",
        "           'subsample': hp.uniform ('x_subsample', 0.8, 1)\n",
        "       },\n",
        "  'LGBMClassifier':\n",
        "       {\n",
        "        'max_depth': ho_scope.int(hp.quniform('c6_max_depth', 3, 10, 1)),\n",
        "        'num_leave': ho_scope.int(hp.quniform('c6_num_leaves', 5, 50, 5)),\n",
        "        'min_child_samples': ho_scope.int(hp.quniform('c6_min_child_samples', 50, 100, 10)),\n",
        "        'scale_pos_weight': ho_scope.float(hp.quniform('c6_scale_pos_weight', 50, 100, 10)),\n",
        "        'subsample': ho_scope.float(hp.quniform('c6_subsample', 0.6, 0.9, 1)),\n",
        "        'colsample_bytree': ho_scope.float(hp.quniform('c6_colsample_bytree', 0.6, 0.9, 1)),\n",
        "        'reg_lambda': hp.choice(\"c6_reg_lambda\",[0, 1e-1, 1, 5, 10, 20, 50]),\n",
        "        'reg_alpha': hp.choice(\"c6_reg_alpha\",[0, 1e-1, 1, 5, 10, 20, 50])\n",
        "       }         \n",
        "       \n",
        "}  \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf8(params):\n",
        "   model1 =Pipeline(steps=[('encoder',Accepted[0][1]()),\n",
        "             ('c4',ExtraTreesClassifier(**f_unpack_dict(params['ExtraTreesClassifier'])))])\n",
        "   model2 =Pipeline(steps=[('encoder',Accepted[1][1]()),('LGBMClassifier', lgb.LGBMClassifier(**f_unpack_dict(params['LGBMClassifier'])))]) \n",
        "   model3 =Pipeline(steps=[('encoder',Accepted[2][1]()),('XGBClassifier', xgb.XGBClassifier(**f_unpack_dict(params['XGBClassifier'])))])   \n",
        "   model4 =Pipeline(steps=[('encoder',Accepted[3][1]()),('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis())]) \n",
        "   model5 =Pipeline(steps=[('encoder',Accepted[4][1]()),\n",
        "             ('c2',RandomForestClassifier(**f_unpack_dict(params['RandomForestClassifier'])))]) \n",
        "   model6 =Pipeline(steps=[('encoder',Accepted[5][1]()),('QuadraticDiscriminantAnalysis', QuadraticDiscriminantAnalysis())])\n",
        "   sclf2 = StackingClassifier(classifiers=[model1,model2,model3,model4,model5,model6],meta_classifier=LogisticRegression())\n",
        "   return sclf2\n",
        "  \n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf8(params)\n",
        "    #clf = RandomForestClassifier(**params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf8 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                param_hyperopt, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "\n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "clf8 = f_clf8(space_eval(param_hyperopt, best_clf8)).fit(X_train, y_train)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf8_val_score = roc_auc_score(y_test, clf8.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf8_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt, best_clf8))\n",
        "oo=-trials.best_trial['result']['loss']\n",
        "oo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [29:27<4:25:04, 1767.20s/it, best loss: -0.8759822037775029]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd05nQ3EojhD",
        "colab_type": "code",
        "outputId": "7a2da0a9-b32c-4347-b9e2-3466c7cbaff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from hyperopt.pyll import scope as ho_scope                                       \n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "import numpy as np\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "\n",
        "param_hyperopt= {\n",
        "    'AdaBoostClassifier':\n",
        "     {\n",
        "          'learning_rate': hp.loguniform('c5_learning_rate', np.log(0.01), np.log(1)),\n",
        "           'n_estimators': ho_scope.int(hp.quniform('c5_n_estimators', 5, 30, 1)),\n",
        "           'algorithm': hp.choice('c5_algorithm',[\"SAMME\"])  \n",
        "       }    \n",
        "} \n",
        "   \n",
        "def f_unpack_dict(dct): \n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "            \n",
        "    return res\n",
        "\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size = 0.2, random_state = 0)\n",
        "\n",
        "def f_clf7(params):\n",
        "   model2 =Pipeline(steps=[('encoder',Accepted[5][1]()),\n",
        "             ('c5',AdaBoostClassifier(**f_unpack_dict(params['AdaBoostClassifier'])))]) \n",
        "   return model2\n",
        "        \n",
        "\n",
        "def objective_function(params,X_train2, y_train2):\n",
        "    model=f_clf7(params)\n",
        "    #clf = RandomForestClassifier(**params)\n",
        "    score = cross_val_score(model, X_train2, y_train2, cv=5,scoring='roc_auc', n_jobs=-1).mean()\n",
        "    return {'loss': -score, 'status': STATUS_OK}  \n",
        "\n",
        "trials = Trials()\n",
        "best_clf7 = fmin(partial(objective_function, X_train2=X_train2, y_train2=y_train2),\n",
        "                 param_hyperopt, algo=tpe.suggest, max_evals=10,trials=trials, rstate=np.random.RandomState(1))\n",
        "\n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "clf7 = f_clf7(space_eval(param_hyperopt, best_clf7)).fit(X_train2, y_train2)\n",
        "\n",
        "# Calculating performance on validation set\n",
        "clf7_val_score = roc_auc_score(y_test, clf7.predict_proba(X_test)[:, 1])\n",
        "print('Cross-val score: {0:.5f}; validation score: {1:.5f}'.\\\n",
        "      format(-trials.best_trial['result']['loss'], clf7_val_score))\n",
        "print('Best parameters:')\n",
        "print(space_eval(param_hyperopt, best_clf7))\n",
        "cc=-trials.best_trial['result']['loss']\n",
        "cc"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [07:45<00:00, 43.23s/it, best loss: -0.7034403411046589]\n",
            "Cross-val score: 0.70344; validation score: 0.70367\n",
            "Best parameters:\n",
            "{'AdaBoostClassifier': {'algorithm': 'SAMME', 'learning_rate': 0.30044074314959096, 'n_estimators': 13}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7034403411046589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTiYkemagMPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install hyperopt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfP43S4Ohohx",
        "colab_type": "code",
        "outputId": "2be333cf-8cd0-4328-c9f5-a54e3d3a5410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# load dataset\n",
        "numeric_features = df6_pd.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df6_pd.select_dtypes(include=['object']).columns\n",
        "X2 = df6_pd.drop('Delay', axis=1)\n",
        "y2 = df6_pd['Delay']\n",
        "# Do the train test split\n",
        "#le = preprocessing.LabelEncoder()\n",
        "#label_encoder = le.fit(y)\n",
        "#y = label_encoder.transform(y)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2)\n",
        "block_size=int(round(X_train2.shape[0]/2))\n",
        "n = block_size  #chunk row size\n",
        "list_X_train = [X_train2[i:i+n] for i in range(0,X_train2.shape[0],n)]\n",
        "list_y_train = [y_train2[i:i+n] for i in range(0,y_train2.shape[0],n)]\n",
        "list_X_test = [X_test2[i:i+n] for i in range(0,X_test2.shape[0],n)]\n",
        "list_y_test = [y_test2[i:i+n] for i in range(0,y_test2.shape[0],n)]\n",
        "# Build the encoder\n",
        "\n",
        "# prepare configuration for cross validation test harness\n",
        "seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('LDA', LinearDiscriminantAnalysis())])).fit(list_X_train[0], list_y_train[0]))\n",
        "models.append((Pipeline(steps=[('encoder',ce.james_stein.JamesSteinEncoder()),\n",
        "                     ('MLPClassifier',\n",
        "                      MLPClassifier(hidden_layer_sizes=(10,10), max_iter=5, alpha=0.0001,\n",
        "                     solver='sgd', verbose=10,  random_state=1))])).fit(list_X_train[1], list_y_train[1]))\n",
        "\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'roc_auc'\n",
        "for name, model in enumerate(models):\n",
        "    #kfold = model_selection.StratifiedKFold(n_splits=5, random_state=1)\n",
        "    print('1')\n",
        "    cv_results = model_selection.cross_val_score(model, list_X_train[name],  list_y_train[name], cv=5, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 112.60309919\n",
            "Iteration 3, loss = 112.60068321\n",
            "Iteration 4, loss = 112.59827204\n",
            "Iteration 5, loss = 112.59586177\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: 0.827382 (0.001427)\n",
            "1\n",
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 181.08164638\n",
            "Iteration 3, loss = 181.07853945\n",
            "Iteration 4, loss = 181.07543119\n",
            "Iteration 5, loss = 181.07232161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 118.73212266\n",
            "Iteration 3, loss = 118.73009402\n",
            "Iteration 4, loss = 118.72805917\n",
            "Iteration 5, loss = 118.72602306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 153.40265149\n",
            "Iteration 3, loss = 153.40002376\n",
            "Iteration 4, loss = 153.39739347\n",
            "Iteration 5, loss = 153.39475892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 120.69334431\n",
            "Iteration 3, loss = 120.69127561\n",
            "Iteration 4, loss = 120.68921110\n",
            "Iteration 5, loss = 120.68714254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = inf\n",
            "Iteration 2, loss = 190.89814426\n",
            "Iteration 3, loss = 190.89486761\n",
            "Iteration 4, loss = 190.89159044\n",
            "Iteration 5, loss = 190.88831180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1: 0.500000 (0.000000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDt8-e_XmiOv",
        "colab_type": "code",
        "outputId": "f7f70bbc-b072-486a-fdbf-5ff5f4d70c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for name, model in enumerate(models):\n",
        "  print(results[name].mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8273824152308913\n",
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aljnuiFrJVF9",
        "colab_type": "code",
        "outputId": "99cbaede-5ba4-4c78-fe56-33f15d363889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "best_clf1,best_clf2"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'c4_criterion': 1,\n",
              "  'c4_max_depth': 15.0,\n",
              "  'c4_max_features': 13.0,\n",
              "  'c4_min_samples_leaf': 4.0,\n",
              "  'c4_min_samples_split': 4.0,\n",
              "  'c4_n_estimators': 13.0},\n",
              " {'c2_criterion': 0,\n",
              "  'c2_max_depth': 7.0,\n",
              "  'c2_max_features': 0,\n",
              "  'c2_min_samples_leaf': 2.0,\n",
              "  'c2_min_samples_split': 3.0,\n",
              "  'c2_n_estimators': 23.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkins7LUbL2I",
        "colab_type": "code",
        "outputId": "b42803f4-b61a-42fc-f18c-02c79188d223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "Fr_classifier,six_classifier"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-c91942c4f55b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFr_classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msix_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'six_classifier' is not defined"
          ]
        }
      ]
    }
  ]
}